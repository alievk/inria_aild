{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import os\n",
    "from time import time\n",
    "import random\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "from models.inceptionresnetv2 import pretrained_settings\n",
    "from models.unet import unet_inceptionresnetv2, UNetUp2\n",
    "\n",
    "pjoin = join = os.path.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_ROOT = '/home/kaliev/Downloads/AerialImageDataset_crop/train/'\n",
    "IMAGES_ROOT = TRAIN_ROOT + 'images'\n",
    "GT_ROOT = TRAIN_ROOT + 'gt'\n",
    "\n",
    "OUTPUT_DIR = './output/'\n",
    "\n",
    "IMAGE_SZ = 255\n",
    "ORIG_IMAGE_SZ = 1250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.setNumThreads(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2018)\n",
    "np.random.seed(2018)\n",
    "torch.manual_seed(2018)\n",
    "torch.cuda.manual_seed_all(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Progress:\n",
    "    def __init__(self, total, desc, print_freq=0.1):\n",
    "        self.total = total\n",
    "        self.desc = desc\n",
    "        self.prog = 0\n",
    "        self.last_print = 0\n",
    "        self.postfix = ''\n",
    "        self.print_freq = print_freq\n",
    "                \n",
    "    def update(self, step):\n",
    "        self.prog += step\n",
    "        if self.prog == self.total:\n",
    "            self._print()\n",
    "        if self.last_print / self.total < self.print_freq \\\n",
    "            and (self.last_print + step) / self.total >= self.print_freq:\n",
    "            self._print()\n",
    "            self.last_print = 0\n",
    "        else:\n",
    "            self.last_print += step\n",
    "            \n",
    "    def _print(self):\n",
    "        prog = self.prog / self.total * 100\n",
    "        line = f'{self.desc} {prog:.2f}% {self.postfix}'\n",
    "        print(line)\n",
    "        \n",
    "    def set_postfix(self, postfix):\n",
    "        self.postfix = str(postfix)\n",
    "        \n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, log_filepath):\n",
    "        self.log = open(log_filepath, 'w')\n",
    "\n",
    "    def msg(self, msg, output_to_console=False, tq=None):\n",
    "        self.log.write('%s %s\\n' % (datetime.now().isoformat(), msg))\n",
    "        if output_to_console:\n",
    "            if tq is not None:\n",
    "                tq.write(msg)\n",
    "            else:\n",
    "                print(msg)\n",
    "                \n",
    "    def __del__(self):\n",
    "        self.log.close()\n",
    "        \n",
    "        \n",
    "def ocv_loader(fpath):\n",
    "    im = cv2.imread(fpath)\n",
    "    return im[:, :, ::-1].copy() if im is not None else None\n",
    "        \n",
    "        \n",
    "normalizer = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=pretrained_settings['mean'], std=pretrained_settings['std']),\n",
    "])\n",
    "\n",
    "\n",
    "class Denormalize:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = torch.FloatTensor(mean)\n",
    "        self.std = torch.FloatTensor(std)\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        img = img.permute(1, 2, 0)\n",
    "        return img * self.std + self.mean\n",
    "\n",
    "\n",
    "denormalizer = Denormalize(pretrained_settings['mean'], pretrained_settings['std'])\n",
    "\n",
    "\n",
    "def mask_overlay(image, mask, ch=0):\n",
    "    if not isinstance(mask, np.ndarray):\n",
    "        mask = mask.numpy()\n",
    "    if mask.ndim > 2:\n",
    "        mask = mask[ch,:,:]\n",
    "    if isinstance(image, str):\n",
    "        im = cv2.imread(image)\n",
    "        im = cv2.resize(im, (mask.shape[1], mask.shape[0]))\n",
    "    else:\n",
    "        im = denormalizer(image).numpy()\n",
    "        im = (im * 255).astype(np.uint8)\n",
    "    mask_ch = np.clip((255*mask) + im[...,0], 0, 255).astype(np.uint8)\n",
    "    return np.dstack((mask_ch,im[...,1],im[...,2]))\n",
    "\n",
    "\n",
    "def variable(x, volatile=False):\n",
    "    return Variable(x, volatile=volatile).cuda()\n",
    "\n",
    "\n",
    "# func to show image\n",
    "def imshow(im,figsz=(12,12),**kwargs):\n",
    "    plt.figure(figsize=figsz)\n",
    "    plt.imshow(im,**kwargs)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCrop(object):\n",
    "    def __init__(self, size):\n",
    "        if isinstance(size, int):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        h, w = img.shape[:2]\n",
    "        tw, th = self.size\n",
    "        if w == tw and h == th:\n",
    "            return img, mask\n",
    "\n",
    "        if ((w - tw) > 0) and ((h - th) > 0):\n",
    "            x1 = np.random.randint(0, w - tw)\n",
    "            y1 = np.random.randint(0, h - th)\n",
    "        else:\n",
    "            x1 = 0\n",
    "            y1 = 0\n",
    "        img = img[y1:y1 + th, x1:x1 + tw]\n",
    "        if mask is not None:\n",
    "            mask = mask[y1:y1 + th, x1:x1 + tw]\n",
    "        return img, mask\n",
    "    \n",
    "\n",
    "class CenterCrop:\n",
    "    def __init__(self, size):\n",
    "        if isinstance(size, (list, tuple, np.ndarray)):\n",
    "            self.width, self.height = size\n",
    "        else:\n",
    "            self.width = self.height = size\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        h, w, c = img.shape\n",
    "        dx = (w-self.width)//2\n",
    "        dy = (h-self.height)//2\n",
    "\n",
    "        y1 = dy\n",
    "        y2 = y1 + self.height\n",
    "        x1 = dx\n",
    "        x2 = x1 + self.width\n",
    "        img = img[y1:y2, x1:x2]\n",
    "        if mask is not None:\n",
    "            mask = mask[y1:y2, x1:x2]\n",
    "        return img, mask\n",
    "    \n",
    "    \n",
    "# ### IMGAUG ###\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "    \n",
    "    \n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "# GEOMETRY\n",
    "ia_aug_geom_light = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),\n",
    "    sometimes(iaa.Affine(\n",
    "        rotate=(-45, 45),\n",
    "        order=1\n",
    "    ))\n",
    "], random_order=True)\n",
    "\n",
    "ia_aug_geom = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Flipud(0.5),\n",
    "    sometimes(iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "        rotate=(-45, 45),\n",
    "        shear=(-10, 10),\n",
    "        order=1\n",
    "    )),\n",
    "    sometimes(iaa.OneOf([\n",
    "        iaa.PiecewiseAffine(scale=(0.01, 0.02)),\n",
    "        iaa.PerspectiveTransform(scale=(0.01, 0.1))\n",
    "    ])),\n",
    "], random_order=True)\n",
    "\n",
    "# COLOR\n",
    "ia_aug_color_light = iaa.Sequential([\n",
    "    iaa.Add((-10, 10)),\n",
    "    iaa.ContrastNormalization((0.8, 1.2))\n",
    "], random_order=True)\n",
    "\n",
    "ia_aug_color = iaa.Sequential([\n",
    "    iaa.Add((-10, 10)),\n",
    "    iaa.ContrastNormalization((0.8, 1.2)),\n",
    "    iaa.OneOf([\n",
    "        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255)),\n",
    "        iaa.OneOf([\n",
    "            iaa.GaussianBlur((0, 1.0)),\n",
    "            iaa.AverageBlur(k=(1, 3)),\n",
    "            iaa.MedianBlur(k=(1, 5)),\n",
    "        ]),\n",
    "        iaa.Sharpen(alpha=(0, 0.5), lightness=(0.75, 1.5)),\n",
    "    ])\n",
    "], random_order=True)\n",
    "\n",
    "\n",
    "def augment(img, mask):\n",
    "    aug_geom = ia_aug_geom.to_deterministic()\n",
    "    aug_color = ia_aug_color\n",
    "    img = aug_geom.augment_image(img)\n",
    "    img = aug_color.augment_image(img)\n",
    "    mask = aug_geom.augment_image(mask)\n",
    "    return img.copy(), mask.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split():\n",
    "    def get_city_n(s):\n",
    "        for i, c in enumerate(s):\n",
    "            if c.isdigit():\n",
    "                break\n",
    "        return int(s[i:])\n",
    "\n",
    "    train_fnames, val_fnames = [], []\n",
    "    for fname in os.listdir(IMAGES_ROOT):\n",
    "        toks = fname[:-4].split('-')\n",
    "        city_n = '-'.join(toks[:-1])\n",
    "        part = toks[-1]\n",
    "        if get_city_n(city_n) < 6:\n",
    "            val_fnames.append(fname)\n",
    "        else:\n",
    "            train_fnames.append(fname)\n",
    "    return train_fnames, val_fnames\n",
    "\n",
    "\n",
    "def prepare_data(img, mask):\n",
    "    img = normalizer(img)\n",
    "    mask = torch.from_numpy(mask / 255).unsqueeze(0).float()\n",
    "    return img, mask\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, image_sz, image_list, epoch_mul=1):\n",
    "        self.image_sz = image_sz\n",
    "        self.image_list = image_list\n",
    "        self.epoch_mul = epoch_mul\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx %= len(self.image_list)            \n",
    "        image_path = pjoin(IMAGES_ROOT, self.image_list[idx])\n",
    "        gt_path = pjoin(GT_ROOT, self.image_list[idx])\n",
    "        img = ocv_loader(image_path)\n",
    "        gt = ocv_loader(gt_path)[:, :, 0]\n",
    "        assert img is not None\n",
    "        assert gt is not None\n",
    "        \n",
    "        pre_aug_sz = int(self.image_sz * 1.5)\n",
    "        img, gt = RandomCrop(pre_aug_sz)(img, gt)\n",
    "        img, gt = augment(img, gt)\n",
    "        img, gt = CenterCrop(self.image_sz)(img, gt)\n",
    "        img, gt = prepare_data(img, gt)\n",
    "        \n",
    "        return img, gt, image_path\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_list) * self.epoch_mul"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "t,v=train_val_split()\n",
    "len(t),len(v)\n",
    "t[:10],v[:10]\n",
    "ds=Dataset(IMAGE_SZ,v)\n",
    "for i in range(5):\n",
    "    img, gt, ipath=ds[i]\n",
    "    imshow(mask_overlay(img, gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_shape(img):\n",
    "    pad = 31 - img.shape[0] % 32\n",
    "    pads = [[0, pad], [0, pad]]\n",
    "    if img.ndim == 3:\n",
    "        pads += [[0, 0]]\n",
    "    return np.pad(img, pads, 'symmetric')\n",
    "\n",
    "\n",
    "def one_batch(img, gt):\n",
    "    img, gt = prepare_data(img, gt)\n",
    "    img, gt = img.unsqueeze(0), gt.unsqueeze(0)\n",
    "    return variable(img, volatile=True), variable(gt)\n",
    "\n",
    "\n",
    "def calc_loss(model, criterion, file_names, return_list=False):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for i, fname in enumerate(file_names):\n",
    "        image_path = pjoin(IMAGES_ROOT, fname)\n",
    "        gt_path = pjoin(GT_ROOT, fname)\n",
    "        img = ocv_loader(image_path)\n",
    "        gt = ocv_loader(gt_path)[:, :, 0]\n",
    "        img, gt = fix_shape(img), fix_shape(gt)\n",
    "        img, gt = one_batch(img, gt)\n",
    "        output = model(img)\n",
    "        losses.append(criterion(output, gt).data[0])\n",
    "    return np.mean(losses)\n",
    "\n",
    "\n",
    "def train(logger,\n",
    "          model,\n",
    "          output_dirpath,\n",
    "          init_optimizer,\n",
    "          lr,\n",
    "          num_iters,\n",
    "          criterion,\n",
    "          train_dataloader, \n",
    "          val_set):\n",
    "    logger.msg(str(model))\n",
    "    optimizer = init_optimizer(model.parameters(), lr=lr)\n",
    "    train_hist = defaultdict(list)\n",
    "    best_val_loss = float('inf')\n",
    "    it = 0\n",
    "    try:\n",
    "        while it < num_iters:\n",
    "            model.train()\n",
    "            for inputs, targets, _ in train_dataloader:\n",
    "                inputs, targets = variable(inputs), variable(targets)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss = loss.data[0]\n",
    "                if it % 20 == 0:\n",
    "                    logger.msg(f'Stage: train, iter: {it}, lr: {lr:.6f}, loss {train_loss:.6f}',\n",
    "                              output_to_console=True)\n",
    "                train_hist['train'].append((it, train_loss))\n",
    "                \n",
    "                if it and it % 5000 == 0:\n",
    "                    model_dirpath = join(output_dirpath, 'model.pt')\n",
    "                    torch.save(model.state_dict(), model_dirpath)\n",
    "                    \n",
    "                if it and it % 10000 == 0:\n",
    "                    val_loss = calc_loss(model, criterion, val_set)\n",
    "                    logger.msg(f'Stage: eval, iter: {it}, loss {val_loss:.6f}',\n",
    "                              output_to_console=True)\n",
    "                    train_hist['val'].append((it, val_loss))\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        best_model_dirpath = join(output_dirpath, 'model_best.pt')\n",
    "                        shutil.copy(model_dirpath, best_model_dirpath)\n",
    "                        \n",
    "                if it and it % 20000 == 0:\n",
    "                    lr /= 2\n",
    "                    optimizer = init_optimizer(model.parameters(), lr=lr)\n",
    "                    print(f'LR => {lr:E}')\n",
    "                        \n",
    "                it += 1\n",
    "                if it == num_iters:\n",
    "                    break\n",
    "    except KeyboardInterrupt:\n",
    "        torch.save(model.state_dict(), model_dirpath)\n",
    "        print('kb interrupt')\n",
    "    return train_hist"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def train(logger,\n",
    "          model,\n",
    "          output_dirpath,\n",
    "          init_optimizer, lr,\n",
    "          epochs,\n",
    "          criterion,\n",
    "          train_dataloader, val_dataloader,\n",
    "          val_every,\n",
    "          metrics={},\n",
    "          patience=5):\n",
    "    model.train()\n",
    "    logger.msg(str(model))\n",
    "    optimizer = init_optimizer(model.parameters(), lr=lr)\n",
    "    best_val_loss = float('inf')\n",
    "    next_val = val_every\n",
    "    last_lr_reset_val_it = 0\n",
    "    val_it = 0\n",
    "    val_losses = []\n",
    "    train_hist = defaultdict(list)\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            pg = Progress(total=len(train_dataloader), desc='Epoch {}'.format(epoch + 1), print_freq=0.1)\n",
    "\n",
    "            it = 0\n",
    "            its = len(train_dataloader)\n",
    "\n",
    "            for inputs, targets, _ in train_dataloader:\n",
    "                if isinstance(inputs, list): print(inputs)\n",
    "                inputs, targets = variable(inputs), variable(targets)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                postfix = {'loss': '{:.6f}'.format(loss.data[0])}\n",
    "                for name, metric in metrics.items():\n",
    "                    metric_value = metric(outputs, targets)\n",
    "                    postfix[name] = '{:.6f}'.format(metric_value)\n",
    "                pg.set_postfix(postfix)\n",
    "                pg.update(1)\n",
    "\n",
    "                logger.msg('Stage: train, epoch: {}, iter: {}, lr: {}, metrics: {}'.format(\n",
    "                    epoch + 1,\n",
    "                    it,\n",
    "                    lr,\n",
    "                    str(postfix)\n",
    "                ))\n",
    "\n",
    "                it += 1\n",
    "                global_progress = epoch + it / its\n",
    "\n",
    "                train_hist['train'].append((global_progress, loss.data[0]))\n",
    "\n",
    "                if global_progress + 1e-9 >= next_val:\n",
    "                    val_it += 1\n",
    "                    model_dirpath = join(output_dirpath, 'model.pt')\n",
    "                    torch.save(model.state_dict(), model_dirpath)\n",
    "                    while not next_val > global_progress:\n",
    "                        next_val += val_every\n",
    "                    metric_values = evaluate(\n",
    "                        logger,\n",
    "                        model,\n",
    "                        val_dataloader,\n",
    "                        metrics={'loss': criterion, **metrics}\n",
    "                    )\n",
    "                    model.train()\n",
    "                    val_loss = metric_values['loss']\n",
    "                    train_hist['val'].append((global_progress, val_loss))\n",
    "                    val_losses.append(val_loss)\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        best_model_dirpath = join(output_dirpath, 'model_best.pt')\n",
    "                        shutil.copy(model_dirpath, best_model_dirpath)\n",
    "                    else:\n",
    "                        if (patience and val_it - last_lr_reset_val_it > patience and\n",
    "                                    min(val_losses[-patience:]) > best_val_loss):\n",
    "                            lr /= np.sqrt(10)\n",
    "                            last_lr_reset_val_it = val_it\n",
    "                            optimizer = init_optimizer(model.parameters(), lr=lr)\n",
    "                            print(f'LR => {lr:E}')\n",
    "    except KeyboardInterrupt:\n",
    "        torch.save(model.state_dict(), model_dirpath)\n",
    "        print('kb interrupt')\n",
    "    return train_hist\n",
    "\n",
    "def evaluate(logger, model, dataloader, metrics={}):\n",
    "    model.eval()\n",
    "    metric_values = defaultdict(int)\n",
    "\n",
    "    pg = Progress(total=len(dataloader), desc='Eval', print_freq=.5)\n",
    "\n",
    "    samples = 0\n",
    "    for inputs, targets, filepaths in dataloader:\n",
    "        inputs, targets = variable(inputs, volatile=True), variable(targets)\n",
    "        outputs = model(inputs)\n",
    "        batch_size = inputs.size(0)\n",
    "        for name, metric in metrics.items():\n",
    "            metric_value = metric(outputs, targets)\n",
    "            if isinstance(metric_value, torch.autograd.Variable):\n",
    "                metric_value = metric_value.data[0]\n",
    "            metric_values[name] += metric_value * batch_size\n",
    "        samples += batch_size\n",
    "        pg.update(1)\n",
    "    for name in metric_values:\n",
    "        metric_values[name] /= samples\n",
    "    logger.msg(\n",
    "        'Stage: eval, metrics: {}'.format(str(dict(metric_values))),\n",
    "        output_to_console=True,\n",
    "    )\n",
    "\n",
    "    return metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "epoch_mul = 1\n",
    "\n",
    "train_set, val_set = train_val_split()\n",
    "\n",
    "ds_train = Dataset(IMAGE_SZ, train_set, epoch_mul=epoch_mul)\n",
    "ds_valid = Dataset(IMAGE_SZ, val_set, epoch_mul=epoch_mul)\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "dl_valid = DataLoader(ds_valid, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set), len(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        pred = F.sigmoid(output)\n",
    "        smooth = 1e-6\n",
    "        intersection = (pred * target).sum()\n",
    "        return 1. - (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
    "\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self, w_bce=.5, w_dice=.5):\n",
    "        super().__init__()\n",
    "        self.dice = DiceLoss()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.w_bce = w_bce\n",
    "        self.w_dice = w_dice\n",
    "        self.hist = {'bce': [], 'dice': []}\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        bce = self.w_bce * self.bce(input, target)\n",
    "        dice = self.w_dice * self.dice(input, target)\n",
    "        self.hist['bce'].append(bce.data[0])\n",
    "        self.hist['dice'].append(dice.data[0])\n",
    "        return bce + dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ch = 1\n",
    "\n",
    "def get_model():\n",
    "    model = unet_inceptionresnetv2(out_ch, up_block=UNetUp2)\n",
    "    model.out_logits = True  # >>> MATCH CRETIRION <<<\n",
    "    return nn.DataParallel(model)\n",
    "\n",
    "init_optimizer = lambda parameters, lr: Adam(parameters, lr=lr)\n",
    "\n",
    "criterion = BCEDiceLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = '2'\n",
    "experiment_dir = OUTPUT_DIR + experiment_name\n",
    "!mkdir -p {experiment_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(pjoin(experiment_dir, 'train_log.txt'))\n",
    "\n",
    "model = get_model()\n",
    "#model.load_state_dict(torch.load('./output/.../model.pt'))\n",
    "# train_dict = {\n",
    "#     'model': model,\n",
    "#     'output_dirpath': experiment_dir,\n",
    "#     'init_optimizer': init_optimizer,\n",
    "#     'lr': 0.001,\n",
    "#     'epochs': 200,\n",
    "#     'criterion': criterion,\n",
    "#     'train_dataloader': dl_train,\n",
    "#     'val_dataloader': dl_valid,\n",
    "#     'val_every': 1,\n",
    "#     'patience': 10,\n",
    "#     #'metrics': {'MSE': mse},\n",
    "#     'logger': logger\n",
    "# }\n",
    "train_dict = {\n",
    "    'model': model,\n",
    "    'output_dirpath': experiment_dir,\n",
    "    'init_optimizer': init_optimizer,\n",
    "    'lr': 1e-4,\n",
    "    'num_iters': 200000,\n",
    "    'criterion': criterion,\n",
    "    'train_dataloader': dl_train,\n",
    "    'val_set': val_set,\n",
    "    'logger': logger\n",
    "}\n",
    "train_hist = train(**train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_smooth(x):\n",
    "    out = x[:]\n",
    "    tau = 0.95\n",
    "    for i in range(1, len(x) - 1):\n",
    "        out[i] = out[i - 1] * tau + out[i] (1 - tau)\n",
    "\n",
    "def plot_train_hist(hist):\n",
    "    val_loss = np.array(hist['val'])[:,1]\n",
    "    v_min, v_min_ep = val_loss.min(), val_loss.argmin()\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    trn_hist = np.array(hist['train'])\n",
    "    plt.plot(trn_hist[10:,0], trn_hist[10:,1])\n",
    "    plt.title('Train loss')\n",
    "    plt.grid(True)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    val_hist = np.array(hist['val'])\n",
    "    plt.plot(val_hist[1:,0], val_hist[1:,1])\n",
    "    plt.hlines([v_min], 0, val_hist[-1,0])\n",
    "    plt.title(f'Validation loss (min {v_min:.6f}@{v_min_ep})')\n",
    "    plt.grid(True)\n",
    "    \n",
    "plot_train_hist(train_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model_path = f'./output/{experiment_name}/model.pt'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.cuda()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def to_crops(img, crop_sz):\n",
    "    assert img.shape[0] == img.shape[1]\n",
    "    n = img.shape[0] // crop_sz\n",
    "    pad = crop_sz * (1 + n) - img.shape[0]\n",
    "    pads = [[0, pad], [0, pad]]\n",
    "    if img.ndim == 3:\n",
    "        pads += [[0, 0]]\n",
    "    img_pad = np.pad(img, pads, 'symmetric')\n",
    "    n_p = img_pad.shape[0] // crop_sz\n",
    "    crops = []\n",
    "    for i in range(n_p):\n",
    "        for j in range(n_p):\n",
    "            x = j * crop_sz\n",
    "            y = i * crop_sz\n",
    "            crops.append(img_pad[y:y+crop_sz,x:x+crop_sz,...])\n",
    "    return crops\n",
    "\n",
    "\n",
    "def pred2img(pred, ch=0):\n",
    "#     return torch.sigmoid(pred).data[0].cpu().numpy()[ch]\n",
    "    return torch.exp(pred).data[0].cpu().numpy()[ch]\n",
    "\n",
    "\n",
    "def predshow(pred, ch=0):\n",
    "    imshow(pred2img(pred, ch),cmap='gray',vmin=0, vmax=1)\n",
    "\n",
    "\n",
    "def iou(pred, target):\n",
    "    thr = 0.4\n",
    "    pred = F.sigmoid(pred).data[0].cpu().numpy()\n",
    "    target = target.data[0].cpu().numpy()\n",
    "    pred = (pred > thr).astype(int)\n",
    "    pred = pred[:ORIG_IMAGE_SZ,:ORIG_IMAGE_SZ]\n",
    "    target = target[:ORIG_IMAGE_SZ,:ORIG_IMAGE_SZ]\n",
    "    intersection = (pred * target).sum()\n",
    "    return intersection / (pred.sum() + target.sum() - intersection + 1e-12)\n",
    "\n",
    "\n",
    "def calc_iou(model, file_names, return_list=False):\n",
    "    model.eval()\n",
    "    ious = []\n",
    "    for i, fname in enumerate(file_names):\n",
    "        print(f'{i+1}/{len(file_names)}')\n",
    "        image_path = pjoin(IMAGES_ROOT, fname)\n",
    "        gt_path = pjoin(GT_ROOT, fname)\n",
    "        img = ocv_loader(image_path)\n",
    "        gt = ocv_loader(gt_path)[:, :, 0]\n",
    "        imshow(gt)\n",
    "        img, gt = fix_shape(img), fix_shape(gt)\n",
    "        img, gt = one_batch(img, gt)\n",
    "        output = model(img)\n",
    "        predshow(output)\n",
    "        ious.append(iou(output, gt))\n",
    "        #img_crops = to_crops(img)\n",
    "        #gt_crops = to_crops(gt)\n",
    "        #img_ious = []\n",
    "        #for img, gt in zip(img_crops, gt_crops):\n",
    "        #    img, gt = one_batch(img, gt)\n",
    "        #    output = model(img)\n",
    "        #    img_ious.append(iou(output, gt))\n",
    "        #ious.append(np.mean(img_ious))\n",
    "    if return_list:\n",
    "        return ious\n",
    "    return np.mean(ious)\n",
    "            \n",
    "# iou_val = calc_iou(model, np.random.permutation(val_set)[:5])\n",
    "\n",
    "# iou_val\n",
    "\n",
    "calc_loss(model, criterion, val_set[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (inria_aild-env)",
   "language": "python",
   "name": "inria_aild-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
