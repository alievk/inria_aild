{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam, RMSprop\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import os\n",
    "from time import time\n",
    "import random\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "from models.unet import MobilenetV2, Resnet34_upsample, Resnet50, InceptionResnetV2\n",
    "from loss import BCEDiceLoss, BCEJaccardLoss\n",
    "\n",
    "pjoin = join = os.path.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2018)\n",
    "np.random.seed(2018)\n",
    "torch.manual_seed(2018)\n",
    "torch.cuda.manual_seed_all(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.setNumThreads(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_ROOT = './data/AerialImageDataset_crop/train/'\n",
    "IMAGES_ROOT = TRAIN_ROOT + 'images'\n",
    "GT_ROOT = TRAIN_ROOT + 'gt'\n",
    "\n",
    "OUTPUT_DIR = './output/'\n",
    "\n",
    "IMAGE_SZ = 512\n",
    "ORIG_IMAGE_SZ = 1250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ch = 1\n",
    "\n",
    "criterion = BCEDiceLoss()\n",
    "\n",
    "model_class = Resnet34_upsample\n",
    "\n",
    "def get_model():\n",
    "    model = nn.DataParallel(model_class(out_ch, 3))\n",
    "    model.cuda()\n",
    "    return model\n",
    "\n",
    "if model_class in (MobilenetV2, Resnet34_upsample, Resnet50):\n",
    "    pretrained_settings = {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}\n",
    "elif model_class in (InceptionResnetV2,):\n",
    "    pretrained_settings = {'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_settings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_model = get_model().module"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# *** Resnet34_upsample ***\n",
    "# child module, million params\n",
    "# bottlenecks: 1.623\n",
    "# decoder_stages: 1.586\n",
    "# last_upsample: 0.018\n",
    "# final: 0.000\n",
    "# encoder_stages: 21.285\n",
    "# ---\n",
    "# total: 24.512\n",
    "\n",
    "_model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = torch.FloatTensor(1, 3, 256, 256).cuda()\n",
    "x = Variable(x)\n",
    "_model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Progress:\n",
    "    def __init__(self, total, desc, print_freq=0.1):\n",
    "        self.total = total\n",
    "        self.desc = desc\n",
    "        self.prog = 0\n",
    "        self.last_print = 0\n",
    "        self.postfix = ''\n",
    "        self.print_freq = print_freq\n",
    "                \n",
    "    def update(self, step):\n",
    "        self.prog += step\n",
    "        if self.prog == self.total:\n",
    "            self._print()\n",
    "        if self.last_print / self.total < self.print_freq \\\n",
    "            and (self.last_print + step) / self.total >= self.print_freq:\n",
    "            self._print()\n",
    "            self.last_print = 0\n",
    "        else:\n",
    "            self.last_print += step\n",
    "            \n",
    "    def _print(self):\n",
    "        prog = self.prog / self.total * 100\n",
    "        line = f'{self.desc} {prog:.2f}% {self.postfix}'\n",
    "        print(line)\n",
    "        \n",
    "    def set_postfix(self, postfix):\n",
    "        self.postfix = str(postfix)\n",
    "        \n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, log_filepath):\n",
    "        self.log = open(log_filepath, 'w')\n",
    "\n",
    "    def msg(self, msg, output_to_console=False, tq=None):\n",
    "        self.log.write('%s %s\\n' % (datetime.now().isoformat(), msg))\n",
    "        if output_to_console:\n",
    "            if tq is not None:\n",
    "                tq.write(msg)\n",
    "            else:\n",
    "                print(msg)\n",
    "                \n",
    "    def __del__(self):\n",
    "        self.log.close()\n",
    "        \n",
    "        \n",
    "def ocv_loader(fpath):\n",
    "    im = cv2.imread(fpath)\n",
    "    return im[:, :, ::-1].copy() if im is not None else None\n",
    "\n",
    "\n",
    "def make_dir(path, remove_exists=False):\n",
    "    if os.path.exists(path):\n",
    "        print(f'WARNING: {path} exists')\n",
    "        if remove_exists:\n",
    "            shutil.rmtree(path)\n",
    "    try:\n",
    "        os.mkdir(prediction_output_dir)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "        \n",
    "\n",
    "normalizer = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=pretrained_settings['mean'], std=pretrained_settings['std']),\n",
    "])\n",
    "\n",
    "\n",
    "class Denormalize:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = torch.FloatTensor(mean)\n",
    "        self.std = torch.FloatTensor(std)\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        img = img.permute(1, 2, 0)\n",
    "        return img * self.std + self.mean\n",
    "\n",
    "\n",
    "denormalizer = Denormalize(pretrained_settings['mean'], pretrained_settings['std'])\n",
    "\n",
    "\n",
    "def mask_overlay(image, mask, ch=0):\n",
    "    if not isinstance(mask, np.ndarray):\n",
    "        mask = mask.numpy()\n",
    "    if mask.ndim > 2:\n",
    "        mask = mask[ch,:,:]\n",
    "    if isinstance(image, str):\n",
    "        im = cv2.imread(image)\n",
    "        im = cv2.resize(im, (mask.shape[1], mask.shape[0]))\n",
    "    else:\n",
    "        im = denormalizer(image).numpy()\n",
    "        im = (im * 255).astype(np.uint8)\n",
    "    mask_ch = np.clip((255*mask) + im[...,0], 0, 255).astype(np.uint8)\n",
    "    return np.dstack((mask_ch,im[...,1],im[...,2]))\n",
    "\n",
    "\n",
    "def variable(x, volatile=False):\n",
    "    return Variable(x, volatile=volatile).cuda()\n",
    "    \n",
    "    \n",
    "def pad_image(img, padw, padh):\n",
    "    pads = [[0, padw], [0, padh]]\n",
    "    if img.ndim == 3:\n",
    "        pads += [[0, 0]]\n",
    "    return np.pad(img, pads, 'symmetric')\n",
    "\n",
    "\n",
    "def fix_input_size(img):\n",
    "    assert img.shape[0] == img.shape[1]\n",
    "    if model_class == UNetInceptionResnetV2:\n",
    "        pad = 31 - img.shape[0] % 32\n",
    "    else:\n",
    "        pad = 32 - img.shape[0] % 32\n",
    "    return pad_image(img, pad, pad)\n",
    "\n",
    "\n",
    "def prepare_data(img, mask):\n",
    "    img = normalizer(img)\n",
    "    mask = torch.from_numpy(mask / 255).unsqueeze(0).float()\n",
    "    return img, mask\n",
    "\n",
    "\n",
    "def prepare_img(img, eval_mode=True):\n",
    "    img = normalizer(img)\n",
    "    if len(img.shape) == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "    return variable(img, volatile=eval_mode)\n",
    "\n",
    "\n",
    "def output2pred(output, ch=0):\n",
    "    return torch.sigmoid(output).data[0].cpu().numpy()[ch]\n",
    "#     return torch.exp(pred).data[0].cpu().numpy()[ch]\n",
    "\n",
    "    \n",
    "##### VISUALIZE #####\n",
    "\n",
    "def imshow(im,figsz=(12,12),**kwargs):\n",
    "    plt.figure(figsize=figsz)\n",
    "    plt.imshow(im,**kwargs)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    \n",
    "def predshow(pred, ch=0):\n",
    "    imshow(pred2img(pred, ch),cmap='gray',vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCrop(object):\n",
    "    def __init__(self, size):\n",
    "        if isinstance(size, int):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        h, w = img.shape[:2]\n",
    "        tw, th = self.size\n",
    "        if w == tw and h == th:\n",
    "            return img, mask\n",
    "\n",
    "        if ((w - tw) > 0) and ((h - th) > 0):\n",
    "            x1 = np.random.randint(0, w - tw)\n",
    "            y1 = np.random.randint(0, h - th)\n",
    "        else:\n",
    "            x1 = 0\n",
    "            y1 = 0\n",
    "        img = img[y1:y1 + th, x1:x1 + tw]\n",
    "        if mask is not None:\n",
    "            mask = mask[y1:y1 + th, x1:x1 + tw]\n",
    "        return img, mask\n",
    "    \n",
    "\n",
    "class CenterCrop:\n",
    "    def __init__(self, size):\n",
    "        if isinstance(size, (list, tuple, np.ndarray)):\n",
    "            self.width, self.height = size\n",
    "        else:\n",
    "            self.width = self.height = size\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        h, w, c = img.shape\n",
    "        dx = (w-self.width)//2\n",
    "        dy = (h-self.height)//2\n",
    "\n",
    "        y1 = dy\n",
    "        y2 = y1 + self.height\n",
    "        x1 = dx\n",
    "        x2 = x1 + self.width\n",
    "        img = img[y1:y2, x1:x2]\n",
    "        if mask is not None:\n",
    "            mask = mask[y1:y2, x1:x2]\n",
    "        return img, mask\n",
    "    \n",
    "    \n",
    "# ### IMGAUG ###\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "    \n",
    "    \n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "# GEOMETRY\n",
    "ia_aug_geom_light = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),\n",
    "    sometimes(iaa.Affine(\n",
    "        rotate=(-45, 45),\n",
    "        order=1\n",
    "    ))\n",
    "], random_order=True)\n",
    "\n",
    "ia_aug_geom = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Flipud(0.5),\n",
    "    sometimes(iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "        rotate=(-45, 45),\n",
    "        shear=(-5, 5),\n",
    "        order=1\n",
    "    )),\n",
    "    sometimes(iaa.OneOf([\n",
    "        iaa.PiecewiseAffine(scale=(0.01, 0.02)),\n",
    "        iaa.PerspectiveTransform(scale=(0.01, 0.1))\n",
    "    ])),\n",
    "], random_order=True)\n",
    "\n",
    "# COLOR\n",
    "ia_aug_color_light = iaa.Sequential([\n",
    "    iaa.Add((-10, 10)),\n",
    "    iaa.ContrastNormalization((0.8, 1.2))\n",
    "], random_order=True)\n",
    " \n",
    "ia_aug_color = iaa.Sequential([\n",
    "    iaa.Add((-10, 10)),\n",
    "    sometimes(iaa.ContrastNormalization((0.8, 1.2))),\n",
    "    sometimes(iaa.AddToHueAndSaturation((-5, 5))),\n",
    "    sometimes(iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255))),\n",
    "    sometimes(iaa.Sharpen(alpha=(0, 0.5), lightness=(0.75, 1.5))),\n",
    "], random_order=True)\n",
    "\n",
    "\n",
    "def augment(img, mask):\n",
    "    aug_geom = ia_aug_geom.to_deterministic()\n",
    "    aug_color = ia_aug_color\n",
    "    img = aug_geom.augment_image(img)\n",
    "    img = aug_color.augment_image(img)\n",
    "    mask = aug_geom.augment_image(mask)\n",
    "    return img.copy(), mask.copy()\n",
    "\n",
    "def dummy_augment(img, mask):\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(cities=None):\n",
    "    def get_city_n(s):\n",
    "        for i, c in enumerate(s):\n",
    "            if c.isdigit():\n",
    "                break\n",
    "        return int(s[i:])\n",
    "\n",
    "    train_fnames, val_fnames = [], []\n",
    "    for fname in os.listdir(IMAGES_ROOT):\n",
    "        toks = fname[:-4].split('-')\n",
    "        if cities:\n",
    "            if not sum([x in toks[0] for x in cities]):\n",
    "                continue\n",
    "        city_n = '-'.join(toks[:-1])\n",
    "        part = toks[-1]\n",
    "        if get_city_n(city_n) < 6:\n",
    "            val_fnames.append(fname)\n",
    "        else:\n",
    "            train_fnames.append(fname)\n",
    "    return train_fnames, val_fnames\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, image_sz, image_list, augment=dummy_augment, epoch_mul=1):\n",
    "        self.image_sz = image_sz\n",
    "        self.image_list = image_list\n",
    "        self.epoch_mul = epoch_mul\n",
    "        self.augment = augment\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx %= len(self.image_list)            \n",
    "        image_path = pjoin(IMAGES_ROOT, self.image_list[idx])\n",
    "        gt_path = pjoin(GT_ROOT, self.image_list[idx])\n",
    "        img = ocv_loader(image_path)\n",
    "        gt = ocv_loader(gt_path)[:, :, 0]\n",
    "        assert img is not None\n",
    "        assert gt is not None\n",
    "        \n",
    "        pre_aug_sz = int(self.image_sz * 1.5)\n",
    "        img, gt = RandomCrop(pre_aug_sz)(img, gt)\n",
    "        img, gt = self.augment(img, gt)\n",
    "        img, gt = CenterCrop(self.image_sz)(img, gt)\n",
    "        img, gt = prepare_data(img, gt)\n",
    "        \n",
    "        return img, gt, image_path\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_list) * self.epoch_mul"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "t,v=train_val_split()\n",
    "len(t),len(v)\n",
    "t[:10],v[:10]\n",
    "ds=Dataset(IMAGE_SZ,v)\n",
    "for i in range(5):\n",
    "    img, gt, ipath=ds[i]\n",
    "    imshow(mask_overlay(img, gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_loss(model, criterion, file_names, return_list=False):\n",
    "#     model.eval()\n",
    "#     losses = []\n",
    "#     for i, fname in enumerate(file_names):\n",
    "#         image_path = pjoin(IMAGES_ROOT, fname)\n",
    "#         gt_path = pjoin(GT_ROOT, fname)\n",
    "#         img = ocv_loader(image_path)\n",
    "#         gt = ocv_loader(gt_path)[:, :, 0]\n",
    "#         img, gt = fix_shape(img), fix_shape(gt)\n",
    "#         img, gt = one_batch(img, gt)\n",
    "#         output = model(img)\n",
    "#         losses.append(criterion(output, gt).data[0])\n",
    "#     return np.mean(losses)\n",
    "\n",
    "\n",
    "class CyclicLR:\n",
    "    def __init__(self, start_lr, cycle_iters=20000, increase_1cycle=1.):\n",
    "        self.start_lr = start_lr\n",
    "        self.cycle_iters = cycle_iters\n",
    "        self.increase_1cycle = increase_1cycle\n",
    "        self.n_cycle = -1\n",
    "        \n",
    "    def calc_lr(self, it, callback=None):\n",
    "        cycle_it = it % self.cycle_iters\n",
    "        if cycle_it == 0:\n",
    "            self.n_cycle += 1\n",
    "            if it and callback:\n",
    "                callback(str(it))\n",
    "        x = .5 * (1 + np.cos(np.pi * cycle_it / (self.cycle_iters - 1)))\n",
    "        if self.n_cycle == 0:\n",
    "            x *= self.increase_1cycle\n",
    "        return x * self.start_lr\n",
    "\n",
    "\n",
    "class StepLR:\n",
    "    def __init__(self, start_lr, lr_decay_iters=20000, lr_decay=1./np.sqrt(10)):\n",
    "        self.start_lr = start_lr\n",
    "        self.lr_decay = lr_decay\n",
    "        self.lr_decay_iters = lr_decay_iters\n",
    "        self.lr_decay_n = 0\n",
    "        \n",
    "    def calc_lr(self, it, callback=None):\n",
    "        if it and it % self.lr_decay_iters == 0:\n",
    "            self.lr_decay_n += 1\n",
    "            if callback:\n",
    "                callback(str(it))\n",
    "        return self.start_lr * self.lr_decay ** self.lr_decay_n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lr_policy = CyclicLR(1e-4, 20)\n",
    "for i in range(100):\n",
    "    print(i, lr_policy.calc_lr(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(logger,\n",
    "          model,\n",
    "          output_dirpath,\n",
    "          optimizer,\n",
    "          num_iters,\n",
    "          criterion,\n",
    "          train_dataloader, \n",
    "          val_set,\n",
    "          lr_policy,\n",
    "          start_iter=None):\n",
    "    def save_snapshot(suffix):\n",
    "        model_dirpath = join(output_dirpath, f'model_{suffix}.pt')\n",
    "        torch.save(model.state_dict(), model_dirpath)\n",
    "        \n",
    "    def set_lr(lr):\n",
    "        for i, grp in enumerate(optimizer.param_groups):\n",
    "            grp['lr'] = lr\n",
    "        \n",
    "    save_each_iter = 20000\n",
    "    \n",
    "    logger.msg(str(model))\n",
    "    train_hist = defaultdict(list)\n",
    "    best_val_loss = float('inf')\n",
    "    it = 0 if start_iter is None else start_iter\n",
    "    try:\n",
    "        while it < num_iters:\n",
    "            model.train()\n",
    "            for inputs, targets, _ in train_dataloader:\n",
    "                inputs, targets = variable(inputs), variable(targets)\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "#                 bce_batch_weigth = targets.clone() * fg_weight\n",
    "#                 loss = criterion(outputs, targets, bce_batch_weight=bce_batch_weigth)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                lr = lr_policy.calc_lr(it, save_snapshot)\n",
    "                set_lr(lr)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss = loss.data[0]\n",
    "                if it % 20 == 0:\n",
    "                    logger.msg(f'Stage: train, iter: {it}, lr: {lr:.3e}, loss {train_loss:.6f}',\n",
    "                              output_to_console=True)\n",
    "                train_hist['train'].append((it, train_loss))\n",
    "                \n",
    "#                 if it % save_each_iter == 0:\n",
    "#                     save_snapshot(str(it))\n",
    "                \n",
    "#                 if it % 5000 == 0:\n",
    "#                 #if it and it % 5 == 0:\n",
    "#                     save_snapshot(it)\n",
    "                    \n",
    "#                     if it % 10000 == 0:\n",
    "#                     #if it and it % 10 == 0:\n",
    "#                         val_loss = calc_loss(model, criterion, val_set)\n",
    "#                         logger.msg(f'Stage: eval, iter: {it}, loss {val_loss:.6f}',\n",
    "#                                   output_to_console=True)\n",
    "#                         train_hist['val'].append((it, val_loss))\n",
    "#                         if val_loss < best_val_loss:\n",
    "#                             best_val_loss = val_loss\n",
    "#                             best_model_dirpath = join(output_dirpath, 'model_best.pt')\n",
    "#                             shutil.copy(model_dirpath, best_model_dirpath)\n",
    "\n",
    "                        \n",
    "                it += 1\n",
    "                if it == num_iters:\n",
    "                    break\n",
    "    except KeyboardInterrupt:\n",
    "        torch.save(model.state_dict(), model_dirpath)\n",
    "        print('kb interrupt')\n",
    "    return train_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 25 00:02:47 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 396.26                 Driver Version: 396.26                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:17:00.0 Off |                  N/A |\r\n",
      "| 22%   57C    P0    60W / 250W |      0MiB / 11178MiB |      1%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:65:00.0 Off |                  N/A |\r\n",
      "| 29%   55C    P8    19W / 250W |   6129MiB / 11175MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1     11994      C   /home/aa/comps/inria_aild/.env/bin/python   6119MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epoch_mul = 1\n",
    "\n",
    "# >>> CHECK INCLUDED CITIES <<<\n",
    "# cities = ['vienna']\n",
    "cities = []\n",
    "train_set, val_set = train_val_split(cities)\n",
    "\n",
    "ds_train = Dataset(IMAGE_SZ, train_set, augment=augment, epoch_mul=epoch_mul)\n",
    "ds_valid = Dataset(IMAGE_SZ, val_set, epoch_mul=epoch_mul)\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "dl_valid = DataLoader(ds_valid, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2480, 400)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'res50_i512_ch128_freeze_encoder'\n",
    "experiment_dir = OUTPUT_DIR + experiment_name\n",
    "#!rm -r {experiment_dir}\n",
    "!mkdir -p {experiment_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 0, lr: 1.000e-04, loss 10.072884\n",
      "Stage: train, iter: 20, lr: 1.000e-04, loss 0.870269\n",
      "Stage: train, iter: 40, lr: 1.000e-04, loss 0.509665\n",
      "Stage: train, iter: 60, lr: 1.000e-04, loss 0.555592\n",
      "Stage: train, iter: 80, lr: 1.000e-04, loss 0.579035\n",
      "Stage: train, iter: 100, lr: 1.000e-04, loss 0.398833\n",
      "Stage: train, iter: 120, lr: 1.000e-04, loss 0.451560\n",
      "Stage: train, iter: 140, lr: 1.000e-04, loss 0.462909\n",
      "Stage: train, iter: 160, lr: 1.000e-04, loss 0.375812\n",
      "Stage: train, iter: 180, lr: 1.000e-04, loss 0.447462\n",
      "Stage: train, iter: 200, lr: 1.000e-04, loss 0.378507\n",
      "Stage: train, iter: 220, lr: 1.000e-04, loss 0.357986\n",
      "Stage: train, iter: 240, lr: 1.000e-04, loss 0.633157\n",
      "Stage: train, iter: 260, lr: 1.000e-04, loss 0.409857\n",
      "Stage: train, iter: 280, lr: 1.000e-04, loss 0.438029\n",
      "Stage: train, iter: 300, lr: 1.000e-04, loss 0.417497\n",
      "Stage: train, iter: 320, lr: 1.000e-04, loss 0.306099\n",
      "Stage: train, iter: 340, lr: 1.000e-04, loss 0.268405\n",
      "Stage: train, iter: 360, lr: 1.000e-04, loss 0.371721\n",
      "Stage: train, iter: 380, lr: 1.000e-04, loss 0.354468\n",
      "Stage: train, iter: 400, lr: 1.000e-04, loss 0.311229\n",
      "Stage: train, iter: 420, lr: 1.000e-04, loss 0.340247\n",
      "Stage: train, iter: 440, lr: 1.000e-04, loss 0.519180\n",
      "Stage: train, iter: 460, lr: 1.000e-04, loss 0.323747\n",
      "Stage: train, iter: 480, lr: 1.000e-04, loss 0.378258\n",
      "Stage: train, iter: 500, lr: 1.000e-04, loss 0.378752\n",
      "Stage: train, iter: 520, lr: 1.000e-04, loss 0.372808\n",
      "Stage: train, iter: 540, lr: 1.000e-04, loss 0.520710\n",
      "Stage: train, iter: 560, lr: 1.000e-04, loss 0.365734\n",
      "Stage: train, iter: 580, lr: 1.000e-04, loss 0.339360\n",
      "Stage: train, iter: 600, lr: 1.000e-04, loss 0.352022\n",
      "Stage: train, iter: 620, lr: 1.000e-04, loss 0.324982\n",
      "Stage: train, iter: 640, lr: 1.000e-04, loss 0.257166\n",
      "Stage: train, iter: 660, lr: 1.000e-04, loss 0.294227\n",
      "Stage: train, iter: 680, lr: 1.000e-04, loss 0.347023\n",
      "Stage: train, iter: 700, lr: 1.000e-04, loss 0.294959\n",
      "Stage: train, iter: 720, lr: 1.000e-04, loss 0.311113\n",
      "Stage: train, iter: 740, lr: 1.000e-04, loss 0.318870\n",
      "Stage: train, iter: 760, lr: 1.000e-04, loss 0.259851\n",
      "Stage: train, iter: 780, lr: 1.000e-04, loss 0.313252\n",
      "Stage: train, iter: 800, lr: 1.000e-04, loss 0.346333\n",
      "Stage: train, iter: 820, lr: 1.000e-04, loss 0.308309\n",
      "Stage: train, iter: 840, lr: 1.000e-04, loss 0.356170\n",
      "Stage: train, iter: 860, lr: 1.000e-04, loss 0.269608\n",
      "Stage: train, iter: 880, lr: 1.000e-04, loss 0.276365\n",
      "Stage: train, iter: 900, lr: 1.000e-04, loss 0.316798\n",
      "Stage: train, iter: 920, lr: 1.000e-04, loss 0.283841\n",
      "Stage: train, iter: 940, lr: 1.000e-04, loss 0.243066\n",
      "Stage: train, iter: 960, lr: 1.000e-04, loss 0.276866\n",
      "Stage: train, iter: 980, lr: 1.000e-04, loss 0.319309\n",
      "Stage: train, iter: 1000, lr: 1.000e-04, loss 0.245697\n",
      "Stage: train, iter: 1020, lr: 1.000e-04, loss 0.311890\n",
      "Stage: train, iter: 1040, lr: 1.000e-04, loss 0.443535\n",
      "Stage: train, iter: 1060, lr: 1.000e-04, loss 0.306870\n",
      "Stage: train, iter: 1080, lr: 1.000e-04, loss 0.261198\n",
      "Stage: train, iter: 1100, lr: 1.000e-04, loss 0.261647\n",
      "Stage: train, iter: 1120, lr: 1.000e-04, loss 0.344553\n",
      "Stage: train, iter: 1140, lr: 1.000e-04, loss 0.248108\n",
      "Stage: train, iter: 1160, lr: 1.000e-04, loss 0.384521\n",
      "Stage: train, iter: 1180, lr: 1.000e-04, loss 0.307779\n",
      "Stage: train, iter: 1200, lr: 1.000e-04, loss 0.251054\n",
      "Stage: train, iter: 1220, lr: 1.000e-04, loss 0.399048\n",
      "Stage: train, iter: 1240, lr: 1.000e-04, loss 0.307996\n",
      "Stage: train, iter: 1260, lr: 1.000e-04, loss 0.260692\n",
      "Stage: train, iter: 1280, lr: 1.000e-04, loss 0.332348\n",
      "Stage: train, iter: 1300, lr: 1.000e-04, loss 0.220876\n",
      "Stage: train, iter: 1320, lr: 1.000e-04, loss 0.282344\n",
      "Stage: train, iter: 1340, lr: 1.000e-04, loss 0.302546\n",
      "Stage: train, iter: 1360, lr: 1.000e-04, loss 0.289058\n",
      "Stage: train, iter: 1380, lr: 1.000e-04, loss 0.274838\n",
      "Stage: train, iter: 1400, lr: 1.000e-04, loss 0.314091\n",
      "Stage: train, iter: 1420, lr: 1.000e-04, loss 0.206824\n",
      "Stage: train, iter: 1440, lr: 1.000e-04, loss 0.234266\n",
      "Stage: train, iter: 1460, lr: 1.000e-04, loss 0.325341\n",
      "Stage: train, iter: 1480, lr: 1.000e-04, loss 0.247882\n",
      "Stage: train, iter: 1500, lr: 1.000e-04, loss 0.301491\n",
      "Stage: train, iter: 1520, lr: 1.000e-04, loss 0.323145\n",
      "Stage: train, iter: 1540, lr: 1.000e-04, loss 0.305813\n",
      "Stage: train, iter: 1560, lr: 1.000e-04, loss 0.337577\n",
      "Stage: train, iter: 1580, lr: 1.000e-04, loss 0.274781\n",
      "Stage: train, iter: 1600, lr: 1.000e-04, loss 0.239734\n",
      "Stage: train, iter: 1620, lr: 1.000e-04, loss 0.295811\n",
      "Stage: train, iter: 1640, lr: 1.000e-04, loss 0.321988\n",
      "Stage: train, iter: 1660, lr: 1.000e-04, loss 0.352498\n",
      "Stage: train, iter: 1680, lr: 1.000e-04, loss 0.626829\n",
      "Stage: train, iter: 1700, lr: 1.000e-04, loss 0.301475\n",
      "Stage: train, iter: 1720, lr: 1.000e-04, loss 0.281092\n",
      "Stage: train, iter: 1740, lr: 1.000e-04, loss 0.269504\n",
      "Stage: train, iter: 1760, lr: 1.000e-04, loss 0.265935\n",
      "Stage: train, iter: 1780, lr: 1.000e-04, loss 0.262063\n",
      "Stage: train, iter: 1800, lr: 1.000e-04, loss 0.309618\n",
      "Stage: train, iter: 1820, lr: 1.000e-04, loss 0.248206\n",
      "Stage: train, iter: 1840, lr: 1.000e-04, loss 0.270831\n",
      "Stage: train, iter: 1860, lr: 1.000e-04, loss 0.248407\n",
      "Stage: train, iter: 1880, lr: 1.000e-04, loss 0.229040\n",
      "Stage: train, iter: 1900, lr: 1.000e-04, loss 0.286594\n",
      "Stage: train, iter: 1920, lr: 1.000e-04, loss 0.491174\n",
      "Stage: train, iter: 1940, lr: 1.000e-04, loss 0.367601\n",
      "Stage: train, iter: 1960, lr: 1.000e-04, loss 0.388175\n",
      "Stage: train, iter: 1980, lr: 1.000e-04, loss 0.376230\n",
      "Stage: train, iter: 2000, lr: 1.000e-04, loss 0.298185\n",
      "Stage: train, iter: 2020, lr: 1.000e-04, loss 0.248647\n",
      "Stage: train, iter: 2040, lr: 1.000e-04, loss 0.255522\n",
      "Stage: train, iter: 2060, lr: 1.000e-04, loss 0.230291\n",
      "Stage: train, iter: 2080, lr: 1.000e-04, loss 0.237844\n",
      "Stage: train, iter: 2100, lr: 1.000e-04, loss 0.287623\n",
      "Stage: train, iter: 2120, lr: 1.000e-04, loss 0.307546\n",
      "Stage: train, iter: 2140, lr: 1.000e-04, loss 0.275797\n",
      "Stage: train, iter: 2160, lr: 1.000e-04, loss 0.278112\n",
      "Stage: train, iter: 2180, lr: 1.000e-04, loss 0.428461\n",
      "Stage: train, iter: 2200, lr: 1.000e-04, loss 0.283722\n",
      "Stage: train, iter: 2220, lr: 1.000e-04, loss 0.242377\n",
      "Stage: train, iter: 2240, lr: 1.000e-04, loss 0.270206\n",
      "Stage: train, iter: 2260, lr: 1.000e-04, loss 0.297189\n",
      "Stage: train, iter: 2280, lr: 1.000e-04, loss 0.387616\n",
      "Stage: train, iter: 2300, lr: 1.000e-04, loss 0.265263\n",
      "Stage: train, iter: 2320, lr: 1.000e-04, loss 0.229736\n",
      "Stage: train, iter: 2340, lr: 1.000e-04, loss 0.279118\n",
      "Stage: train, iter: 2360, lr: 1.000e-04, loss 0.274750\n",
      "Stage: train, iter: 2380, lr: 1.000e-04, loss 0.244264\n",
      "Stage: train, iter: 2400, lr: 1.000e-04, loss 0.307389\n",
      "Stage: train, iter: 2420, lr: 1.000e-04, loss 0.272163\n",
      "Stage: train, iter: 2440, lr: 1.000e-04, loss 0.231557\n",
      "Stage: train, iter: 2460, lr: 1.000e-04, loss 0.265616\n",
      "Stage: train, iter: 2480, lr: 1.000e-04, loss 0.248568\n",
      "Stage: train, iter: 2500, lr: 1.000e-04, loss 0.230817\n",
      "Stage: train, iter: 2520, lr: 1.000e-04, loss 0.220092\n",
      "Stage: train, iter: 2540, lr: 1.000e-04, loss 0.253381\n",
      "Stage: train, iter: 2560, lr: 1.000e-04, loss 0.376637\n",
      "Stage: train, iter: 2580, lr: 1.000e-04, loss 0.230595\n",
      "Stage: train, iter: 2600, lr: 1.000e-04, loss 0.272282\n",
      "Stage: train, iter: 2620, lr: 1.000e-04, loss 0.203725\n",
      "Stage: train, iter: 2640, lr: 1.000e-04, loss 0.212911\n",
      "Stage: train, iter: 2660, lr: 1.000e-04, loss 0.375958\n",
      "Stage: train, iter: 2680, lr: 1.000e-04, loss 0.285925\n",
      "Stage: train, iter: 2700, lr: 1.000e-04, loss 0.241227\n",
      "Stage: train, iter: 2720, lr: 1.000e-04, loss 0.280102\n",
      "Stage: train, iter: 2740, lr: 1.000e-04, loss 0.242507\n",
      "Stage: train, iter: 2760, lr: 1.000e-04, loss 0.236566\n",
      "Stage: train, iter: 2780, lr: 1.000e-04, loss 0.284527\n",
      "Stage: train, iter: 2800, lr: 1.000e-04, loss 0.216761\n",
      "Stage: train, iter: 2820, lr: 1.000e-04, loss 0.225494\n",
      "Stage: train, iter: 2840, lr: 1.000e-04, loss 0.254429\n",
      "Stage: train, iter: 2860, lr: 1.000e-04, loss 0.203719\n",
      "Stage: train, iter: 2880, lr: 1.000e-04, loss 0.378149\n",
      "Stage: train, iter: 2900, lr: 1.000e-04, loss 0.179672\n",
      "Stage: train, iter: 2920, lr: 1.000e-04, loss 0.263874\n",
      "Stage: train, iter: 2940, lr: 1.000e-04, loss 0.290468\n",
      "Stage: train, iter: 2960, lr: 1.000e-04, loss 0.283925\n",
      "Stage: train, iter: 2980, lr: 1.000e-04, loss 0.211068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 3000, lr: 1.000e-04, loss 0.275719\n",
      "Stage: train, iter: 3020, lr: 1.000e-04, loss 0.326566\n",
      "Stage: train, iter: 3040, lr: 1.000e-04, loss 0.244271\n",
      "Stage: train, iter: 3060, lr: 1.000e-04, loss 0.280256\n",
      "Stage: train, iter: 3080, lr: 1.000e-04, loss 0.199193\n",
      "Stage: train, iter: 3100, lr: 1.000e-04, loss 0.267195\n",
      "Stage: train, iter: 3120, lr: 1.000e-04, loss 0.247157\n",
      "Stage: train, iter: 3140, lr: 1.000e-04, loss 0.326304\n",
      "Stage: train, iter: 3160, lr: 1.000e-04, loss 0.217323\n",
      "Stage: train, iter: 3180, lr: 1.000e-04, loss 0.315515\n",
      "Stage: train, iter: 3200, lr: 1.000e-04, loss 0.198533\n",
      "Stage: train, iter: 3220, lr: 1.000e-04, loss 0.249973\n",
      "Stage: train, iter: 3240, lr: 1.000e-04, loss 0.246101\n",
      "Stage: train, iter: 3260, lr: 1.000e-04, loss 0.280291\n",
      "Stage: train, iter: 3280, lr: 1.000e-04, loss 0.303512\n",
      "Stage: train, iter: 3300, lr: 1.000e-04, loss 0.224586\n",
      "Stage: train, iter: 3320, lr: 1.000e-04, loss 0.254621\n",
      "Stage: train, iter: 3340, lr: 1.000e-04, loss 0.258605\n",
      "Stage: train, iter: 3360, lr: 1.000e-04, loss 0.247274\n",
      "Stage: train, iter: 3380, lr: 1.000e-04, loss 0.203255\n",
      "Stage: train, iter: 3400, lr: 1.000e-04, loss 0.297599\n",
      "Stage: train, iter: 3420, lr: 1.000e-04, loss 0.314115\n",
      "Stage: train, iter: 3440, lr: 1.000e-04, loss 0.457509\n",
      "Stage: train, iter: 3460, lr: 1.000e-04, loss 0.262147\n",
      "Stage: train, iter: 3480, lr: 1.000e-04, loss 0.267015\n",
      "Stage: train, iter: 3500, lr: 1.000e-04, loss 0.232073\n",
      "Stage: train, iter: 3520, lr: 1.000e-04, loss 0.190297\n",
      "Stage: train, iter: 3540, lr: 1.000e-04, loss 0.246229\n",
      "Stage: train, iter: 3560, lr: 1.000e-04, loss 0.211523\n",
      "Stage: train, iter: 3580, lr: 1.000e-04, loss 0.248583\n",
      "Stage: train, iter: 3600, lr: 1.000e-04, loss 0.243123\n",
      "Stage: train, iter: 3620, lr: 1.000e-04, loss 0.241588\n",
      "Stage: train, iter: 3640, lr: 1.000e-04, loss 0.233346\n",
      "Stage: train, iter: 3660, lr: 1.000e-04, loss 0.244158\n",
      "Stage: train, iter: 3680, lr: 1.000e-04, loss 0.219953\n",
      "Stage: train, iter: 3700, lr: 1.000e-04, loss 0.213150\n",
      "Stage: train, iter: 3720, lr: 1.000e-04, loss 0.270955\n",
      "Stage: train, iter: 3740, lr: 1.000e-04, loss 0.215499\n",
      "Stage: train, iter: 3760, lr: 1.000e-04, loss 0.196466\n",
      "Stage: train, iter: 3780, lr: 1.000e-04, loss 0.226490\n",
      "Stage: train, iter: 3800, lr: 1.000e-04, loss 0.232985\n",
      "Stage: train, iter: 3820, lr: 1.000e-04, loss 0.211283\n",
      "Stage: train, iter: 3840, lr: 1.000e-04, loss 0.237825\n",
      "Stage: train, iter: 3860, lr: 1.000e-04, loss 0.229000\n",
      "Stage: train, iter: 3880, lr: 1.000e-04, loss 0.222290\n",
      "Stage: train, iter: 3900, lr: 1.000e-04, loss 0.244415\n",
      "Stage: train, iter: 3920, lr: 1.000e-04, loss 0.270926\n",
      "Stage: train, iter: 3940, lr: 1.000e-04, loss 0.211622\n",
      "Stage: train, iter: 3960, lr: 1.000e-04, loss 0.252480\n",
      "Stage: train, iter: 3980, lr: 1.000e-04, loss 0.222682\n",
      "Stage: train, iter: 4000, lr: 1.000e-04, loss 0.261380\n",
      "Stage: train, iter: 4020, lr: 1.000e-04, loss 0.166541\n",
      "Stage: train, iter: 4040, lr: 1.000e-04, loss 0.223462\n",
      "Stage: train, iter: 4060, lr: 1.000e-04, loss 0.219434\n",
      "Stage: train, iter: 4080, lr: 1.000e-04, loss 0.187262\n",
      "Stage: train, iter: 4100, lr: 1.000e-04, loss 0.225609\n",
      "Stage: train, iter: 4120, lr: 1.000e-04, loss 0.173503\n",
      "Stage: train, iter: 4140, lr: 1.000e-04, loss 0.258518\n",
      "Stage: train, iter: 4160, lr: 1.000e-04, loss 0.254291\n",
      "Stage: train, iter: 4180, lr: 1.000e-04, loss 0.195956\n",
      "Stage: train, iter: 4200, lr: 1.000e-04, loss 0.229897\n",
      "Stage: train, iter: 4220, lr: 1.000e-04, loss 0.202649\n",
      "Stage: train, iter: 4240, lr: 1.000e-04, loss 0.297070\n",
      "Stage: train, iter: 4260, lr: 1.000e-04, loss 0.259839\n",
      "Stage: train, iter: 4280, lr: 1.000e-04, loss 0.168647\n",
      "Stage: train, iter: 4300, lr: 1.000e-04, loss 0.392096\n",
      "Stage: train, iter: 4320, lr: 1.000e-04, loss 0.308849\n",
      "Stage: train, iter: 4340, lr: 1.000e-04, loss 0.226254\n",
      "Stage: train, iter: 4360, lr: 1.000e-04, loss 0.195859\n",
      "Stage: train, iter: 4380, lr: 1.000e-04, loss 0.171267\n",
      "Stage: train, iter: 4400, lr: 1.000e-04, loss 0.243879\n",
      "Stage: train, iter: 4420, lr: 1.000e-04, loss 0.249551\n",
      "Stage: train, iter: 4440, lr: 1.000e-04, loss 0.218182\n",
      "Stage: train, iter: 4460, lr: 1.000e-04, loss 0.227804\n",
      "Stage: train, iter: 4480, lr: 1.000e-04, loss 0.258666\n",
      "Stage: train, iter: 4500, lr: 1.000e-04, loss 0.219229\n",
      "Stage: train, iter: 4520, lr: 1.000e-04, loss 0.176416\n",
      "Stage: train, iter: 4540, lr: 1.000e-04, loss 0.254756\n",
      "Stage: train, iter: 4560, lr: 1.000e-04, loss 0.235896\n",
      "Stage: train, iter: 4580, lr: 1.000e-04, loss 0.171593\n",
      "Stage: train, iter: 4600, lr: 1.000e-04, loss 0.179692\n",
      "Stage: train, iter: 4620, lr: 1.000e-04, loss 0.211683\n",
      "Stage: train, iter: 4640, lr: 1.000e-04, loss 0.275466\n",
      "Stage: train, iter: 4660, lr: 1.000e-04, loss 0.285704\n",
      "Stage: train, iter: 4680, lr: 1.000e-04, loss 0.276447\n",
      "Stage: train, iter: 4700, lr: 1.000e-04, loss 0.247725\n",
      "Stage: train, iter: 4720, lr: 1.000e-04, loss 0.214435\n",
      "Stage: train, iter: 4740, lr: 1.000e-04, loss 0.181696\n",
      "Stage: train, iter: 4760, lr: 1.000e-04, loss 0.276467\n",
      "Stage: train, iter: 4780, lr: 1.000e-04, loss 0.285012\n",
      "Stage: train, iter: 4800, lr: 1.000e-04, loss 0.205610\n",
      "Stage: train, iter: 4820, lr: 1.000e-04, loss 0.174550\n",
      "Stage: train, iter: 4840, lr: 1.000e-04, loss 0.188512\n",
      "Stage: train, iter: 4860, lr: 1.000e-04, loss 0.234870\n",
      "Stage: train, iter: 4880, lr: 1.000e-04, loss 0.224981\n",
      "Stage: train, iter: 4900, lr: 1.000e-04, loss 0.243134\n",
      "Stage: train, iter: 4920, lr: 1.000e-04, loss 0.225037\n",
      "Stage: train, iter: 4940, lr: 1.000e-04, loss 0.235964\n",
      "Stage: train, iter: 4960, lr: 1.000e-04, loss 0.257533\n",
      "Stage: train, iter: 4980, lr: 1.000e-04, loss 0.250963\n",
      "Stage: train, iter: 5000, lr: 1.000e-04, loss 0.210017\n",
      "Stage: train, iter: 5020, lr: 1.000e-04, loss 0.229989\n",
      "Stage: train, iter: 5040, lr: 1.000e-04, loss 0.359739\n",
      "Stage: train, iter: 5060, lr: 1.000e-04, loss 0.205834\n",
      "Stage: train, iter: 5080, lr: 1.000e-04, loss 0.261095\n",
      "Stage: train, iter: 5100, lr: 1.000e-04, loss 0.168303\n",
      "Stage: train, iter: 5120, lr: 1.000e-04, loss 0.212671\n",
      "Stage: train, iter: 5140, lr: 1.000e-04, loss 0.245437\n",
      "Stage: train, iter: 5160, lr: 1.000e-04, loss 0.234790\n",
      "Stage: train, iter: 5180, lr: 1.000e-04, loss 0.224353\n",
      "Stage: train, iter: 5200, lr: 1.000e-04, loss 0.266584\n",
      "Stage: train, iter: 5220, lr: 1.000e-04, loss 0.191366\n",
      "Stage: train, iter: 5240, lr: 1.000e-04, loss 0.208421\n",
      "Stage: train, iter: 5260, lr: 1.000e-04, loss 0.254180\n",
      "Stage: train, iter: 5280, lr: 1.000e-04, loss 0.240133\n",
      "Stage: train, iter: 5300, lr: 1.000e-04, loss 0.175784\n",
      "Stage: train, iter: 5320, lr: 1.000e-04, loss 0.185596\n",
      "Stage: train, iter: 5340, lr: 1.000e-04, loss 0.312889\n",
      "Stage: train, iter: 5360, lr: 1.000e-04, loss 0.173570\n",
      "Stage: train, iter: 5380, lr: 1.000e-04, loss 0.240016\n",
      "Stage: train, iter: 5400, lr: 1.000e-04, loss 0.201960\n",
      "Stage: train, iter: 5420, lr: 1.000e-04, loss 0.216336\n",
      "Stage: train, iter: 5440, lr: 1.000e-04, loss 0.173951\n",
      "Stage: train, iter: 5460, lr: 1.000e-04, loss 0.205714\n",
      "Stage: train, iter: 5480, lr: 1.000e-04, loss 0.162303\n",
      "Stage: train, iter: 5500, lr: 1.000e-04, loss 0.150781\n",
      "Stage: train, iter: 5520, lr: 1.000e-04, loss 0.205051\n",
      "Stage: train, iter: 5540, lr: 1.000e-04, loss 0.242458\n",
      "Stage: train, iter: 5560, lr: 1.000e-04, loss 0.167340\n",
      "Stage: train, iter: 5580, lr: 1.000e-04, loss 0.226610\n",
      "Stage: train, iter: 5600, lr: 1.000e-04, loss 0.201817\n",
      "Stage: train, iter: 5620, lr: 1.000e-04, loss 0.201789\n",
      "Stage: train, iter: 5640, lr: 1.000e-04, loss 0.341702\n",
      "Stage: train, iter: 5660, lr: 1.000e-04, loss 0.115267\n",
      "Stage: train, iter: 5680, lr: 1.000e-04, loss 0.191120\n",
      "Stage: train, iter: 5700, lr: 1.000e-04, loss 0.216117\n",
      "Stage: train, iter: 5720, lr: 1.000e-04, loss 0.197531\n",
      "Stage: train, iter: 5740, lr: 1.000e-04, loss 0.247942\n",
      "Stage: train, iter: 5760, lr: 1.000e-04, loss 0.187882\n",
      "Stage: train, iter: 5780, lr: 1.000e-04, loss 0.218184\n",
      "Stage: train, iter: 5800, lr: 1.000e-04, loss 0.239687\n",
      "Stage: train, iter: 5820, lr: 1.000e-04, loss 0.202074\n",
      "Stage: train, iter: 5840, lr: 1.000e-04, loss 0.319409\n",
      "Stage: train, iter: 5860, lr: 1.000e-04, loss 0.201254\n",
      "Stage: train, iter: 5880, lr: 1.000e-04, loss 0.226178\n",
      "Stage: train, iter: 5900, lr: 1.000e-04, loss 0.234954\n",
      "Stage: train, iter: 5920, lr: 1.000e-04, loss 0.155051\n",
      "Stage: train, iter: 5940, lr: 1.000e-04, loss 0.170653\n",
      "Stage: train, iter: 5960, lr: 1.000e-04, loss 0.224534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 5980, lr: 1.000e-04, loss 0.157280\n",
      "Stage: train, iter: 6000, lr: 1.000e-04, loss 0.177862\n",
      "Stage: train, iter: 6020, lr: 1.000e-04, loss 0.160968\n",
      "Stage: train, iter: 6040, lr: 1.000e-04, loss 0.231953\n",
      "Stage: train, iter: 6060, lr: 1.000e-04, loss 0.196589\n",
      "Stage: train, iter: 6080, lr: 1.000e-04, loss 0.330248\n",
      "Stage: train, iter: 6100, lr: 1.000e-04, loss 0.196944\n",
      "Stage: train, iter: 6120, lr: 1.000e-04, loss 0.164692\n",
      "Stage: train, iter: 6140, lr: 1.000e-04, loss 0.198198\n",
      "Stage: train, iter: 6160, lr: 1.000e-04, loss 0.223802\n",
      "Stage: train, iter: 6180, lr: 1.000e-04, loss 0.260657\n",
      "Stage: train, iter: 6200, lr: 1.000e-04, loss 0.235499\n",
      "Stage: train, iter: 6220, lr: 1.000e-04, loss 0.191748\n",
      "Stage: train, iter: 6240, lr: 1.000e-04, loss 0.218095\n",
      "Stage: train, iter: 6260, lr: 1.000e-04, loss 0.161784\n",
      "Stage: train, iter: 6280, lr: 1.000e-04, loss 0.250515\n",
      "Stage: train, iter: 6300, lr: 1.000e-04, loss 0.205006\n",
      "Stage: train, iter: 6320, lr: 1.000e-04, loss 0.322128\n",
      "Stage: train, iter: 6340, lr: 1.000e-04, loss 0.215978\n",
      "Stage: train, iter: 6360, lr: 1.000e-04, loss 0.268543\n",
      "Stage: train, iter: 6380, lr: 1.000e-04, loss 0.237408\n",
      "Stage: train, iter: 6400, lr: 1.000e-04, loss 0.203150\n",
      "Stage: train, iter: 6420, lr: 1.000e-04, loss 0.164066\n",
      "Stage: train, iter: 6440, lr: 1.000e-04, loss 0.321952\n",
      "Stage: train, iter: 6460, lr: 1.000e-04, loss 0.150870\n",
      "Stage: train, iter: 6480, lr: 1.000e-04, loss 0.181652\n",
      "Stage: train, iter: 6500, lr: 1.000e-04, loss 0.213456\n",
      "Stage: train, iter: 6520, lr: 1.000e-04, loss 0.239506\n",
      "Stage: train, iter: 6540, lr: 1.000e-04, loss 0.212421\n",
      "Stage: train, iter: 6560, lr: 1.000e-04, loss 0.256599\n",
      "Stage: train, iter: 6580, lr: 1.000e-04, loss 0.171098\n",
      "Stage: train, iter: 6600, lr: 1.000e-04, loss 0.266648\n",
      "Stage: train, iter: 6620, lr: 1.000e-04, loss 0.330812\n",
      "Stage: train, iter: 6640, lr: 1.000e-04, loss 0.222612\n",
      "Stage: train, iter: 6660, lr: 1.000e-04, loss 0.151564\n",
      "Stage: train, iter: 6680, lr: 1.000e-04, loss 0.229179\n",
      "Stage: train, iter: 6700, lr: 1.000e-04, loss 0.196657\n",
      "Stage: train, iter: 6720, lr: 1.000e-04, loss 0.275710\n",
      "Stage: train, iter: 6740, lr: 1.000e-04, loss 0.208778\n",
      "Stage: train, iter: 6760, lr: 1.000e-04, loss 0.155330\n",
      "Stage: train, iter: 6780, lr: 1.000e-04, loss 0.191643\n",
      "Stage: train, iter: 6800, lr: 1.000e-04, loss 0.248668\n",
      "Stage: train, iter: 6820, lr: 1.000e-04, loss 0.173032\n",
      "Stage: train, iter: 6840, lr: 1.000e-04, loss 0.207252\n",
      "Stage: train, iter: 6860, lr: 1.000e-04, loss 0.227341\n",
      "Stage: train, iter: 6880, lr: 1.000e-04, loss 0.237220\n",
      "Stage: train, iter: 6900, lr: 1.000e-04, loss 0.155423\n",
      "Stage: train, iter: 6920, lr: 1.000e-04, loss 0.309567\n",
      "Stage: train, iter: 6940, lr: 1.000e-04, loss 0.236280\n",
      "Stage: train, iter: 6960, lr: 1.000e-04, loss 0.160737\n",
      "Stage: train, iter: 6980, lr: 1.000e-04, loss 0.177323\n",
      "Stage: train, iter: 7000, lr: 1.000e-04, loss 0.143068\n",
      "Stage: train, iter: 7020, lr: 1.000e-04, loss 0.202102\n",
      "Stage: train, iter: 7040, lr: 1.000e-04, loss 0.170110\n",
      "Stage: train, iter: 7060, lr: 1.000e-04, loss 0.207612\n",
      "Stage: train, iter: 7080, lr: 1.000e-04, loss 0.188149\n",
      "Stage: train, iter: 7100, lr: 1.000e-04, loss 0.309391\n",
      "Stage: train, iter: 7120, lr: 1.000e-04, loss 0.177946\n",
      "Stage: train, iter: 7140, lr: 1.000e-04, loss 0.243509\n",
      "Stage: train, iter: 7160, lr: 1.000e-04, loss 0.276153\n",
      "Stage: train, iter: 7180, lr: 1.000e-04, loss 0.243544\n",
      "Stage: train, iter: 7200, lr: 1.000e-04, loss 0.231868\n",
      "Stage: train, iter: 7220, lr: 1.000e-04, loss 0.204855\n",
      "Stage: train, iter: 7240, lr: 1.000e-04, loss 0.188381\n",
      "Stage: train, iter: 7260, lr: 1.000e-04, loss 0.141926\n",
      "Stage: train, iter: 7280, lr: 1.000e-04, loss 0.193759\n",
      "Stage: train, iter: 7300, lr: 1.000e-04, loss 0.241275\n",
      "Stage: train, iter: 7320, lr: 1.000e-04, loss 0.200002\n",
      "Stage: train, iter: 7340, lr: 1.000e-04, loss 0.180185\n",
      "Stage: train, iter: 7360, lr: 1.000e-04, loss 0.193130\n",
      "Stage: train, iter: 7380, lr: 1.000e-04, loss 0.216844\n",
      "Stage: train, iter: 7400, lr: 1.000e-04, loss 0.222624\n",
      "Stage: train, iter: 7420, lr: 1.000e-04, loss 0.258402\n",
      "Stage: train, iter: 7440, lr: 1.000e-04, loss 0.265595\n",
      "Stage: train, iter: 7460, lr: 1.000e-04, loss 0.211583\n",
      "Stage: train, iter: 7480, lr: 1.000e-04, loss 0.201105\n",
      "Stage: train, iter: 7500, lr: 1.000e-04, loss 0.166928\n",
      "Stage: train, iter: 7520, lr: 1.000e-04, loss 0.174486\n",
      "Stage: train, iter: 7540, lr: 1.000e-04, loss 0.209209\n",
      "Stage: train, iter: 7560, lr: 1.000e-04, loss 0.165570\n",
      "Stage: train, iter: 7580, lr: 1.000e-04, loss 0.246688\n",
      "Stage: train, iter: 7600, lr: 1.000e-04, loss 0.266843\n",
      "Stage: train, iter: 7620, lr: 1.000e-04, loss 0.189096\n",
      "Stage: train, iter: 7640, lr: 1.000e-04, loss 0.247671\n",
      "Stage: train, iter: 7660, lr: 1.000e-04, loss 0.209240\n",
      "Stage: train, iter: 7680, lr: 1.000e-04, loss 0.194777\n",
      "Stage: train, iter: 7700, lr: 1.000e-04, loss 0.233316\n",
      "Stage: train, iter: 7720, lr: 1.000e-04, loss 0.208769\n",
      "Stage: train, iter: 7740, lr: 1.000e-04, loss 0.205794\n",
      "Stage: train, iter: 7760, lr: 1.000e-04, loss 0.157299\n",
      "Stage: train, iter: 7780, lr: 1.000e-04, loss 0.214132\n",
      "Stage: train, iter: 7800, lr: 1.000e-04, loss 0.192868\n",
      "Stage: train, iter: 7820, lr: 1.000e-04, loss 0.263627\n",
      "Stage: train, iter: 7840, lr: 1.000e-04, loss 0.126450\n",
      "Stage: train, iter: 7860, lr: 1.000e-04, loss 0.240884\n",
      "Stage: train, iter: 7880, lr: 1.000e-04, loss 0.337460\n",
      "Stage: train, iter: 7900, lr: 1.000e-04, loss 0.163543\n",
      "Stage: train, iter: 7920, lr: 1.000e-04, loss 0.298811\n",
      "Stage: train, iter: 7940, lr: 1.000e-04, loss 0.346082\n",
      "Stage: train, iter: 7960, lr: 1.000e-04, loss 0.214748\n",
      "Stage: train, iter: 7980, lr: 1.000e-04, loss 0.166489\n",
      "Stage: train, iter: 8000, lr: 1.000e-04, loss 0.298369\n",
      "Stage: train, iter: 8020, lr: 1.000e-04, loss 0.156666\n",
      "Stage: train, iter: 8040, lr: 1.000e-04, loss 0.270987\n",
      "Stage: train, iter: 8060, lr: 1.000e-04, loss 0.137644\n",
      "Stage: train, iter: 8080, lr: 1.000e-04, loss 0.290297\n",
      "Stage: train, iter: 8100, lr: 1.000e-04, loss 0.173195\n",
      "Stage: train, iter: 8120, lr: 1.000e-04, loss 0.214781\n",
      "Stage: train, iter: 8140, lr: 1.000e-04, loss 0.209039\n",
      "Stage: train, iter: 8160, lr: 1.000e-04, loss 0.284430\n",
      "Stage: train, iter: 8180, lr: 1.000e-04, loss 0.210499\n",
      "Stage: train, iter: 8200, lr: 1.000e-04, loss 0.233289\n",
      "Stage: train, iter: 8220, lr: 1.000e-04, loss 0.229193\n",
      "Stage: train, iter: 8240, lr: 1.000e-04, loss 0.178008\n",
      "Stage: train, iter: 8260, lr: 1.000e-04, loss 0.286152\n",
      "Stage: train, iter: 8280, lr: 1.000e-04, loss 0.216101\n",
      "Stage: train, iter: 8300, lr: 1.000e-04, loss 0.190716\n",
      "Stage: train, iter: 8320, lr: 1.000e-04, loss 0.193219\n",
      "Stage: train, iter: 8340, lr: 1.000e-04, loss 0.116820\n",
      "Stage: train, iter: 8360, lr: 1.000e-04, loss 0.236436\n",
      "Stage: train, iter: 8380, lr: 1.000e-04, loss 0.143906\n",
      "Stage: train, iter: 8400, lr: 1.000e-04, loss 0.182809\n",
      "Stage: train, iter: 8420, lr: 1.000e-04, loss 0.178483\n",
      "Stage: train, iter: 8440, lr: 1.000e-04, loss 0.180374\n",
      "Stage: train, iter: 8460, lr: 1.000e-04, loss 0.204443\n",
      "Stage: train, iter: 8480, lr: 1.000e-04, loss 0.236863\n",
      "Stage: train, iter: 8500, lr: 1.000e-04, loss 0.258500\n",
      "Stage: train, iter: 8520, lr: 1.000e-04, loss 0.210854\n",
      "Stage: train, iter: 8540, lr: 1.000e-04, loss 0.276083\n",
      "Stage: train, iter: 8560, lr: 1.000e-04, loss 0.158903\n",
      "Stage: train, iter: 8580, lr: 1.000e-04, loss 0.172246\n",
      "Stage: train, iter: 8600, lr: 1.000e-04, loss 0.166710\n",
      "Stage: train, iter: 8620, lr: 1.000e-04, loss 0.207201\n",
      "Stage: train, iter: 8640, lr: 1.000e-04, loss 0.183230\n",
      "Stage: train, iter: 8660, lr: 1.000e-04, loss 0.219159\n",
      "Stage: train, iter: 8680, lr: 1.000e-04, loss 0.171499\n",
      "Stage: train, iter: 8700, lr: 1.000e-04, loss 0.222068\n",
      "Stage: train, iter: 8720, lr: 1.000e-04, loss 0.200416\n",
      "Stage: train, iter: 8740, lr: 1.000e-04, loss 0.162997\n",
      "Stage: train, iter: 8760, lr: 1.000e-04, loss 0.236465\n",
      "Stage: train, iter: 8780, lr: 1.000e-04, loss 0.219472\n",
      "Stage: train, iter: 8800, lr: 1.000e-04, loss 0.188522\n",
      "Stage: train, iter: 8820, lr: 1.000e-04, loss 0.292199\n",
      "Stage: train, iter: 8840, lr: 1.000e-04, loss 0.272863\n",
      "Stage: train, iter: 8860, lr: 1.000e-04, loss 0.226357\n",
      "Stage: train, iter: 8880, lr: 1.000e-04, loss 0.231681\n",
      "Stage: train, iter: 8900, lr: 1.000e-04, loss 0.140333\n",
      "Stage: train, iter: 8920, lr: 1.000e-04, loss 0.249127\n",
      "Stage: train, iter: 8940, lr: 1.000e-04, loss 0.189179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 8960, lr: 1.000e-04, loss 0.259526\n",
      "Stage: train, iter: 8980, lr: 1.000e-04, loss 0.177447\n",
      "Stage: train, iter: 9000, lr: 1.000e-04, loss 0.189899\n",
      "Stage: train, iter: 9020, lr: 1.000e-04, loss 0.175669\n",
      "Stage: train, iter: 9040, lr: 1.000e-04, loss 0.199418\n",
      "Stage: train, iter: 9060, lr: 1.000e-04, loss 0.198282\n",
      "Stage: train, iter: 9080, lr: 1.000e-04, loss 0.348602\n",
      "Stage: train, iter: 9100, lr: 1.000e-04, loss 0.145196\n",
      "Stage: train, iter: 9120, lr: 1.000e-04, loss 0.233472\n",
      "Stage: train, iter: 9140, lr: 1.000e-04, loss 0.208053\n",
      "Stage: train, iter: 9160, lr: 1.000e-04, loss 0.214510\n",
      "Stage: train, iter: 9180, lr: 1.000e-04, loss 0.177183\n",
      "Stage: train, iter: 9200, lr: 1.000e-04, loss 0.401374\n",
      "Stage: train, iter: 9220, lr: 1.000e-04, loss 0.153557\n",
      "Stage: train, iter: 9240, lr: 1.000e-04, loss 0.202854\n",
      "Stage: train, iter: 9260, lr: 1.000e-04, loss 0.160881\n",
      "Stage: train, iter: 9280, lr: 1.000e-04, loss 0.262511\n",
      "Stage: train, iter: 9300, lr: 1.000e-04, loss 0.178704\n",
      "Stage: train, iter: 9320, lr: 1.000e-04, loss 0.237841\n",
      "Stage: train, iter: 9340, lr: 1.000e-04, loss 0.242886\n",
      "Stage: train, iter: 9360, lr: 1.000e-04, loss 0.202580\n",
      "Stage: train, iter: 9380, lr: 1.000e-04, loss 0.138746\n",
      "Stage: train, iter: 9400, lr: 1.000e-04, loss 0.228776\n",
      "Stage: train, iter: 9420, lr: 1.000e-04, loss 0.171340\n",
      "Stage: train, iter: 9440, lr: 1.000e-04, loss 0.197148\n",
      "Stage: train, iter: 9460, lr: 1.000e-04, loss 0.219665\n",
      "Stage: train, iter: 9480, lr: 1.000e-04, loss 0.271452\n",
      "Stage: train, iter: 9500, lr: 1.000e-04, loss 0.158527\n",
      "Stage: train, iter: 9520, lr: 1.000e-04, loss 0.273219\n",
      "Stage: train, iter: 9540, lr: 1.000e-04, loss 0.188746\n",
      "Stage: train, iter: 9560, lr: 1.000e-04, loss 0.249404\n",
      "Stage: train, iter: 9580, lr: 1.000e-04, loss 0.172707\n",
      "Stage: train, iter: 9600, lr: 1.000e-04, loss 0.215807\n",
      "Stage: train, iter: 9620, lr: 1.000e-04, loss 0.168085\n",
      "Stage: train, iter: 9640, lr: 1.000e-04, loss 0.253817\n",
      "Stage: train, iter: 9660, lr: 1.000e-04, loss 0.167976\n",
      "Stage: train, iter: 9680, lr: 1.000e-04, loss 0.315167\n",
      "Stage: train, iter: 9700, lr: 1.000e-04, loss 0.418169\n",
      "Stage: train, iter: 9720, lr: 1.000e-04, loss 0.172770\n",
      "Stage: train, iter: 9740, lr: 1.000e-04, loss 0.191497\n",
      "Stage: train, iter: 9760, lr: 1.000e-04, loss 0.198147\n",
      "Stage: train, iter: 9780, lr: 1.000e-04, loss 0.195249\n",
      "Stage: train, iter: 9800, lr: 1.000e-04, loss 0.271854\n",
      "Stage: train, iter: 9820, lr: 1.000e-04, loss 0.141653\n",
      "Stage: train, iter: 9840, lr: 1.000e-04, loss 0.149118\n",
      "Stage: train, iter: 9860, lr: 1.000e-04, loss 0.186658\n",
      "Stage: train, iter: 9880, lr: 1.000e-04, loss 0.226435\n",
      "Stage: train, iter: 9900, lr: 1.000e-04, loss 0.192749\n",
      "Stage: train, iter: 9920, lr: 1.000e-04, loss 0.203013\n",
      "Stage: train, iter: 9940, lr: 1.000e-04, loss 0.388326\n",
      "Stage: train, iter: 9960, lr: 1.000e-04, loss 0.158190\n",
      "Stage: train, iter: 9980, lr: 1.000e-04, loss 0.268952\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(pjoin(experiment_dir, 'train_log.txt'))\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "start_lr = 1e-4\n",
    "optimizer_freeze_encoder = Adam([\n",
    "    {'params': model.module.encoder_squeeze.parameters()},\n",
    "    {'params': model.module.decoder_stages.parameters()},\n",
    "    {'params': model.module.bottlenecks.parameters()},\n",
    "    {'params': model.module.last_upsample.parameters()},\n",
    "    {'params': model.module.final.parameters()}\n",
    "], lr=start_lr)\n",
    "lr_policy = StepLR(start_lr)\n",
    "\n",
    "# model.load_state_dict(torch.load('./output/irv2_i384_b16_upsample_dice2/model_last.pt'))\n",
    "train_dict = {\n",
    "    'model': model,\n",
    "    'output_dirpath': experiment_dir,\n",
    "    'optimizer': optimizer_freeze_encoder,\n",
    "    'lr_policy': lr_policy,\n",
    "#     'start_iter': 200000, \n",
    "    'num_iters': 10000,\n",
    "    'criterion': criterion,\n",
    "    'train_dataloader': dl_train,\n",
    "    'val_set': val_set,\n",
    "    'logger': logger,\n",
    "}\n",
    "train_hist = train(**train_dict)\n",
    "\n",
    "model_dirpath = join(experiment_dir, f'model_last.pt')\n",
    "torch.save(model.state_dict(), model_dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'res50_i512_ch128_dice0.5_400k'\n",
    "experiment_dir = OUTPUT_DIR + experiment_name\n",
    "#!rm -r {experiment_dir}\n",
    "!mkdir -p {experiment_dir}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_set, val_set = train_val_split()\n",
    "\n",
    "# NO AUGMENT\n",
    "ds_train = Dataset(IMAGE_SZ, train_set, epoch_mul=epoch_mul)\n",
    "ds_valid = Dataset(IMAGE_SZ, val_set, epoch_mul=epoch_mul)\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "dl_valid = DataLoader(ds_valid, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 0, lr: 1.000e-04, loss 0.157827\n",
      "Stage: train, iter: 20, lr: 1.000e-04, loss 0.135674\n",
      "Stage: train, iter: 40, lr: 1.000e-04, loss 0.159892\n",
      "Stage: train, iter: 60, lr: 1.000e-04, loss 0.164676\n",
      "Stage: train, iter: 80, lr: 1.000e-04, loss 0.167141\n",
      "Stage: train, iter: 100, lr: 9.999e-05, loss 0.133138\n",
      "Stage: train, iter: 120, lr: 9.999e-05, loss 0.125994\n",
      "Stage: train, iter: 140, lr: 9.999e-05, loss 0.125550\n",
      "Stage: train, iter: 160, lr: 9.998e-05, loss 0.157842\n",
      "Stage: train, iter: 180, lr: 9.998e-05, loss 0.114782\n",
      "Stage: train, iter: 200, lr: 9.998e-05, loss 0.099650\n",
      "Stage: train, iter: 220, lr: 9.997e-05, loss 0.137164\n",
      "Stage: train, iter: 240, lr: 9.996e-05, loss 0.112647\n",
      "Stage: train, iter: 260, lr: 9.996e-05, loss 0.125325\n",
      "Stage: train, iter: 280, lr: 9.995e-05, loss 0.133991\n",
      "Stage: train, iter: 300, lr: 9.994e-05, loss 0.075667\n",
      "Stage: train, iter: 320, lr: 9.994e-05, loss 0.154214\n",
      "Stage: train, iter: 340, lr: 9.993e-05, loss 0.089717\n",
      "Stage: train, iter: 360, lr: 9.992e-05, loss 0.146444\n",
      "Stage: train, iter: 380, lr: 9.991e-05, loss 0.183747\n",
      "Stage: train, iter: 400, lr: 9.990e-05, loss 0.149492\n",
      "Stage: train, iter: 420, lr: 9.989e-05, loss 0.116469\n",
      "Stage: train, iter: 440, lr: 9.988e-05, loss 0.164807\n",
      "Stage: train, iter: 460, lr: 9.987e-05, loss 0.107327\n",
      "Stage: train, iter: 480, lr: 9.986e-05, loss 0.106150\n",
      "Stage: train, iter: 500, lr: 9.985e-05, loss 0.135370\n",
      "Stage: train, iter: 520, lr: 9.983e-05, loss 0.153230\n",
      "Stage: train, iter: 540, lr: 9.982e-05, loss 0.120156\n",
      "Stage: train, iter: 560, lr: 9.981e-05, loss 0.117548\n",
      "Stage: train, iter: 580, lr: 9.979e-05, loss 0.110481\n",
      "Stage: train, iter: 600, lr: 9.978e-05, loss 0.073803\n",
      "Stage: train, iter: 620, lr: 9.976e-05, loss 0.102717\n",
      "Stage: train, iter: 640, lr: 9.975e-05, loss 0.134611\n",
      "Stage: train, iter: 660, lr: 9.973e-05, loss 0.080715\n",
      "Stage: train, iter: 680, lr: 9.972e-05, loss 0.140204\n",
      "Stage: train, iter: 700, lr: 9.970e-05, loss 0.122061\n",
      "Stage: train, iter: 720, lr: 9.968e-05, loss 0.155452\n",
      "Stage: train, iter: 740, lr: 9.966e-05, loss 0.118707\n",
      "Stage: train, iter: 760, lr: 9.964e-05, loss 0.115556\n",
      "Stage: train, iter: 780, lr: 9.963e-05, loss 0.174396\n",
      "Stage: train, iter: 800, lr: 9.961e-05, loss 0.124345\n",
      "Stage: train, iter: 820, lr: 9.959e-05, loss 0.114950\n",
      "Stage: train, iter: 840, lr: 9.957e-05, loss 0.131061\n",
      "Stage: train, iter: 860, lr: 9.954e-05, loss 0.120748\n",
      "Stage: train, iter: 880, lr: 9.952e-05, loss 0.117674\n",
      "Stage: train, iter: 900, lr: 9.950e-05, loss 0.096043\n",
      "Stage: train, iter: 920, lr: 9.948e-05, loss 0.073750\n",
      "Stage: train, iter: 940, lr: 9.946e-05, loss 0.110000\n",
      "Stage: train, iter: 960, lr: 9.943e-05, loss 0.091017\n",
      "Stage: train, iter: 980, lr: 9.941e-05, loss 0.108427\n",
      "Stage: train, iter: 1000, lr: 9.938e-05, loss 0.104035\n",
      "Stage: train, iter: 1020, lr: 9.936e-05, loss 0.117148\n",
      "Stage: train, iter: 1040, lr: 9.933e-05, loss 0.105223\n",
      "Stage: train, iter: 1060, lr: 9.931e-05, loss 0.116663\n",
      "Stage: train, iter: 1080, lr: 9.928e-05, loss 0.108160\n",
      "Stage: train, iter: 1100, lr: 9.926e-05, loss 0.137339\n",
      "Stage: train, iter: 1120, lr: 9.923e-05, loss 0.127713\n",
      "Stage: train, iter: 1140, lr: 9.920e-05, loss 0.185246\n",
      "Stage: train, iter: 1160, lr: 9.917e-05, loss 0.132043\n",
      "Stage: train, iter: 1180, lr: 9.914e-05, loss 0.105070\n",
      "Stage: train, iter: 1200, lr: 9.911e-05, loss 0.141006\n",
      "Stage: train, iter: 1220, lr: 9.908e-05, loss 0.066130\n",
      "Stage: train, iter: 1240, lr: 9.905e-05, loss 0.129165\n",
      "Stage: train, iter: 1260, lr: 9.902e-05, loss 0.095713\n",
      "Stage: train, iter: 1280, lr: 9.899e-05, loss 0.094996\n",
      "Stage: train, iter: 1300, lr: 9.896e-05, loss 0.139214\n",
      "Stage: train, iter: 1320, lr: 9.893e-05, loss 0.110209\n",
      "Stage: train, iter: 1340, lr: 9.890e-05, loss 0.144503\n",
      "Stage: train, iter: 1360, lr: 9.886e-05, loss 0.087578\n",
      "Stage: train, iter: 1380, lr: 9.883e-05, loss 0.098115\n",
      "Stage: train, iter: 1400, lr: 9.880e-05, loss 0.135636\n",
      "Stage: train, iter: 1420, lr: 9.876e-05, loss 0.104039\n",
      "Stage: train, iter: 1440, lr: 9.873e-05, loss 0.114859\n",
      "Stage: train, iter: 1460, lr: 9.869e-05, loss 0.055509\n",
      "Stage: train, iter: 1480, lr: 9.865e-05, loss 0.153030\n",
      "Stage: train, iter: 1500, lr: 9.862e-05, loss 0.098183\n",
      "Stage: train, iter: 1520, lr: 9.858e-05, loss 0.169574\n",
      "Stage: train, iter: 1540, lr: 9.854e-05, loss 0.094777\n",
      "Stage: train, iter: 1560, lr: 9.851e-05, loss 0.122975\n",
      "Stage: train, iter: 1580, lr: 9.847e-05, loss 0.159019\n",
      "Stage: train, iter: 1600, lr: 9.843e-05, loss 0.119291\n",
      "Stage: train, iter: 1620, lr: 9.839e-05, loss 0.079712\n",
      "Stage: train, iter: 1640, lr: 9.835e-05, loss 0.129441\n",
      "Stage: train, iter: 1660, lr: 9.831e-05, loss 0.147544\n",
      "Stage: train, iter: 1680, lr: 9.827e-05, loss 0.102454\n",
      "Stage: train, iter: 1700, lr: 9.823e-05, loss 0.070388\n",
      "Stage: train, iter: 1720, lr: 9.819e-05, loss 0.089217\n",
      "Stage: train, iter: 1740, lr: 9.814e-05, loss 0.139725\n",
      "Stage: train, iter: 1760, lr: 9.810e-05, loss 0.148714\n",
      "Stage: train, iter: 1780, lr: 9.806e-05, loss 0.124235\n",
      "Stage: train, iter: 1800, lr: 9.801e-05, loss 0.127646\n",
      "Stage: train, iter: 1820, lr: 9.797e-05, loss 0.120411\n",
      "Stage: train, iter: 1840, lr: 9.793e-05, loss 0.109193\n",
      "Stage: train, iter: 1860, lr: 9.788e-05, loss 0.122363\n",
      "Stage: train, iter: 1880, lr: 9.784e-05, loss 0.123197\n",
      "Stage: train, iter: 1900, lr: 9.779e-05, loss 0.108076\n",
      "Stage: train, iter: 1920, lr: 9.774e-05, loss 0.112049\n",
      "Stage: train, iter: 1940, lr: 9.770e-05, loss 0.152672\n",
      "Stage: train, iter: 1960, lr: 9.765e-05, loss 0.227809\n",
      "Stage: train, iter: 1980, lr: 9.760e-05, loss 0.056092\n",
      "Stage: train, iter: 2000, lr: 9.755e-05, loss 0.154195\n",
      "Stage: train, iter: 2020, lr: 9.750e-05, loss 0.131336\n",
      "Stage: train, iter: 2040, lr: 9.745e-05, loss 0.157624\n",
      "Stage: train, iter: 2060, lr: 9.740e-05, loss 0.153808\n",
      "Stage: train, iter: 2080, lr: 9.735e-05, loss 0.140704\n",
      "Stage: train, iter: 2100, lr: 9.730e-05, loss 0.138230\n",
      "Stage: train, iter: 2120, lr: 9.725e-05, loss 0.161009\n",
      "Stage: train, iter: 2140, lr: 9.720e-05, loss 0.120838\n",
      "Stage: train, iter: 2160, lr: 9.715e-05, loss 0.151524\n",
      "Stage: train, iter: 2180, lr: 9.710e-05, loss 0.221607\n",
      "Stage: train, iter: 2200, lr: 9.704e-05, loss 0.062692\n",
      "Stage: train, iter: 2220, lr: 9.699e-05, loss 0.100759\n",
      "Stage: train, iter: 2240, lr: 9.694e-05, loss 0.100879\n",
      "Stage: train, iter: 2260, lr: 9.688e-05, loss 0.082077\n",
      "Stage: train, iter: 2280, lr: 9.683e-05, loss 0.095142\n",
      "Stage: train, iter: 2300, lr: 9.677e-05, loss 0.154832\n",
      "Stage: train, iter: 2320, lr: 9.672e-05, loss 0.104364\n",
      "Stage: train, iter: 2340, lr: 9.666e-05, loss 0.089218\n",
      "Stage: train, iter: 2360, lr: 9.660e-05, loss 0.128668\n",
      "Stage: train, iter: 2380, lr: 9.655e-05, loss 0.162554\n",
      "Stage: train, iter: 2400, lr: 9.649e-05, loss 0.145500\n",
      "Stage: train, iter: 2420, lr: 9.643e-05, loss 0.157008\n",
      "Stage: train, iter: 2440, lr: 9.637e-05, loss 0.103748\n",
      "Stage: train, iter: 2460, lr: 9.631e-05, loss 0.109384\n",
      "Stage: train, iter: 2480, lr: 9.625e-05, loss 0.116793\n",
      "Stage: train, iter: 2500, lr: 9.619e-05, loss 0.081214\n",
      "Stage: train, iter: 2520, lr: 9.613e-05, loss 0.154952\n",
      "Stage: train, iter: 2540, lr: 9.607e-05, loss 0.137469\n",
      "Stage: train, iter: 2560, lr: 9.601e-05, loss 0.130149\n",
      "Stage: train, iter: 2580, lr: 9.595e-05, loss 0.121536\n",
      "Stage: train, iter: 2600, lr: 9.589e-05, loss 0.150295\n",
      "Stage: train, iter: 2620, lr: 9.582e-05, loss 0.180098\n",
      "Stage: train, iter: 2640, lr: 9.576e-05, loss 0.135672\n",
      "Stage: train, iter: 2660, lr: 9.570e-05, loss 0.132469\n",
      "Stage: train, iter: 2680, lr: 9.563e-05, loss 0.154469\n",
      "Stage: train, iter: 2700, lr: 9.557e-05, loss 0.168697\n",
      "Stage: train, iter: 2720, lr: 9.550e-05, loss 0.217129\n",
      "Stage: train, iter: 2740, lr: 9.544e-05, loss 0.135492\n",
      "Stage: train, iter: 2760, lr: 9.537e-05, loss 0.174518\n",
      "Stage: train, iter: 2780, lr: 9.531e-05, loss 0.182545\n",
      "Stage: train, iter: 2800, lr: 9.524e-05, loss 0.084009\n",
      "Stage: train, iter: 2820, lr: 9.517e-05, loss 0.099656\n",
      "Stage: train, iter: 2840, lr: 9.511e-05, loss 0.118965\n",
      "Stage: train, iter: 2860, lr: 9.504e-05, loss 0.100412\n",
      "Stage: train, iter: 2880, lr: 9.497e-05, loss 0.152922\n",
      "Stage: train, iter: 2900, lr: 9.490e-05, loss 0.121456\n",
      "Stage: train, iter: 2920, lr: 9.483e-05, loss 0.157283\n",
      "Stage: train, iter: 2940, lr: 9.476e-05, loss 0.142129\n",
      "Stage: train, iter: 2960, lr: 9.469e-05, loss 0.106032\n",
      "Stage: train, iter: 2980, lr: 9.462e-05, loss 0.183730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 3000, lr: 9.455e-05, loss 0.116062\n",
      "Stage: train, iter: 3020, lr: 9.448e-05, loss 0.115118\n",
      "Stage: train, iter: 3040, lr: 9.441e-05, loss 0.132274\n",
      "Stage: train, iter: 3060, lr: 9.433e-05, loss 0.102333\n",
      "Stage: train, iter: 3080, lr: 9.426e-05, loss 0.119889\n",
      "Stage: train, iter: 3100, lr: 9.419e-05, loss 0.160934\n",
      "Stage: train, iter: 3120, lr: 9.411e-05, loss 0.070023\n",
      "Stage: train, iter: 3140, lr: 9.404e-05, loss 0.107824\n",
      "Stage: train, iter: 3160, lr: 9.397e-05, loss 0.153217\n",
      "Stage: train, iter: 3180, lr: 9.389e-05, loss 0.105700\n",
      "Stage: train, iter: 3200, lr: 9.381e-05, loss 0.113188\n",
      "Stage: train, iter: 3220, lr: 9.374e-05, loss 0.146792\n",
      "Stage: train, iter: 3240, lr: 9.366e-05, loss 0.111069\n",
      "Stage: train, iter: 3260, lr: 9.359e-05, loss 0.156894\n",
      "Stage: train, iter: 3280, lr: 9.351e-05, loss 0.147990\n",
      "Stage: train, iter: 3300, lr: 9.343e-05, loss 0.144896\n",
      "Stage: train, iter: 3320, lr: 9.335e-05, loss 0.192795\n",
      "Stage: train, iter: 3340, lr: 9.327e-05, loss 0.119154\n",
      "Stage: train, iter: 3360, lr: 9.320e-05, loss 0.142592\n",
      "Stage: train, iter: 3380, lr: 9.312e-05, loss 0.091567\n",
      "Stage: train, iter: 3400, lr: 9.304e-05, loss 0.126112\n",
      "Stage: train, iter: 3420, lr: 9.296e-05, loss 0.153996\n",
      "Stage: train, iter: 3440, lr: 9.288e-05, loss 0.139408\n",
      "Stage: train, iter: 3460, lr: 9.279e-05, loss 0.159092\n",
      "Stage: train, iter: 3480, lr: 9.271e-05, loss 0.077822\n",
      "Stage: train, iter: 3500, lr: 9.263e-05, loss 0.141837\n",
      "Stage: train, iter: 3520, lr: 9.255e-05, loss 0.072914\n",
      "Stage: train, iter: 3540, lr: 9.247e-05, loss 0.160059\n",
      "Stage: train, iter: 3560, lr: 9.238e-05, loss 0.126491\n",
      "Stage: train, iter: 3580, lr: 9.230e-05, loss 0.132818\n",
      "Stage: train, iter: 3600, lr: 9.222e-05, loss 0.128284\n",
      "Stage: train, iter: 3620, lr: 9.213e-05, loss 0.132536\n",
      "Stage: train, iter: 3640, lr: 9.205e-05, loss 0.073666\n",
      "Stage: train, iter: 3660, lr: 9.196e-05, loss 0.156916\n",
      "Stage: train, iter: 3680, lr: 9.188e-05, loss 0.103545\n",
      "Stage: train, iter: 3700, lr: 9.179e-05, loss 0.135351\n",
      "Stage: train, iter: 3720, lr: 9.170e-05, loss 0.105545\n",
      "Stage: train, iter: 3740, lr: 9.162e-05, loss 0.077045\n",
      "Stage: train, iter: 3760, lr: 9.153e-05, loss 0.151967\n",
      "Stage: train, iter: 3780, lr: 9.144e-05, loss 0.095419\n",
      "Stage: train, iter: 3800, lr: 9.135e-05, loss 0.126127\n",
      "Stage: train, iter: 3820, lr: 9.126e-05, loss 0.108739\n",
      "Stage: train, iter: 3840, lr: 9.118e-05, loss 0.095874\n",
      "Stage: train, iter: 3860, lr: 9.109e-05, loss 0.150026\n",
      "Stage: train, iter: 3880, lr: 9.100e-05, loss 0.100092\n",
      "Stage: train, iter: 3900, lr: 9.091e-05, loss 0.125834\n",
      "Stage: train, iter: 3920, lr: 9.082e-05, loss 0.091752\n",
      "Stage: train, iter: 3940, lr: 9.073e-05, loss 0.127426\n",
      "Stage: train, iter: 3960, lr: 9.063e-05, loss 0.135822\n",
      "Stage: train, iter: 3980, lr: 9.054e-05, loss 0.142766\n",
      "Stage: train, iter: 4000, lr: 9.045e-05, loss 0.110797\n",
      "Stage: train, iter: 4020, lr: 9.036e-05, loss 0.124005\n",
      "Stage: train, iter: 4040, lr: 9.026e-05, loss 0.137899\n",
      "Stage: train, iter: 4060, lr: 9.017e-05, loss 0.141350\n",
      "Stage: train, iter: 4080, lr: 9.008e-05, loss 0.157046\n",
      "Stage: train, iter: 4100, lr: 8.998e-05, loss 0.126665\n",
      "Stage: train, iter: 4120, lr: 8.989e-05, loss 0.131016\n",
      "Stage: train, iter: 4140, lr: 8.979e-05, loss 0.142733\n",
      "Stage: train, iter: 4160, lr: 8.970e-05, loss 0.122738\n",
      "Stage: train, iter: 4180, lr: 8.960e-05, loss 0.153643\n",
      "Stage: train, iter: 4200, lr: 8.951e-05, loss 0.130458\n",
      "Stage: train, iter: 4220, lr: 8.941e-05, loss 0.118344\n",
      "Stage: train, iter: 4240, lr: 8.931e-05, loss 0.143294\n",
      "Stage: train, iter: 4260, lr: 8.922e-05, loss 0.139812\n",
      "Stage: train, iter: 4280, lr: 8.912e-05, loss 0.119613\n",
      "Stage: train, iter: 4300, lr: 8.902e-05, loss 0.153913\n",
      "Stage: train, iter: 4320, lr: 8.892e-05, loss 0.195339\n",
      "Stage: train, iter: 4340, lr: 8.882e-05, loss 0.141490\n",
      "Stage: train, iter: 4360, lr: 8.872e-05, loss 0.160116\n",
      "Stage: train, iter: 4380, lr: 8.862e-05, loss 0.150026\n",
      "Stage: train, iter: 4400, lr: 8.852e-05, loss 0.174140\n",
      "Stage: train, iter: 4420, lr: 8.842e-05, loss 0.177478\n",
      "Stage: train, iter: 4440, lr: 8.832e-05, loss 0.103157\n",
      "Stage: train, iter: 4460, lr: 8.822e-05, loss 0.155053\n",
      "Stage: train, iter: 4480, lr: 8.812e-05, loss 0.134216\n",
      "Stage: train, iter: 4500, lr: 8.802e-05, loss 0.127954\n",
      "Stage: train, iter: 4520, lr: 8.792e-05, loss 0.088706\n",
      "Stage: train, iter: 4540, lr: 8.781e-05, loss 0.101987\n",
      "Stage: train, iter: 4560, lr: 8.771e-05, loss 0.067041\n",
      "Stage: train, iter: 4580, lr: 8.761e-05, loss 0.093698\n",
      "Stage: train, iter: 4600, lr: 8.750e-05, loss 0.127105\n",
      "Stage: train, iter: 4620, lr: 8.740e-05, loss 0.121556\n",
      "Stage: train, iter: 4640, lr: 8.730e-05, loss 0.142659\n",
      "Stage: train, iter: 4660, lr: 8.719e-05, loss 0.103865\n",
      "Stage: train, iter: 4680, lr: 8.709e-05, loss 0.120051\n",
      "Stage: train, iter: 4700, lr: 8.698e-05, loss 0.070233\n",
      "Stage: train, iter: 4720, lr: 8.687e-05, loss 0.151964\n",
      "Stage: train, iter: 4740, lr: 8.677e-05, loss 0.160780\n",
      "Stage: train, iter: 4760, lr: 8.666e-05, loss 0.163080\n",
      "Stage: train, iter: 4780, lr: 8.655e-05, loss 0.103641\n",
      "Stage: train, iter: 4800, lr: 8.645e-05, loss 0.147121\n",
      "Stage: train, iter: 4820, lr: 8.634e-05, loss 0.119062\n",
      "Stage: train, iter: 4840, lr: 8.623e-05, loss 0.111828\n",
      "Stage: train, iter: 4860, lr: 8.612e-05, loss 0.091752\n",
      "Stage: train, iter: 4880, lr: 8.601e-05, loss 0.099859\n",
      "Stage: train, iter: 4900, lr: 8.590e-05, loss 0.117368\n",
      "Stage: train, iter: 4920, lr: 8.580e-05, loss 0.091530\n",
      "Stage: train, iter: 4940, lr: 8.569e-05, loss 0.130836\n",
      "Stage: train, iter: 4960, lr: 8.558e-05, loss 0.152128\n",
      "Stage: train, iter: 4980, lr: 8.546e-05, loss 0.151128\n",
      "Stage: train, iter: 5000, lr: 8.535e-05, loss 0.102291\n",
      "Stage: train, iter: 5020, lr: 8.524e-05, loss 0.112640\n",
      "Stage: train, iter: 5040, lr: 8.513e-05, loss 0.227079\n",
      "Stage: train, iter: 5060, lr: 8.502e-05, loss 0.073375\n",
      "Stage: train, iter: 5080, lr: 8.491e-05, loss 0.142212\n",
      "Stage: train, iter: 5100, lr: 8.479e-05, loss 0.124465\n",
      "Stage: train, iter: 5120, lr: 8.468e-05, loss 0.145817\n",
      "Stage: train, iter: 5140, lr: 8.457e-05, loss 0.113962\n",
      "Stage: train, iter: 5160, lr: 8.445e-05, loss 0.147304\n",
      "Stage: train, iter: 5180, lr: 8.434e-05, loss 0.128383\n",
      "Stage: train, iter: 5200, lr: 8.423e-05, loss 0.142223\n",
      "Stage: train, iter: 5220, lr: 8.411e-05, loss 0.129592\n",
      "Stage: train, iter: 5240, lr: 8.400e-05, loss 0.124094\n",
      "Stage: train, iter: 5260, lr: 8.388e-05, loss 0.193158\n",
      "Stage: train, iter: 5280, lr: 8.377e-05, loss 0.114036\n",
      "Stage: train, iter: 5300, lr: 8.365e-05, loss 0.093428\n",
      "Stage: train, iter: 5320, lr: 8.353e-05, loss 0.095013\n",
      "Stage: train, iter: 5340, lr: 8.342e-05, loss 0.134868\n",
      "Stage: train, iter: 5360, lr: 8.330e-05, loss 0.108192\n",
      "Stage: train, iter: 5380, lr: 8.318e-05, loss 0.129957\n",
      "Stage: train, iter: 5400, lr: 8.306e-05, loss 0.102007\n",
      "Stage: train, iter: 5420, lr: 8.295e-05, loss 0.120257\n",
      "Stage: train, iter: 5440, lr: 8.283e-05, loss 0.177403\n",
      "Stage: train, iter: 5460, lr: 8.271e-05, loss 0.080886\n",
      "Stage: train, iter: 5480, lr: 8.259e-05, loss 0.131383\n",
      "Stage: train, iter: 5500, lr: 8.247e-05, loss 0.118356\n",
      "Stage: train, iter: 5520, lr: 8.235e-05, loss 0.100564\n",
      "Stage: train, iter: 5540, lr: 8.223e-05, loss 0.140089\n",
      "Stage: train, iter: 5560, lr: 8.211e-05, loss 0.095635\n",
      "Stage: train, iter: 5580, lr: 8.199e-05, loss 0.129689\n",
      "Stage: train, iter: 5600, lr: 8.187e-05, loss 0.140785\n",
      "Stage: train, iter: 5620, lr: 8.175e-05, loss 0.141018\n",
      "Stage: train, iter: 5640, lr: 8.163e-05, loss 0.109003\n",
      "Stage: train, iter: 5660, lr: 8.150e-05, loss 0.157139\n",
      "Stage: train, iter: 5680, lr: 8.138e-05, loss 0.086945\n",
      "Stage: train, iter: 5700, lr: 8.126e-05, loss 0.154906\n",
      "Stage: train, iter: 5720, lr: 8.114e-05, loss 0.133975\n",
      "Stage: train, iter: 5740, lr: 8.101e-05, loss 0.086770\n",
      "Stage: train, iter: 5760, lr: 8.089e-05, loss 0.123449\n",
      "Stage: train, iter: 5780, lr: 8.077e-05, loss 0.154045\n",
      "Stage: train, iter: 5800, lr: 8.064e-05, loss 0.118362\n",
      "Stage: train, iter: 5820, lr: 8.052e-05, loss 0.117671\n",
      "Stage: train, iter: 5840, lr: 8.039e-05, loss 0.118042\n",
      "Stage: train, iter: 5860, lr: 8.027e-05, loss 0.115889\n",
      "Stage: train, iter: 5880, lr: 8.014e-05, loss 0.165235\n",
      "Stage: train, iter: 5900, lr: 8.002e-05, loss 0.085359\n",
      "Stage: train, iter: 5920, lr: 7.989e-05, loss 0.105614\n",
      "Stage: train, iter: 5940, lr: 7.977e-05, loss 0.139789\n",
      "Stage: train, iter: 5960, lr: 7.964e-05, loss 0.167863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 5980, lr: 7.951e-05, loss 0.148939\n",
      "Stage: train, iter: 6000, lr: 7.939e-05, loss 0.143242\n",
      "Stage: train, iter: 6020, lr: 7.926e-05, loss 0.124544\n",
      "Stage: train, iter: 6040, lr: 7.913e-05, loss 0.112902\n",
      "Stage: train, iter: 6060, lr: 7.900e-05, loss 0.152296\n",
      "Stage: train, iter: 6080, lr: 7.888e-05, loss 0.116851\n",
      "Stage: train, iter: 6100, lr: 7.875e-05, loss 0.134065\n",
      "Stage: train, iter: 6120, lr: 7.862e-05, loss 0.105512\n",
      "Stage: train, iter: 6140, lr: 7.849e-05, loss 0.124802\n",
      "Stage: train, iter: 6160, lr: 7.836e-05, loss 0.104386\n",
      "Stage: train, iter: 6180, lr: 7.823e-05, loss 0.166698\n",
      "Stage: train, iter: 6200, lr: 7.810e-05, loss 0.121399\n",
      "Stage: train, iter: 6220, lr: 7.797e-05, loss 0.068773\n",
      "Stage: train, iter: 6240, lr: 7.784e-05, loss 0.143039\n",
      "Stage: train, iter: 6260, lr: 7.771e-05, loss 0.065096\n",
      "Stage: train, iter: 6280, lr: 7.758e-05, loss 0.101115\n",
      "Stage: train, iter: 6300, lr: 7.745e-05, loss 0.099639\n",
      "Stage: train, iter: 6320, lr: 7.732e-05, loss 0.124931\n",
      "Stage: train, iter: 6340, lr: 7.719e-05, loss 0.111195\n",
      "Stage: train, iter: 6360, lr: 7.705e-05, loss 0.128626\n",
      "Stage: train, iter: 6380, lr: 7.692e-05, loss 0.066763\n",
      "Stage: train, iter: 6400, lr: 7.679e-05, loss 0.092805\n",
      "Stage: train, iter: 6420, lr: 7.666e-05, loss 0.130635\n",
      "Stage: train, iter: 6440, lr: 7.652e-05, loss 0.097149\n",
      "Stage: train, iter: 6460, lr: 7.639e-05, loss 0.101687\n",
      "Stage: train, iter: 6480, lr: 7.626e-05, loss 0.114004\n",
      "Stage: train, iter: 6500, lr: 7.612e-05, loss 0.124942\n",
      "Stage: train, iter: 6520, lr: 7.599e-05, loss 0.151799\n",
      "Stage: train, iter: 6540, lr: 7.585e-05, loss 0.156412\n",
      "Stage: train, iter: 6560, lr: 7.572e-05, loss 0.097254\n",
      "Stage: train, iter: 6580, lr: 7.558e-05, loss 0.132236\n",
      "Stage: train, iter: 6600, lr: 7.545e-05, loss 0.120899\n",
      "Stage: train, iter: 6620, lr: 7.531e-05, loss 0.091218\n",
      "Stage: train, iter: 6640, lr: 7.518e-05, loss 0.187934\n",
      "Stage: train, iter: 6660, lr: 7.504e-05, loss 0.091635\n",
      "Stage: train, iter: 6680, lr: 7.491e-05, loss 0.100621\n",
      "Stage: train, iter: 6700, lr: 7.477e-05, loss 0.154298\n",
      "Stage: train, iter: 6720, lr: 7.463e-05, loss 0.127191\n",
      "Stage: train, iter: 6740, lr: 7.450e-05, loss 0.128072\n",
      "Stage: train, iter: 6760, lr: 7.436e-05, loss 0.155122\n",
      "Stage: train, iter: 6780, lr: 7.422e-05, loss 0.093054\n",
      "Stage: train, iter: 6800, lr: 7.409e-05, loss 0.128407\n",
      "Stage: train, iter: 6820, lr: 7.395e-05, loss 0.149666\n",
      "Stage: train, iter: 6840, lr: 7.381e-05, loss 0.157558\n",
      "Stage: train, iter: 6860, lr: 7.367e-05, loss 0.084204\n",
      "Stage: train, iter: 6880, lr: 7.353e-05, loss 0.159945\n",
      "Stage: train, iter: 6900, lr: 7.339e-05, loss 0.080096\n",
      "Stage: train, iter: 6920, lr: 7.326e-05, loss 0.180565\n",
      "Stage: train, iter: 6940, lr: 7.312e-05, loss 0.119331\n",
      "Stage: train, iter: 6960, lr: 7.298e-05, loss 0.116495\n",
      "Stage: train, iter: 6980, lr: 7.284e-05, loss 0.159036\n",
      "Stage: train, iter: 7000, lr: 7.270e-05, loss 0.192739\n",
      "Stage: train, iter: 7020, lr: 7.256e-05, loss 0.201800\n",
      "Stage: train, iter: 7040, lr: 7.242e-05, loss 0.127909\n",
      "Stage: train, iter: 7060, lr: 7.228e-05, loss 0.176766\n",
      "Stage: train, iter: 7080, lr: 7.214e-05, loss 0.086745\n",
      "Stage: train, iter: 7100, lr: 7.199e-05, loss 0.106976\n",
      "Stage: train, iter: 7120, lr: 7.185e-05, loss 0.153171\n",
      "Stage: train, iter: 7140, lr: 7.171e-05, loss 0.066522\n",
      "Stage: train, iter: 7160, lr: 7.157e-05, loss 0.177462\n",
      "Stage: train, iter: 7180, lr: 7.143e-05, loss 0.198616\n",
      "Stage: train, iter: 7200, lr: 7.129e-05, loss 0.070895\n",
      "Stage: train, iter: 7220, lr: 7.114e-05, loss 0.109846\n",
      "Stage: train, iter: 7240, lr: 7.100e-05, loss 0.120533\n",
      "Stage: train, iter: 7260, lr: 7.086e-05, loss 0.115712\n",
      "Stage: train, iter: 7280, lr: 7.072e-05, loss 0.126656\n",
      "Stage: train, iter: 7300, lr: 7.057e-05, loss 0.119810\n",
      "Stage: train, iter: 7320, lr: 7.043e-05, loss 0.140744\n",
      "Stage: train, iter: 7340, lr: 7.029e-05, loss 0.096747\n",
      "Stage: train, iter: 7360, lr: 7.014e-05, loss 0.197532\n",
      "Stage: train, iter: 7380, lr: 7.000e-05, loss 0.150008\n",
      "Stage: train, iter: 7400, lr: 6.985e-05, loss 0.095220\n",
      "Stage: train, iter: 7420, lr: 6.971e-05, loss 0.122424\n",
      "Stage: train, iter: 7440, lr: 6.957e-05, loss 0.155810\n",
      "Stage: train, iter: 7460, lr: 6.942e-05, loss 0.104749\n",
      "Stage: train, iter: 7480, lr: 6.928e-05, loss 0.116974\n",
      "Stage: train, iter: 7500, lr: 6.913e-05, loss 0.159606\n",
      "Stage: train, iter: 7520, lr: 6.899e-05, loss 0.217645\n",
      "Stage: train, iter: 7540, lr: 6.884e-05, loss 0.154109\n",
      "Stage: train, iter: 7560, lr: 6.870e-05, loss 0.113388\n",
      "Stage: train, iter: 7580, lr: 6.855e-05, loss 0.095121\n",
      "Stage: train, iter: 7600, lr: 6.840e-05, loss 0.171530\n",
      "Stage: train, iter: 7620, lr: 6.826e-05, loss 0.126888\n",
      "Stage: train, iter: 7640, lr: 6.811e-05, loss 0.075896\n",
      "Stage: train, iter: 7660, lr: 6.796e-05, loss 0.137347\n",
      "Stage: train, iter: 7680, lr: 6.782e-05, loss 0.115896\n",
      "Stage: train, iter: 7700, lr: 6.767e-05, loss 0.126990\n",
      "Stage: train, iter: 7720, lr: 6.752e-05, loss 0.077900\n",
      "Stage: train, iter: 7740, lr: 6.738e-05, loss 0.153172\n",
      "Stage: train, iter: 7760, lr: 6.723e-05, loss 0.181046\n",
      "Stage: train, iter: 7780, lr: 6.708e-05, loss 0.065452\n",
      "Stage: train, iter: 7800, lr: 6.693e-05, loss 0.132632\n",
      "Stage: train, iter: 7820, lr: 6.679e-05, loss 0.110063\n",
      "Stage: train, iter: 7840, lr: 6.664e-05, loss 0.080403\n",
      "Stage: train, iter: 7860, lr: 6.649e-05, loss 0.150534\n",
      "Stage: train, iter: 7880, lr: 6.634e-05, loss 0.096500\n",
      "Stage: train, iter: 7900, lr: 6.619e-05, loss 0.131509\n",
      "Stage: train, iter: 7920, lr: 6.604e-05, loss 0.197436\n",
      "Stage: train, iter: 7940, lr: 6.590e-05, loss 0.094505\n",
      "Stage: train, iter: 7960, lr: 6.575e-05, loss 0.130624\n",
      "Stage: train, iter: 7980, lr: 6.560e-05, loss 0.155775\n",
      "Stage: train, iter: 8000, lr: 6.545e-05, loss 0.101368\n",
      "Stage: train, iter: 8020, lr: 6.530e-05, loss 0.082931\n",
      "Stage: train, iter: 8040, lr: 6.515e-05, loss 0.084734\n",
      "Stage: train, iter: 8060, lr: 6.500e-05, loss 0.100523\n",
      "Stage: train, iter: 8080, lr: 6.485e-05, loss 0.098439\n",
      "Stage: train, iter: 8100, lr: 6.470e-05, loss 0.112912\n",
      "Stage: train, iter: 8120, lr: 6.455e-05, loss 0.174567\n",
      "Stage: train, iter: 8140, lr: 6.440e-05, loss 0.134988\n",
      "Stage: train, iter: 8160, lr: 6.425e-05, loss 0.134434\n",
      "Stage: train, iter: 8180, lr: 6.410e-05, loss 0.132190\n",
      "Stage: train, iter: 8200, lr: 6.395e-05, loss 0.145918\n",
      "Stage: train, iter: 8220, lr: 6.380e-05, loss 0.117389\n",
      "Stage: train, iter: 8240, lr: 6.364e-05, loss 0.062861\n",
      "Stage: train, iter: 8260, lr: 6.349e-05, loss 0.127963\n",
      "Stage: train, iter: 8280, lr: 6.334e-05, loss 0.152269\n",
      "Stage: train, iter: 8300, lr: 6.319e-05, loss 0.135916\n",
      "Stage: train, iter: 8320, lr: 6.304e-05, loss 0.096697\n",
      "Stage: train, iter: 8340, lr: 6.289e-05, loss 0.111897\n",
      "Stage: train, iter: 8360, lr: 6.274e-05, loss 0.138233\n",
      "Stage: train, iter: 8380, lr: 6.258e-05, loss 0.124257\n",
      "Stage: train, iter: 8400, lr: 6.243e-05, loss 0.110226\n",
      "Stage: train, iter: 8420, lr: 6.228e-05, loss 0.049213\n",
      "Stage: train, iter: 8440, lr: 6.213e-05, loss 0.135883\n",
      "Stage: train, iter: 8460, lr: 6.197e-05, loss 0.184036\n",
      "Stage: train, iter: 8480, lr: 6.182e-05, loss 0.117789\n",
      "Stage: train, iter: 8500, lr: 6.167e-05, loss 0.150230\n",
      "Stage: train, iter: 8520, lr: 6.152e-05, loss 0.158203\n",
      "Stage: train, iter: 8540, lr: 6.136e-05, loss 0.172758\n",
      "Stage: train, iter: 8560, lr: 6.121e-05, loss 0.159990\n",
      "Stage: train, iter: 8580, lr: 6.106e-05, loss 0.087498\n",
      "Stage: train, iter: 8600, lr: 6.090e-05, loss 0.083715\n",
      "Stage: train, iter: 8620, lr: 6.075e-05, loss 0.150836\n",
      "Stage: train, iter: 8640, lr: 6.060e-05, loss 0.125246\n",
      "Stage: train, iter: 8660, lr: 6.044e-05, loss 0.103317\n",
      "Stage: train, iter: 8680, lr: 6.029e-05, loss 0.096671\n",
      "Stage: train, iter: 8700, lr: 6.014e-05, loss 0.112652\n",
      "Stage: train, iter: 8720, lr: 5.998e-05, loss 0.078054\n",
      "Stage: train, iter: 8740, lr: 5.983e-05, loss 0.127277\n",
      "Stage: train, iter: 8760, lr: 5.967e-05, loss 0.122311\n",
      "Stage: train, iter: 8780, lr: 5.952e-05, loss 0.078529\n",
      "Stage: train, iter: 8800, lr: 5.937e-05, loss 0.169564\n",
      "Stage: train, iter: 8820, lr: 5.921e-05, loss 0.122320\n",
      "Stage: train, iter: 8840, lr: 5.906e-05, loss 0.101053\n",
      "Stage: train, iter: 8860, lr: 5.890e-05, loss 0.148779\n",
      "Stage: train, iter: 8880, lr: 5.875e-05, loss 0.085409\n",
      "Stage: train, iter: 8900, lr: 5.859e-05, loss 0.139296\n",
      "Stage: train, iter: 8920, lr: 5.844e-05, loss 0.207961\n",
      "Stage: train, iter: 8940, lr: 5.828e-05, loss 0.153882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 8960, lr: 5.813e-05, loss 0.090967\n",
      "Stage: train, iter: 8980, lr: 5.797e-05, loss 0.086160\n",
      "Stage: train, iter: 9000, lr: 5.782e-05, loss 0.164147\n",
      "Stage: train, iter: 9020, lr: 5.766e-05, loss 0.133598\n",
      "Stage: train, iter: 9040, lr: 5.751e-05, loss 0.108664\n",
      "Stage: train, iter: 9060, lr: 5.735e-05, loss 0.118444\n",
      "Stage: train, iter: 9080, lr: 5.720e-05, loss 0.077046\n",
      "Stage: train, iter: 9100, lr: 5.704e-05, loss 0.155089\n",
      "Stage: train, iter: 9120, lr: 5.689e-05, loss 0.088839\n",
      "Stage: train, iter: 9140, lr: 5.673e-05, loss 0.119321\n",
      "Stage: train, iter: 9160, lr: 5.657e-05, loss 0.127459\n",
      "Stage: train, iter: 9180, lr: 5.642e-05, loss 0.109406\n",
      "Stage: train, iter: 9200, lr: 5.626e-05, loss 0.175160\n",
      "Stage: train, iter: 9220, lr: 5.611e-05, loss 0.173955\n",
      "Stage: train, iter: 9240, lr: 5.595e-05, loss 0.116531\n",
      "Stage: train, iter: 9260, lr: 5.580e-05, loss 0.093263\n",
      "Stage: train, iter: 9280, lr: 5.564e-05, loss 0.126722\n",
      "Stage: train, iter: 9300, lr: 5.548e-05, loss 0.104452\n",
      "Stage: train, iter: 9320, lr: 5.533e-05, loss 0.148697\n",
      "Stage: train, iter: 9340, lr: 5.517e-05, loss 0.175586\n",
      "Stage: train, iter: 9360, lr: 5.501e-05, loss 0.141959\n",
      "Stage: train, iter: 9380, lr: 5.486e-05, loss 0.071539\n",
      "Stage: train, iter: 9400, lr: 5.470e-05, loss 0.052606\n",
      "Stage: train, iter: 9420, lr: 5.455e-05, loss 0.207760\n",
      "Stage: train, iter: 9440, lr: 5.439e-05, loss 0.081120\n",
      "Stage: train, iter: 9460, lr: 5.423e-05, loss 0.133187\n",
      "Stage: train, iter: 9480, lr: 5.408e-05, loss 0.123156\n",
      "Stage: train, iter: 9500, lr: 5.392e-05, loss 0.135770\n",
      "Stage: train, iter: 9520, lr: 5.376e-05, loss 0.100784\n",
      "Stage: train, iter: 9540, lr: 5.361e-05, loss 0.134531\n",
      "Stage: train, iter: 9560, lr: 5.345e-05, loss 0.168728\n",
      "Stage: train, iter: 9580, lr: 5.329e-05, loss 0.158218\n",
      "Stage: train, iter: 9600, lr: 5.314e-05, loss 0.125364\n",
      "Stage: train, iter: 9620, lr: 5.298e-05, loss 0.108142\n",
      "Stage: train, iter: 9640, lr: 5.282e-05, loss 0.133715\n",
      "Stage: train, iter: 9660, lr: 5.267e-05, loss 0.078024\n",
      "Stage: train, iter: 9680, lr: 5.251e-05, loss 0.099040\n",
      "Stage: train, iter: 9700, lr: 5.235e-05, loss 0.142955\n",
      "Stage: train, iter: 9720, lr: 5.219e-05, loss 0.107224\n",
      "Stage: train, iter: 9740, lr: 5.204e-05, loss 0.165722\n",
      "Stage: train, iter: 9760, lr: 5.188e-05, loss 0.072554\n",
      "Stage: train, iter: 9780, lr: 5.172e-05, loss 0.095128\n",
      "Stage: train, iter: 9800, lr: 5.157e-05, loss 0.092327\n",
      "Stage: train, iter: 9820, lr: 5.141e-05, loss 0.160875\n",
      "Stage: train, iter: 9840, lr: 5.125e-05, loss 0.084980\n",
      "Stage: train, iter: 9860, lr: 5.110e-05, loss 0.141622\n",
      "Stage: train, iter: 9880, lr: 5.094e-05, loss 0.129935\n",
      "Stage: train, iter: 9900, lr: 5.078e-05, loss 0.120357\n",
      "Stage: train, iter: 9920, lr: 5.062e-05, loss 0.122419\n",
      "Stage: train, iter: 9940, lr: 5.047e-05, loss 0.115563\n",
      "Stage: train, iter: 9960, lr: 5.031e-05, loss 0.113962\n",
      "Stage: train, iter: 9980, lr: 5.015e-05, loss 0.093494\n",
      "Stage: train, iter: 10000, lr: 5.000e-05, loss 0.121436\n",
      "Stage: train, iter: 10020, lr: 4.984e-05, loss 0.115846\n",
      "Stage: train, iter: 10040, lr: 4.968e-05, loss 0.114728\n",
      "Stage: train, iter: 10060, lr: 4.952e-05, loss 0.180056\n",
      "Stage: train, iter: 10080, lr: 4.937e-05, loss 0.077380\n",
      "Stage: train, iter: 10100, lr: 4.921e-05, loss 0.087974\n",
      "Stage: train, iter: 10120, lr: 4.905e-05, loss 0.148367\n",
      "Stage: train, iter: 10140, lr: 4.890e-05, loss 0.098085\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(pjoin(experiment_dir, 'train_log.txt'))\n",
    "\n",
    "model = get_model()\n",
    "model.load_state_dict(torch.load('./output/res50_i512_ch128_dice0.5/model_180000.pt'))\n",
    "\n",
    "start_lr = 1e-4\n",
    "optimizer = Adam(model.parameters(), lr=start_lr)\n",
    "# lr_policy = StepLR(1e-5, 20000, lr_decay=0.5)\n",
    "lr_policy = CyclicLR(start_lr, 20000)\n",
    "criterion = BCEDiceLoss(w_bce=1, w_dice=0.5)\n",
    "\n",
    "train_dict = {\n",
    "    'model': model,\n",
    "    'output_dirpath': experiment_dir,\n",
    "    'optimizer': optimizer,\n",
    "    'lr_policy': lr_policy,\n",
    "#     'start_iter': 200000,\n",
    "    'num_iters': 200000,\n",
    "    'criterion': criterion,\n",
    "    'train_dataloader': dl_train,\n",
    "    'val_set': val_set,\n",
    "    'logger': logger,\n",
    "}\n",
    "train_hist = train(**train_dict)\n",
    "\n",
    "model_dirpath = join(experiment_dir, f'model_last.pt')\n",
    "torch.save(model.state_dict(), model_dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'res50_i512_ch128_dice0.5_train+val'\n",
    "experiment_dir = OUTPUT_DIR + experiment_name\n",
    "#!rm -r {experiment_dir}\n",
    "!mkdir -p {experiment_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = Dataset(IMAGE_SZ, train_set + val_set, epoch_mul=epoch_mul)\n",
    "dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 0, lr: 1.000e-05, loss 0.063101\n",
      "Stage: train, iter: 20, lr: 1.000e-05, loss 0.108421\n",
      "Stage: train, iter: 40, lr: 1.000e-05, loss 0.091700\n",
      "Stage: train, iter: 60, lr: 1.000e-05, loss 0.126670\n",
      "Stage: train, iter: 80, lr: 1.000e-05, loss 0.098768\n",
      "Stage: train, iter: 100, lr: 9.999e-06, loss 0.084430\n",
      "Stage: train, iter: 120, lr: 9.999e-06, loss 0.054597\n",
      "Stage: train, iter: 140, lr: 9.999e-06, loss 0.055674\n",
      "Stage: train, iter: 160, lr: 9.998e-06, loss 0.139285\n",
      "Stage: train, iter: 180, lr: 9.998e-06, loss 0.071402\n",
      "Stage: train, iter: 200, lr: 9.998e-06, loss 0.109633\n",
      "Stage: train, iter: 220, lr: 9.997e-06, loss 0.082866\n",
      "Stage: train, iter: 240, lr: 9.996e-06, loss 0.103660\n",
      "Stage: train, iter: 260, lr: 9.996e-06, loss 0.114150\n",
      "Stage: train, iter: 280, lr: 9.995e-06, loss 0.099381\n",
      "Stage: train, iter: 300, lr: 9.994e-06, loss 0.092966\n",
      "Stage: train, iter: 320, lr: 9.994e-06, loss 0.083791\n",
      "Stage: train, iter: 340, lr: 9.993e-06, loss 0.092606\n",
      "Stage: train, iter: 360, lr: 9.992e-06, loss 0.089806\n",
      "Stage: train, iter: 380, lr: 9.991e-06, loss 0.119121\n",
      "Stage: train, iter: 400, lr: 9.990e-06, loss 0.106890\n",
      "Stage: train, iter: 420, lr: 9.989e-06, loss 0.082151\n",
      "Stage: train, iter: 440, lr: 9.988e-06, loss 0.176761\n",
      "Stage: train, iter: 460, lr: 9.987e-06, loss 0.080050\n",
      "Stage: train, iter: 480, lr: 9.986e-06, loss 0.084781\n",
      "Stage: train, iter: 500, lr: 9.985e-06, loss 0.132657\n",
      "Stage: train, iter: 520, lr: 9.983e-06, loss 0.104056\n",
      "Stage: train, iter: 540, lr: 9.982e-06, loss 0.081723\n",
      "Stage: train, iter: 560, lr: 9.981e-06, loss 0.047265\n",
      "Stage: train, iter: 580, lr: 9.979e-06, loss 0.084732\n",
      "Stage: train, iter: 600, lr: 9.978e-06, loss 0.090048\n",
      "Stage: train, iter: 620, lr: 9.976e-06, loss 0.100829\n",
      "Stage: train, iter: 640, lr: 9.975e-06, loss 0.198819\n",
      "Stage: train, iter: 660, lr: 9.973e-06, loss 0.088910\n",
      "Stage: train, iter: 680, lr: 9.972e-06, loss 0.100160\n",
      "Stage: train, iter: 700, lr: 9.970e-06, loss 0.102595\n",
      "Stage: train, iter: 720, lr: 9.968e-06, loss 0.085234\n",
      "Stage: train, iter: 740, lr: 9.966e-06, loss 0.070767\n",
      "Stage: train, iter: 760, lr: 9.964e-06, loss 0.085947\n",
      "Stage: train, iter: 780, lr: 9.963e-06, loss 0.069073\n",
      "Stage: train, iter: 800, lr: 9.961e-06, loss 0.121662\n",
      "Stage: train, iter: 820, lr: 9.959e-06, loss 0.066653\n",
      "Stage: train, iter: 840, lr: 9.957e-06, loss 0.083347\n",
      "Stage: train, iter: 860, lr: 9.954e-06, loss 0.091113\n",
      "Stage: train, iter: 880, lr: 9.952e-06, loss 0.089260\n",
      "Stage: train, iter: 900, lr: 9.950e-06, loss 0.140862\n",
      "Stage: train, iter: 920, lr: 9.948e-06, loss 0.144818\n",
      "Stage: train, iter: 940, lr: 9.946e-06, loss 0.117036\n",
      "Stage: train, iter: 960, lr: 9.943e-06, loss 0.061685\n",
      "Stage: train, iter: 980, lr: 9.941e-06, loss 0.090017\n",
      "Stage: train, iter: 1000, lr: 9.938e-06, loss 0.204397\n",
      "Stage: train, iter: 1020, lr: 9.936e-06, loss 0.077912\n",
      "Stage: train, iter: 1040, lr: 9.933e-06, loss 0.133161\n",
      "Stage: train, iter: 1060, lr: 9.931e-06, loss 0.056567\n",
      "Stage: train, iter: 1080, lr: 9.928e-06, loss 0.081708\n",
      "Stage: train, iter: 1100, lr: 9.926e-06, loss 0.117137\n",
      "Stage: train, iter: 1120, lr: 9.923e-06, loss 0.131188\n",
      "Stage: train, iter: 1140, lr: 9.920e-06, loss 0.119002\n",
      "Stage: train, iter: 1160, lr: 9.917e-06, loss 0.063419\n",
      "Stage: train, iter: 1180, lr: 9.914e-06, loss 0.081623\n",
      "Stage: train, iter: 1200, lr: 9.911e-06, loss 0.071118\n",
      "Stage: train, iter: 1220, lr: 9.908e-06, loss 0.079028\n",
      "Stage: train, iter: 1240, lr: 9.905e-06, loss 0.099852\n",
      "Stage: train, iter: 1260, lr: 9.902e-06, loss 0.081660\n",
      "Stage: train, iter: 1280, lr: 9.899e-06, loss 0.115919\n",
      "Stage: train, iter: 1300, lr: 9.896e-06, loss 0.077466\n",
      "Stage: train, iter: 1320, lr: 9.893e-06, loss 0.074381\n",
      "Stage: train, iter: 1340, lr: 9.890e-06, loss 0.108230\n",
      "Stage: train, iter: 1360, lr: 9.886e-06, loss 0.081951\n",
      "Stage: train, iter: 1380, lr: 9.883e-06, loss 0.104810\n",
      "Stage: train, iter: 1400, lr: 9.880e-06, loss 0.081106\n",
      "Stage: train, iter: 1420, lr: 9.876e-06, loss 0.078626\n",
      "Stage: train, iter: 1440, lr: 9.873e-06, loss 0.129463\n",
      "Stage: train, iter: 1460, lr: 9.869e-06, loss 0.108355\n",
      "Stage: train, iter: 1480, lr: 9.865e-06, loss 0.066096\n",
      "Stage: train, iter: 1500, lr: 9.862e-06, loss 0.084682\n",
      "Stage: train, iter: 1520, lr: 9.858e-06, loss 0.096813\n",
      "Stage: train, iter: 1540, lr: 9.854e-06, loss 0.095129\n",
      "Stage: train, iter: 1560, lr: 9.851e-06, loss 0.060441\n",
      "Stage: train, iter: 1580, lr: 9.847e-06, loss 0.131961\n",
      "Stage: train, iter: 1600, lr: 9.843e-06, loss 0.062353\n",
      "Stage: train, iter: 1620, lr: 9.839e-06, loss 0.091290\n",
      "Stage: train, iter: 1640, lr: 9.835e-06, loss 0.081574\n",
      "Stage: train, iter: 1660, lr: 9.831e-06, loss 0.109395\n",
      "Stage: train, iter: 1680, lr: 9.827e-06, loss 0.095676\n",
      "Stage: train, iter: 1700, lr: 9.823e-06, loss 0.077935\n",
      "Stage: train, iter: 1720, lr: 9.819e-06, loss 0.094967\n",
      "Stage: train, iter: 1740, lr: 9.814e-06, loss 0.093765\n",
      "Stage: train, iter: 1760, lr: 9.810e-06, loss 0.117116\n",
      "Stage: train, iter: 1780, lr: 9.806e-06, loss 0.086167\n",
      "Stage: train, iter: 1800, lr: 9.801e-06, loss 0.086390\n",
      "Stage: train, iter: 1820, lr: 9.797e-06, loss 0.106047\n",
      "Stage: train, iter: 1840, lr: 9.793e-06, loss 0.081237\n",
      "Stage: train, iter: 1860, lr: 9.788e-06, loss 0.088662\n",
      "Stage: train, iter: 1880, lr: 9.784e-06, loss 0.258671\n",
      "Stage: train, iter: 1900, lr: 9.779e-06, loss 0.128100\n",
      "Stage: train, iter: 1920, lr: 9.774e-06, loss 0.124378\n",
      "Stage: train, iter: 1940, lr: 9.770e-06, loss 0.075487\n",
      "Stage: train, iter: 1960, lr: 9.765e-06, loss 0.149538\n",
      "Stage: train, iter: 1980, lr: 9.760e-06, loss 0.079558\n",
      "Stage: train, iter: 2000, lr: 9.755e-06, loss 0.088860\n",
      "Stage: train, iter: 2020, lr: 9.750e-06, loss 0.137416\n",
      "Stage: train, iter: 2040, lr: 9.745e-06, loss 0.091094\n",
      "Stage: train, iter: 2060, lr: 9.740e-06, loss 0.103079\n",
      "Stage: train, iter: 2080, lr: 9.735e-06, loss 0.101187\n",
      "Stage: train, iter: 2100, lr: 9.730e-06, loss 0.091832\n",
      "Stage: train, iter: 2120, lr: 9.725e-06, loss 0.081255\n",
      "Stage: train, iter: 2140, lr: 9.720e-06, loss 0.089141\n",
      "Stage: train, iter: 2160, lr: 9.715e-06, loss 0.066403\n",
      "Stage: train, iter: 2180, lr: 9.710e-06, loss 0.081255\n",
      "Stage: train, iter: 2200, lr: 9.704e-06, loss 0.127416\n",
      "Stage: train, iter: 2220, lr: 9.699e-06, loss 0.083300\n",
      "Stage: train, iter: 2240, lr: 9.694e-06, loss 0.069721\n",
      "Stage: train, iter: 2260, lr: 9.688e-06, loss 0.129450\n",
      "Stage: train, iter: 2280, lr: 9.683e-06, loss 0.078062\n",
      "Stage: train, iter: 2300, lr: 9.677e-06, loss 0.101667\n",
      "Stage: train, iter: 2320, lr: 9.672e-06, loss 0.118180\n",
      "Stage: train, iter: 2340, lr: 9.666e-06, loss 0.069321\n",
      "Stage: train, iter: 2360, lr: 9.660e-06, loss 0.083825\n",
      "Stage: train, iter: 2380, lr: 9.655e-06, loss 0.078583\n",
      "Stage: train, iter: 2400, lr: 9.649e-06, loss 0.140521\n",
      "Stage: train, iter: 2420, lr: 9.643e-06, loss 0.082196\n",
      "Stage: train, iter: 2440, lr: 9.637e-06, loss 0.093390\n",
      "Stage: train, iter: 2460, lr: 9.631e-06, loss 0.142730\n",
      "Stage: train, iter: 2480, lr: 9.625e-06, loss 0.086573\n",
      "Stage: train, iter: 2500, lr: 9.619e-06, loss 0.089200\n",
      "Stage: train, iter: 2520, lr: 9.613e-06, loss 0.085490\n",
      "Stage: train, iter: 2540, lr: 9.607e-06, loss 0.118226\n",
      "Stage: train, iter: 2560, lr: 9.601e-06, loss 0.120388\n",
      "Stage: train, iter: 2580, lr: 9.595e-06, loss 0.087969\n",
      "Stage: train, iter: 2600, lr: 9.589e-06, loss 0.070543\n",
      "Stage: train, iter: 2620, lr: 9.582e-06, loss 0.088273\n",
      "Stage: train, iter: 2640, lr: 9.576e-06, loss 0.095002\n",
      "Stage: train, iter: 2660, lr: 9.570e-06, loss 0.044043\n",
      "Stage: train, iter: 2680, lr: 9.563e-06, loss 0.128410\n",
      "Stage: train, iter: 2700, lr: 9.557e-06, loss 0.060407\n",
      "Stage: train, iter: 2720, lr: 9.550e-06, loss 0.152037\n",
      "Stage: train, iter: 2740, lr: 9.544e-06, loss 0.137999\n",
      "Stage: train, iter: 2760, lr: 9.537e-06, loss 0.098883\n",
      "Stage: train, iter: 2780, lr: 9.531e-06, loss 0.135023\n",
      "Stage: train, iter: 2800, lr: 9.524e-06, loss 0.058912\n",
      "Stage: train, iter: 2820, lr: 9.517e-06, loss 0.116375\n",
      "Stage: train, iter: 2840, lr: 9.511e-06, loss 0.098636\n",
      "Stage: train, iter: 2860, lr: 9.504e-06, loss 0.113108\n",
      "Stage: train, iter: 2880, lr: 9.497e-06, loss 0.062001\n",
      "Stage: train, iter: 2900, lr: 9.490e-06, loss 0.073540\n",
      "Stage: train, iter: 2920, lr: 9.483e-06, loss 0.132299\n",
      "Stage: train, iter: 2940, lr: 9.476e-06, loss 0.099955\n",
      "Stage: train, iter: 2960, lr: 9.469e-06, loss 0.112179\n",
      "Stage: train, iter: 2980, lr: 9.462e-06, loss 0.099383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 3000, lr: 9.455e-06, loss 0.098736\n",
      "Stage: train, iter: 3020, lr: 9.448e-06, loss 0.138734\n",
      "Stage: train, iter: 3040, lr: 9.441e-06, loss 0.070496\n",
      "Stage: train, iter: 3060, lr: 9.433e-06, loss 0.110726\n",
      "Stage: train, iter: 3080, lr: 9.426e-06, loss 0.075645\n",
      "Stage: train, iter: 3100, lr: 9.419e-06, loss 0.091790\n",
      "Stage: train, iter: 3120, lr: 9.411e-06, loss 0.070406\n",
      "Stage: train, iter: 3140, lr: 9.404e-06, loss 0.090732\n",
      "Stage: train, iter: 3160, lr: 9.397e-06, loss 0.076973\n",
      "Stage: train, iter: 3180, lr: 9.389e-06, loss 0.094418\n",
      "Stage: train, iter: 3200, lr: 9.381e-06, loss 0.086077\n",
      "Stage: train, iter: 3220, lr: 9.374e-06, loss 0.079238\n",
      "Stage: train, iter: 3240, lr: 9.366e-06, loss 0.086994\n",
      "Stage: train, iter: 3260, lr: 9.359e-06, loss 0.073030\n",
      "Stage: train, iter: 3280, lr: 9.351e-06, loss 0.062822\n",
      "Stage: train, iter: 3300, lr: 9.343e-06, loss 0.134609\n",
      "Stage: train, iter: 3320, lr: 9.335e-06, loss 0.078562\n",
      "Stage: train, iter: 3340, lr: 9.327e-06, loss 0.109214\n",
      "Stage: train, iter: 3360, lr: 9.320e-06, loss 0.116557\n",
      "Stage: train, iter: 3380, lr: 9.312e-06, loss 0.063271\n",
      "Stage: train, iter: 3400, lr: 9.304e-06, loss 0.080179\n",
      "Stage: train, iter: 3420, lr: 9.296e-06, loss 0.070383\n",
      "Stage: train, iter: 3440, lr: 9.288e-06, loss 0.095697\n",
      "Stage: train, iter: 3460, lr: 9.279e-06, loss 0.086880\n",
      "Stage: train, iter: 3480, lr: 9.271e-06, loss 0.082088\n",
      "Stage: train, iter: 3500, lr: 9.263e-06, loss 0.102908\n",
      "Stage: train, iter: 3520, lr: 9.255e-06, loss 0.095396\n",
      "Stage: train, iter: 3540, lr: 9.247e-06, loss 0.068691\n",
      "Stage: train, iter: 3560, lr: 9.238e-06, loss 0.106407\n",
      "Stage: train, iter: 3580, lr: 9.230e-06, loss 0.066839\n",
      "Stage: train, iter: 3600, lr: 9.222e-06, loss 0.112730\n",
      "Stage: train, iter: 3620, lr: 9.213e-06, loss 0.141116\n",
      "Stage: train, iter: 3640, lr: 9.205e-06, loss 0.069248\n",
      "Stage: train, iter: 3660, lr: 9.196e-06, loss 0.083926\n",
      "Stage: train, iter: 3680, lr: 9.188e-06, loss 0.097796\n",
      "Stage: train, iter: 3700, lr: 9.179e-06, loss 0.107070\n",
      "Stage: train, iter: 3720, lr: 9.170e-06, loss 0.085209\n",
      "Stage: train, iter: 3740, lr: 9.162e-06, loss 0.101574\n",
      "Stage: train, iter: 3760, lr: 9.153e-06, loss 0.109137\n",
      "Stage: train, iter: 3780, lr: 9.144e-06, loss 0.190812\n",
      "Stage: train, iter: 3800, lr: 9.135e-06, loss 0.092757\n",
      "Stage: train, iter: 3820, lr: 9.126e-06, loss 0.041265\n",
      "Stage: train, iter: 3840, lr: 9.118e-06, loss 0.073666\n",
      "Stage: train, iter: 3860, lr: 9.109e-06, loss 0.107420\n",
      "Stage: train, iter: 3880, lr: 9.100e-06, loss 0.099858\n",
      "Stage: train, iter: 3900, lr: 9.091e-06, loss 0.107181\n",
      "Stage: train, iter: 3920, lr: 9.082e-06, loss 0.107331\n",
      "Stage: train, iter: 3940, lr: 9.073e-06, loss 0.075833\n",
      "Stage: train, iter: 3960, lr: 9.063e-06, loss 0.048112\n",
      "Stage: train, iter: 3980, lr: 9.054e-06, loss 0.102175\n",
      "Stage: train, iter: 4000, lr: 9.045e-06, loss 0.107429\n",
      "Stage: train, iter: 4020, lr: 9.036e-06, loss 0.082761\n",
      "Stage: train, iter: 4040, lr: 9.026e-06, loss 0.055190\n",
      "Stage: train, iter: 4060, lr: 9.017e-06, loss 0.090484\n",
      "Stage: train, iter: 4080, lr: 9.008e-06, loss 0.091169\n",
      "Stage: train, iter: 4100, lr: 8.998e-06, loss 0.092392\n",
      "Stage: train, iter: 4120, lr: 8.989e-06, loss 0.088049\n",
      "Stage: train, iter: 4140, lr: 8.979e-06, loss 0.099392\n",
      "Stage: train, iter: 4160, lr: 8.970e-06, loss 0.083324\n",
      "Stage: train, iter: 4180, lr: 8.960e-06, loss 0.072283\n",
      "Stage: train, iter: 4200, lr: 8.951e-06, loss 0.070629\n",
      "Stage: train, iter: 4220, lr: 8.941e-06, loss 0.105275\n",
      "Stage: train, iter: 4240, lr: 8.931e-06, loss 0.064139\n",
      "Stage: train, iter: 4260, lr: 8.922e-06, loss 0.065940\n",
      "Stage: train, iter: 4280, lr: 8.912e-06, loss 0.063492\n",
      "Stage: train, iter: 4300, lr: 8.902e-06, loss 0.097682\n",
      "Stage: train, iter: 4320, lr: 8.892e-06, loss 0.148309\n",
      "Stage: train, iter: 4340, lr: 8.882e-06, loss 0.062915\n",
      "Stage: train, iter: 4360, lr: 8.872e-06, loss 0.106982\n",
      "Stage: train, iter: 4380, lr: 8.862e-06, loss 0.095905\n",
      "Stage: train, iter: 4400, lr: 8.852e-06, loss 0.085850\n",
      "Stage: train, iter: 4420, lr: 8.842e-06, loss 0.098316\n",
      "Stage: train, iter: 4440, lr: 8.832e-06, loss 0.083561\n",
      "Stage: train, iter: 4460, lr: 8.822e-06, loss 0.136700\n",
      "Stage: train, iter: 4480, lr: 8.812e-06, loss 0.041062\n",
      "Stage: train, iter: 4500, lr: 8.802e-06, loss 0.089491\n",
      "Stage: train, iter: 4520, lr: 8.792e-06, loss 0.115353\n",
      "Stage: train, iter: 4540, lr: 8.781e-06, loss 0.125345\n",
      "Stage: train, iter: 4560, lr: 8.771e-06, loss 0.082018\n",
      "Stage: train, iter: 4580, lr: 8.761e-06, loss 0.114779\n",
      "Stage: train, iter: 4600, lr: 8.750e-06, loss 0.087957\n",
      "Stage: train, iter: 4620, lr: 8.740e-06, loss 0.078187\n",
      "Stage: train, iter: 4640, lr: 8.730e-06, loss 0.099333\n",
      "Stage: train, iter: 4660, lr: 8.719e-06, loss 0.072909\n",
      "Stage: train, iter: 4680, lr: 8.709e-06, loss 0.124065\n",
      "Stage: train, iter: 4700, lr: 8.698e-06, loss 0.065160\n",
      "Stage: train, iter: 4720, lr: 8.687e-06, loss 0.071730\n",
      "Stage: train, iter: 4740, lr: 8.677e-06, loss 0.091439\n",
      "Stage: train, iter: 4760, lr: 8.666e-06, loss 0.068673\n",
      "Stage: train, iter: 4780, lr: 8.655e-06, loss 0.101693\n",
      "Stage: train, iter: 4800, lr: 8.645e-06, loss 0.123265\n",
      "Stage: train, iter: 4820, lr: 8.634e-06, loss 0.106161\n",
      "Stage: train, iter: 4840, lr: 8.623e-06, loss 0.096038\n",
      "Stage: train, iter: 4860, lr: 8.612e-06, loss 0.080529\n",
      "Stage: train, iter: 4880, lr: 8.601e-06, loss 0.116674\n",
      "Stage: train, iter: 4900, lr: 8.590e-06, loss 0.109560\n",
      "Stage: train, iter: 4920, lr: 8.580e-06, loss 0.098903\n",
      "Stage: train, iter: 4940, lr: 8.569e-06, loss 0.074741\n",
      "Stage: train, iter: 4960, lr: 8.558e-06, loss 0.143781\n",
      "Stage: train, iter: 4980, lr: 8.546e-06, loss 0.073263\n",
      "Stage: train, iter: 5000, lr: 8.535e-06, loss 0.109853\n",
      "Stage: train, iter: 5020, lr: 8.524e-06, loss 0.082557\n",
      "Stage: train, iter: 5040, lr: 8.513e-06, loss 0.078840\n",
      "Stage: train, iter: 5060, lr: 8.502e-06, loss 0.118381\n",
      "Stage: train, iter: 5080, lr: 8.491e-06, loss 0.123309\n",
      "Stage: train, iter: 5100, lr: 8.479e-06, loss 0.079738\n",
      "Stage: train, iter: 5120, lr: 8.468e-06, loss 0.083074\n",
      "Stage: train, iter: 5140, lr: 8.457e-06, loss 0.081500\n",
      "Stage: train, iter: 5160, lr: 8.445e-06, loss 0.115015\n",
      "Stage: train, iter: 5180, lr: 8.434e-06, loss 0.097865\n",
      "Stage: train, iter: 5200, lr: 8.423e-06, loss 0.098398\n",
      "Stage: train, iter: 5220, lr: 8.411e-06, loss 0.065967\n",
      "Stage: train, iter: 5240, lr: 8.400e-06, loss 0.050981\n",
      "Stage: train, iter: 5260, lr: 8.388e-06, loss 0.057932\n",
      "Stage: train, iter: 5280, lr: 8.377e-06, loss 0.091740\n",
      "Stage: train, iter: 5300, lr: 8.365e-06, loss 0.081312\n",
      "Stage: train, iter: 5320, lr: 8.353e-06, loss 0.139583\n",
      "Stage: train, iter: 5340, lr: 8.342e-06, loss 0.098571\n",
      "Stage: train, iter: 5360, lr: 8.330e-06, loss 0.095607\n",
      "Stage: train, iter: 5380, lr: 8.318e-06, loss 0.122595\n",
      "Stage: train, iter: 5400, lr: 8.306e-06, loss 0.066882\n",
      "Stage: train, iter: 5420, lr: 8.295e-06, loss 0.111718\n",
      "Stage: train, iter: 5440, lr: 8.283e-06, loss 0.091386\n",
      "Stage: train, iter: 5460, lr: 8.271e-06, loss 0.073549\n",
      "Stage: train, iter: 5480, lr: 8.259e-06, loss 0.135668\n",
      "Stage: train, iter: 5500, lr: 8.247e-06, loss 0.111281\n",
      "Stage: train, iter: 5520, lr: 8.235e-06, loss 0.122702\n",
      "Stage: train, iter: 5540, lr: 8.223e-06, loss 0.075117\n",
      "Stage: train, iter: 5560, lr: 8.211e-06, loss 0.082905\n",
      "Stage: train, iter: 5580, lr: 8.199e-06, loss 0.073002\n",
      "Stage: train, iter: 5600, lr: 8.187e-06, loss 0.107436\n",
      "Stage: train, iter: 5620, lr: 8.175e-06, loss 0.077573\n",
      "Stage: train, iter: 5640, lr: 8.163e-06, loss 0.058065\n",
      "Stage: train, iter: 5660, lr: 8.150e-06, loss 0.105056\n",
      "Stage: train, iter: 5680, lr: 8.138e-06, loss 0.063086\n",
      "Stage: train, iter: 5700, lr: 8.126e-06, loss 0.062016\n",
      "Stage: train, iter: 5720, lr: 8.114e-06, loss 0.069322\n",
      "Stage: train, iter: 5740, lr: 8.101e-06, loss 0.082939\n",
      "Stage: train, iter: 5760, lr: 8.089e-06, loss 0.144431\n",
      "Stage: train, iter: 5780, lr: 8.077e-06, loss 0.130792\n",
      "Stage: train, iter: 5800, lr: 8.064e-06, loss 0.135046\n",
      "Stage: train, iter: 5820, lr: 8.052e-06, loss 0.070795\n",
      "Stage: train, iter: 5840, lr: 8.039e-06, loss 0.068094\n",
      "Stage: train, iter: 5860, lr: 8.027e-06, loss 0.085128\n",
      "Stage: train, iter: 5880, lr: 8.014e-06, loss 0.148151\n",
      "Stage: train, iter: 5900, lr: 8.002e-06, loss 0.077099\n",
      "Stage: train, iter: 5920, lr: 7.989e-06, loss 0.095995\n",
      "Stage: train, iter: 5940, lr: 7.977e-06, loss 0.146788\n",
      "Stage: train, iter: 5960, lr: 7.964e-06, loss 0.062183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 5980, lr: 7.951e-06, loss 0.078210\n",
      "Stage: train, iter: 6000, lr: 7.939e-06, loss 0.077891\n",
      "Stage: train, iter: 6020, lr: 7.926e-06, loss 0.123904\n",
      "Stage: train, iter: 6040, lr: 7.913e-06, loss 0.070642\n",
      "Stage: train, iter: 6060, lr: 7.900e-06, loss 0.033895\n",
      "Stage: train, iter: 6080, lr: 7.888e-06, loss 0.065946\n",
      "Stage: train, iter: 6100, lr: 7.875e-06, loss 0.067805\n",
      "Stage: train, iter: 6120, lr: 7.862e-06, loss 0.074429\n",
      "Stage: train, iter: 6140, lr: 7.849e-06, loss 0.080810\n",
      "Stage: train, iter: 6160, lr: 7.836e-06, loss 0.058845\n",
      "Stage: train, iter: 6180, lr: 7.823e-06, loss 0.085284\n",
      "Stage: train, iter: 6200, lr: 7.810e-06, loss 0.063423\n",
      "Stage: train, iter: 6220, lr: 7.797e-06, loss 0.066719\n",
      "Stage: train, iter: 6240, lr: 7.784e-06, loss 0.112648\n",
      "Stage: train, iter: 6260, lr: 7.771e-06, loss 0.083744\n",
      "Stage: train, iter: 6280, lr: 7.758e-06, loss 0.103942\n",
      "Stage: train, iter: 6300, lr: 7.745e-06, loss 0.074743\n",
      "Stage: train, iter: 6320, lr: 7.732e-06, loss 0.111440\n",
      "Stage: train, iter: 6340, lr: 7.719e-06, loss 0.119040\n",
      "Stage: train, iter: 6360, lr: 7.705e-06, loss 0.135314\n",
      "Stage: train, iter: 6380, lr: 7.692e-06, loss 0.114211\n",
      "Stage: train, iter: 6400, lr: 7.679e-06, loss 0.188243\n",
      "Stage: train, iter: 6420, lr: 7.666e-06, loss 0.139533\n",
      "Stage: train, iter: 6440, lr: 7.652e-06, loss 0.090092\n",
      "Stage: train, iter: 6460, lr: 7.639e-06, loss 0.053860\n",
      "Stage: train, iter: 6480, lr: 7.626e-06, loss 0.080998\n",
      "Stage: train, iter: 6500, lr: 7.612e-06, loss 0.066016\n",
      "Stage: train, iter: 6520, lr: 7.599e-06, loss 0.057625\n",
      "Stage: train, iter: 6540, lr: 7.585e-06, loss 0.078675\n",
      "Stage: train, iter: 6560, lr: 7.572e-06, loss 0.105601\n",
      "Stage: train, iter: 6580, lr: 7.558e-06, loss 0.083656\n",
      "Stage: train, iter: 6600, lr: 7.545e-06, loss 0.083495\n",
      "Stage: train, iter: 6620, lr: 7.531e-06, loss 0.080064\n",
      "Stage: train, iter: 6640, lr: 7.518e-06, loss 0.089393\n",
      "Stage: train, iter: 6660, lr: 7.504e-06, loss 0.068199\n",
      "Stage: train, iter: 6680, lr: 7.491e-06, loss 0.072153\n",
      "Stage: train, iter: 6700, lr: 7.477e-06, loss 0.111700\n",
      "Stage: train, iter: 6720, lr: 7.463e-06, loss 0.128471\n",
      "Stage: train, iter: 6740, lr: 7.450e-06, loss 0.111238\n",
      "Stage: train, iter: 6760, lr: 7.436e-06, loss 0.094727\n",
      "Stage: train, iter: 6780, lr: 7.422e-06, loss 0.057777\n",
      "Stage: train, iter: 6800, lr: 7.409e-06, loss 0.093744\n",
      "Stage: train, iter: 6820, lr: 7.395e-06, loss 0.089142\n",
      "Stage: train, iter: 6840, lr: 7.381e-06, loss 0.097281\n",
      "Stage: train, iter: 6860, lr: 7.367e-06, loss 0.047863\n",
      "Stage: train, iter: 6880, lr: 7.353e-06, loss 0.050278\n",
      "Stage: train, iter: 6900, lr: 7.339e-06, loss 0.108825\n",
      "Stage: train, iter: 6920, lr: 7.326e-06, loss 0.102933\n",
      "Stage: train, iter: 6940, lr: 7.312e-06, loss 0.103052\n",
      "Stage: train, iter: 6960, lr: 7.298e-06, loss 0.073705\n",
      "Stage: train, iter: 6980, lr: 7.284e-06, loss 0.075723\n",
      "Stage: train, iter: 7000, lr: 7.270e-06, loss 0.083476\n",
      "Stage: train, iter: 7020, lr: 7.256e-06, loss 0.064002\n",
      "Stage: train, iter: 7040, lr: 7.242e-06, loss 0.095453\n",
      "Stage: train, iter: 7060, lr: 7.228e-06, loss 0.049857\n",
      "Stage: train, iter: 7080, lr: 7.214e-06, loss 0.118345\n",
      "Stage: train, iter: 7100, lr: 7.199e-06, loss 0.069217\n",
      "Stage: train, iter: 7120, lr: 7.185e-06, loss 0.046528\n",
      "Stage: train, iter: 7140, lr: 7.171e-06, loss 0.082558\n",
      "Stage: train, iter: 7160, lr: 7.157e-06, loss 0.083533\n",
      "Stage: train, iter: 7180, lr: 7.143e-06, loss 0.092087\n",
      "Stage: train, iter: 7200, lr: 7.129e-06, loss 0.097567\n",
      "Stage: train, iter: 7220, lr: 7.114e-06, loss 0.075538\n",
      "Stage: train, iter: 7240, lr: 7.100e-06, loss 0.070309\n",
      "Stage: train, iter: 7260, lr: 7.086e-06, loss 0.098976\n",
      "Stage: train, iter: 7280, lr: 7.072e-06, loss 0.049816\n",
      "Stage: train, iter: 7300, lr: 7.057e-06, loss 0.084476\n",
      "Stage: train, iter: 7320, lr: 7.043e-06, loss 0.098047\n",
      "Stage: train, iter: 7340, lr: 7.029e-06, loss 0.097674\n",
      "Stage: train, iter: 7360, lr: 7.014e-06, loss 0.059059\n",
      "Stage: train, iter: 7380, lr: 7.000e-06, loss 0.067297\n",
      "Stage: train, iter: 7400, lr: 6.985e-06, loss 0.103875\n",
      "Stage: train, iter: 7420, lr: 6.971e-06, loss 0.090382\n",
      "Stage: train, iter: 7440, lr: 6.957e-06, loss 0.145198\n",
      "Stage: train, iter: 7460, lr: 6.942e-06, loss 0.095250\n",
      "Stage: train, iter: 7480, lr: 6.928e-06, loss 0.084984\n",
      "Stage: train, iter: 7500, lr: 6.913e-06, loss 0.086830\n",
      "Stage: train, iter: 7520, lr: 6.899e-06, loss 0.077815\n",
      "Stage: train, iter: 7540, lr: 6.884e-06, loss 0.098954\n",
      "Stage: train, iter: 7560, lr: 6.870e-06, loss 0.086977\n",
      "Stage: train, iter: 7580, lr: 6.855e-06, loss 0.068401\n",
      "Stage: train, iter: 7600, lr: 6.840e-06, loss 0.041137\n",
      "Stage: train, iter: 7620, lr: 6.826e-06, loss 0.078640\n",
      "Stage: train, iter: 7640, lr: 6.811e-06, loss 0.080715\n",
      "Stage: train, iter: 7660, lr: 6.796e-06, loss 0.134486\n",
      "Stage: train, iter: 7680, lr: 6.782e-06, loss 0.091679\n",
      "Stage: train, iter: 7700, lr: 6.767e-06, loss 0.121151\n",
      "Stage: train, iter: 7720, lr: 6.752e-06, loss 0.107214\n",
      "Stage: train, iter: 7740, lr: 6.738e-06, loss 0.083584\n",
      "Stage: train, iter: 7760, lr: 6.723e-06, loss 0.074533\n",
      "Stage: train, iter: 7780, lr: 6.708e-06, loss 0.043630\n",
      "Stage: train, iter: 7800, lr: 6.693e-06, loss 0.069938\n",
      "Stage: train, iter: 7820, lr: 6.679e-06, loss 0.095207\n",
      "Stage: train, iter: 7840, lr: 6.664e-06, loss 0.113400\n",
      "Stage: train, iter: 7860, lr: 6.649e-06, loss 0.111692\n",
      "Stage: train, iter: 7880, lr: 6.634e-06, loss 0.099389\n",
      "Stage: train, iter: 7900, lr: 6.619e-06, loss 0.093279\n",
      "Stage: train, iter: 7920, lr: 6.604e-06, loss 0.084152\n",
      "Stage: train, iter: 7940, lr: 6.590e-06, loss 0.146409\n",
      "Stage: train, iter: 7960, lr: 6.575e-06, loss 0.054860\n",
      "Stage: train, iter: 7980, lr: 6.560e-06, loss 0.061978\n",
      "Stage: train, iter: 8000, lr: 6.545e-06, loss 0.071569\n",
      "Stage: train, iter: 8020, lr: 6.530e-06, loss 0.052163\n",
      "Stage: train, iter: 8040, lr: 6.515e-06, loss 0.082103\n",
      "Stage: train, iter: 8060, lr: 6.500e-06, loss 0.115076\n",
      "Stage: train, iter: 8080, lr: 6.485e-06, loss 0.078181\n",
      "Stage: train, iter: 8100, lr: 6.470e-06, loss 0.097499\n",
      "Stage: train, iter: 8120, lr: 6.455e-06, loss 0.090179\n",
      "Stage: train, iter: 8140, lr: 6.440e-06, loss 0.104159\n",
      "Stage: train, iter: 8160, lr: 6.425e-06, loss 0.098602\n",
      "Stage: train, iter: 8180, lr: 6.410e-06, loss 0.083660\n",
      "Stage: train, iter: 8200, lr: 6.395e-06, loss 0.090442\n",
      "Stage: train, iter: 8220, lr: 6.380e-06, loss 0.086082\n",
      "Stage: train, iter: 8240, lr: 6.364e-06, loss 0.053803\n",
      "Stage: train, iter: 8260, lr: 6.349e-06, loss 0.110491\n",
      "Stage: train, iter: 8280, lr: 6.334e-06, loss 0.075118\n",
      "Stage: train, iter: 8300, lr: 6.319e-06, loss 0.091422\n",
      "Stage: train, iter: 8320, lr: 6.304e-06, loss 0.115966\n",
      "Stage: train, iter: 8340, lr: 6.289e-06, loss 0.075769\n",
      "Stage: train, iter: 8360, lr: 6.274e-06, loss 0.098300\n",
      "Stage: train, iter: 8380, lr: 6.258e-06, loss 0.085624\n",
      "Stage: train, iter: 8400, lr: 6.243e-06, loss 0.087018\n",
      "Stage: train, iter: 8420, lr: 6.228e-06, loss 0.068407\n",
      "Stage: train, iter: 8440, lr: 6.213e-06, loss 0.082829\n",
      "Stage: train, iter: 8460, lr: 6.197e-06, loss 0.107336\n",
      "Stage: train, iter: 8480, lr: 6.182e-06, loss 0.127891\n",
      "Stage: train, iter: 8500, lr: 6.167e-06, loss 0.137627\n",
      "Stage: train, iter: 8520, lr: 6.152e-06, loss 0.050638\n",
      "Stage: train, iter: 8540, lr: 6.136e-06, loss 0.126154\n",
      "Stage: train, iter: 8560, lr: 6.121e-06, loss 0.072580\n",
      "Stage: train, iter: 8580, lr: 6.106e-06, loss 0.098065\n",
      "Stage: train, iter: 8600, lr: 6.090e-06, loss 0.117108\n",
      "Stage: train, iter: 8620, lr: 6.075e-06, loss 0.092798\n",
      "Stage: train, iter: 8640, lr: 6.060e-06, loss 0.086552\n",
      "Stage: train, iter: 8660, lr: 6.044e-06, loss 0.074296\n",
      "Stage: train, iter: 8680, lr: 6.029e-06, loss 0.125123\n",
      "Stage: train, iter: 8700, lr: 6.014e-06, loss 0.063272\n",
      "Stage: train, iter: 8720, lr: 5.998e-06, loss 0.068529\n",
      "Stage: train, iter: 8740, lr: 5.983e-06, loss 0.048314\n",
      "Stage: train, iter: 8760, lr: 5.967e-06, loss 0.065672\n",
      "Stage: train, iter: 8780, lr: 5.952e-06, loss 0.093044\n",
      "Stage: train, iter: 8800, lr: 5.937e-06, loss 0.114733\n",
      "Stage: train, iter: 8820, lr: 5.921e-06, loss 0.082958\n",
      "Stage: train, iter: 8840, lr: 5.906e-06, loss 0.085593\n",
      "Stage: train, iter: 8860, lr: 5.890e-06, loss 0.092811\n",
      "Stage: train, iter: 8880, lr: 5.875e-06, loss 0.069875\n",
      "Stage: train, iter: 8900, lr: 5.859e-06, loss 0.072169\n",
      "Stage: train, iter: 8920, lr: 5.844e-06, loss 0.081013\n",
      "Stage: train, iter: 8940, lr: 5.828e-06, loss 0.095700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 8960, lr: 5.813e-06, loss 0.088594\n",
      "Stage: train, iter: 8980, lr: 5.797e-06, loss 0.040001\n",
      "Stage: train, iter: 9000, lr: 5.782e-06, loss 0.101004\n",
      "Stage: train, iter: 9020, lr: 5.766e-06, loss 0.078998\n",
      "Stage: train, iter: 9040, lr: 5.751e-06, loss 0.086736\n",
      "Stage: train, iter: 9060, lr: 5.735e-06, loss 0.080655\n",
      "Stage: train, iter: 9080, lr: 5.720e-06, loss 0.076050\n",
      "Stage: train, iter: 9100, lr: 5.704e-06, loss 0.058134\n",
      "Stage: train, iter: 9120, lr: 5.689e-06, loss 0.080617\n",
      "Stage: train, iter: 9140, lr: 5.673e-06, loss 0.077389\n",
      "Stage: train, iter: 9160, lr: 5.657e-06, loss 0.073424\n",
      "Stage: train, iter: 9180, lr: 5.642e-06, loss 0.124537\n",
      "Stage: train, iter: 9200, lr: 5.626e-06, loss 0.057966\n",
      "Stage: train, iter: 9220, lr: 5.611e-06, loss 0.048729\n",
      "Stage: train, iter: 9240, lr: 5.595e-06, loss 0.093172\n",
      "Stage: train, iter: 9260, lr: 5.580e-06, loss 0.087205\n",
      "Stage: train, iter: 9280, lr: 5.564e-06, loss 0.086633\n",
      "Stage: train, iter: 9300, lr: 5.548e-06, loss 0.111675\n",
      "Stage: train, iter: 9320, lr: 5.533e-06, loss 0.102720\n",
      "Stage: train, iter: 9340, lr: 5.517e-06, loss 0.089355\n",
      "Stage: train, iter: 9360, lr: 5.501e-06, loss 0.145726\n",
      "Stage: train, iter: 9380, lr: 5.486e-06, loss 0.095733\n",
      "Stage: train, iter: 9400, lr: 5.470e-06, loss 0.045988\n",
      "Stage: train, iter: 9420, lr: 5.455e-06, loss 0.064734\n",
      "Stage: train, iter: 9440, lr: 5.439e-06, loss 0.111992\n",
      "Stage: train, iter: 9460, lr: 5.423e-06, loss 0.077183\n",
      "Stage: train, iter: 9480, lr: 5.408e-06, loss 0.058850\n",
      "Stage: train, iter: 9500, lr: 5.392e-06, loss 0.099108\n",
      "Stage: train, iter: 9520, lr: 5.376e-06, loss 0.118944\n",
      "Stage: train, iter: 9540, lr: 5.361e-06, loss 0.071844\n",
      "Stage: train, iter: 9560, lr: 5.345e-06, loss 0.101585\n",
      "Stage: train, iter: 9580, lr: 5.329e-06, loss 0.074930\n",
      "Stage: train, iter: 9600, lr: 5.314e-06, loss 0.127201\n",
      "Stage: train, iter: 9620, lr: 5.298e-06, loss 0.100868\n",
      "Stage: train, iter: 9640, lr: 5.282e-06, loss 0.087178\n",
      "Stage: train, iter: 9660, lr: 5.267e-06, loss 0.089792\n",
      "Stage: train, iter: 9680, lr: 5.251e-06, loss 0.074745\n",
      "Stage: train, iter: 9700, lr: 5.235e-06, loss 0.079840\n",
      "Stage: train, iter: 9720, lr: 5.219e-06, loss 0.089162\n",
      "Stage: train, iter: 9740, lr: 5.204e-06, loss 0.049878\n",
      "Stage: train, iter: 9760, lr: 5.188e-06, loss 0.078569\n",
      "Stage: train, iter: 9780, lr: 5.172e-06, loss 0.105704\n",
      "Stage: train, iter: 9800, lr: 5.157e-06, loss 0.061621\n",
      "Stage: train, iter: 9820, lr: 5.141e-06, loss 0.076477\n",
      "Stage: train, iter: 9840, lr: 5.125e-06, loss 0.091847\n",
      "Stage: train, iter: 9860, lr: 5.110e-06, loss 0.068178\n",
      "Stage: train, iter: 9880, lr: 5.094e-06, loss 0.076544\n",
      "Stage: train, iter: 9900, lr: 5.078e-06, loss 0.096760\n",
      "Stage: train, iter: 9920, lr: 5.062e-06, loss 0.087139\n",
      "Stage: train, iter: 9940, lr: 5.047e-06, loss 0.081309\n",
      "Stage: train, iter: 9960, lr: 5.031e-06, loss 0.081985\n",
      "Stage: train, iter: 9980, lr: 5.015e-06, loss 0.099232\n",
      "Stage: train, iter: 10000, lr: 5.000e-06, loss 0.091711\n",
      "Stage: train, iter: 10020, lr: 4.984e-06, loss 0.106133\n",
      "Stage: train, iter: 10040, lr: 4.968e-06, loss 0.079621\n",
      "Stage: train, iter: 10060, lr: 4.952e-06, loss 0.079549\n",
      "Stage: train, iter: 10080, lr: 4.937e-06, loss 0.069262\n",
      "Stage: train, iter: 10100, lr: 4.921e-06, loss 0.105626\n",
      "Stage: train, iter: 10120, lr: 4.905e-06, loss 0.059955\n",
      "Stage: train, iter: 10140, lr: 4.890e-06, loss 0.083668\n",
      "Stage: train, iter: 10160, lr: 4.874e-06, loss 0.060165\n",
      "Stage: train, iter: 10180, lr: 4.858e-06, loss 0.102297\n",
      "Stage: train, iter: 10200, lr: 4.843e-06, loss 0.052538\n",
      "Stage: train, iter: 10220, lr: 4.827e-06, loss 0.129487\n",
      "Stage: train, iter: 10240, lr: 4.811e-06, loss 0.086658\n",
      "Stage: train, iter: 10260, lr: 4.795e-06, loss 0.094671\n",
      "Stage: train, iter: 10280, lr: 4.780e-06, loss 0.025046\n",
      "Stage: train, iter: 10300, lr: 4.764e-06, loss 0.127203\n",
      "Stage: train, iter: 10320, lr: 4.748e-06, loss 0.086400\n",
      "Stage: train, iter: 10340, lr: 4.733e-06, loss 0.124647\n",
      "Stage: train, iter: 10360, lr: 4.717e-06, loss 0.036133\n",
      "Stage: train, iter: 10380, lr: 4.701e-06, loss 0.098200\n",
      "Stage: train, iter: 10400, lr: 4.686e-06, loss 0.115491\n",
      "Stage: train, iter: 10420, lr: 4.670e-06, loss 0.084868\n",
      "Stage: train, iter: 10440, lr: 4.654e-06, loss 0.119613\n",
      "Stage: train, iter: 10460, lr: 4.639e-06, loss 0.122739\n",
      "Stage: train, iter: 10480, lr: 4.623e-06, loss 0.046279\n",
      "Stage: train, iter: 10500, lr: 4.607e-06, loss 0.084353\n",
      "Stage: train, iter: 10520, lr: 4.592e-06, loss 0.141451\n",
      "Stage: train, iter: 10540, lr: 4.576e-06, loss 0.067289\n",
      "Stage: train, iter: 10560, lr: 4.560e-06, loss 0.057976\n",
      "Stage: train, iter: 10580, lr: 4.545e-06, loss 0.095278\n",
      "Stage: train, iter: 10600, lr: 4.529e-06, loss 0.060808\n",
      "Stage: train, iter: 10620, lr: 4.513e-06, loss 0.107830\n",
      "Stage: train, iter: 10640, lr: 4.498e-06, loss 0.119756\n",
      "Stage: train, iter: 10660, lr: 4.482e-06, loss 0.096306\n",
      "Stage: train, iter: 10680, lr: 4.467e-06, loss 0.058700\n",
      "Stage: train, iter: 10700, lr: 4.451e-06, loss 0.086033\n",
      "Stage: train, iter: 10720, lr: 4.435e-06, loss 0.065448\n",
      "Stage: train, iter: 10740, lr: 4.420e-06, loss 0.112351\n",
      "Stage: train, iter: 10760, lr: 4.404e-06, loss 0.082288\n",
      "Stage: train, iter: 10780, lr: 4.389e-06, loss 0.059108\n",
      "Stage: train, iter: 10800, lr: 4.373e-06, loss 0.122690\n",
      "Stage: train, iter: 10820, lr: 4.357e-06, loss 0.106611\n",
      "Stage: train, iter: 10840, lr: 4.342e-06, loss 0.093232\n",
      "Stage: train, iter: 10860, lr: 4.326e-06, loss 0.073801\n",
      "Stage: train, iter: 10880, lr: 4.311e-06, loss 0.099206\n",
      "Stage: train, iter: 10900, lr: 4.295e-06, loss 0.078599\n",
      "Stage: train, iter: 10920, lr: 4.280e-06, loss 0.060285\n",
      "Stage: train, iter: 10940, lr: 4.264e-06, loss 0.091368\n",
      "Stage: train, iter: 10960, lr: 4.248e-06, loss 0.074284\n",
      "Stage: train, iter: 10980, lr: 4.233e-06, loss 0.106719\n",
      "Stage: train, iter: 11000, lr: 4.217e-06, loss 0.071446\n",
      "Stage: train, iter: 11020, lr: 4.202e-06, loss 0.102651\n",
      "Stage: train, iter: 11040, lr: 4.186e-06, loss 0.090692\n",
      "Stage: train, iter: 11060, lr: 4.171e-06, loss 0.082450\n",
      "Stage: train, iter: 11080, lr: 4.155e-06, loss 0.082384\n",
      "Stage: train, iter: 11100, lr: 4.140e-06, loss 0.074972\n",
      "Stage: train, iter: 11120, lr: 4.124e-06, loss 0.092796\n",
      "Stage: train, iter: 11140, lr: 4.109e-06, loss 0.095483\n",
      "Stage: train, iter: 11160, lr: 4.094e-06, loss 0.087502\n",
      "Stage: train, iter: 11180, lr: 4.078e-06, loss 0.083803\n",
      "Stage: train, iter: 11200, lr: 4.063e-06, loss 0.047192\n",
      "Stage: train, iter: 11220, lr: 4.047e-06, loss 0.130848\n",
      "Stage: train, iter: 11240, lr: 4.032e-06, loss 0.083371\n",
      "Stage: train, iter: 11260, lr: 4.016e-06, loss 0.064310\n",
      "Stage: train, iter: 11280, lr: 4.001e-06, loss 0.079970\n",
      "Stage: train, iter: 11300, lr: 3.986e-06, loss 0.066561\n",
      "Stage: train, iter: 11320, lr: 3.970e-06, loss 0.074733\n",
      "Stage: train, iter: 11340, lr: 3.955e-06, loss 0.081139\n",
      "Stage: train, iter: 11360, lr: 3.940e-06, loss 0.111404\n",
      "Stage: train, iter: 11380, lr: 3.924e-06, loss 0.047140\n",
      "Stage: train, iter: 11400, lr: 3.909e-06, loss 0.066570\n",
      "Stage: train, iter: 11420, lr: 3.894e-06, loss 0.110704\n",
      "Stage: train, iter: 11440, lr: 3.878e-06, loss 0.088580\n",
      "Stage: train, iter: 11460, lr: 3.863e-06, loss 0.097609\n",
      "Stage: train, iter: 11480, lr: 3.848e-06, loss 0.107412\n",
      "Stage: train, iter: 11500, lr: 3.832e-06, loss 0.113251\n",
      "Stage: train, iter: 11520, lr: 3.817e-06, loss 0.102999\n",
      "Stage: train, iter: 11540, lr: 3.802e-06, loss 0.127294\n",
      "Stage: train, iter: 11560, lr: 3.787e-06, loss 0.047444\n",
      "Stage: train, iter: 11580, lr: 3.771e-06, loss 0.074618\n",
      "Stage: train, iter: 11600, lr: 3.756e-06, loss 0.077096\n",
      "Stage: train, iter: 11620, lr: 3.741e-06, loss 0.100866\n",
      "Stage: train, iter: 11640, lr: 3.726e-06, loss 0.087356\n",
      "Stage: train, iter: 11660, lr: 3.711e-06, loss 0.059622\n",
      "Stage: train, iter: 11680, lr: 3.695e-06, loss 0.115595\n",
      "Stage: train, iter: 11700, lr: 3.680e-06, loss 0.098632\n",
      "Stage: train, iter: 11720, lr: 3.665e-06, loss 0.105254\n",
      "Stage: train, iter: 11740, lr: 3.650e-06, loss 0.053862\n",
      "Stage: train, iter: 11760, lr: 3.635e-06, loss 0.085465\n",
      "Stage: train, iter: 11780, lr: 3.620e-06, loss 0.117604\n",
      "Stage: train, iter: 11800, lr: 3.605e-06, loss 0.057193\n",
      "Stage: train, iter: 11820, lr: 3.590e-06, loss 0.112477\n",
      "Stage: train, iter: 11840, lr: 3.574e-06, loss 0.082701\n",
      "Stage: train, iter: 11860, lr: 3.559e-06, loss 0.118947\n",
      "Stage: train, iter: 11880, lr: 3.544e-06, loss 0.105807\n",
      "Stage: train, iter: 11900, lr: 3.529e-06, loss 0.092155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 11920, lr: 3.514e-06, loss 0.078467\n",
      "Stage: train, iter: 11940, lr: 3.499e-06, loss 0.075960\n",
      "Stage: train, iter: 11960, lr: 3.484e-06, loss 0.085225\n",
      "Stage: train, iter: 11980, lr: 3.469e-06, loss 0.115077\n",
      "Stage: train, iter: 12000, lr: 3.454e-06, loss 0.094082\n",
      "Stage: train, iter: 12020, lr: 3.440e-06, loss 0.133628\n",
      "Stage: train, iter: 12040, lr: 3.425e-06, loss 0.073088\n",
      "Stage: train, iter: 12060, lr: 3.410e-06, loss 0.099480\n",
      "Stage: train, iter: 12080, lr: 3.395e-06, loss 0.097577\n",
      "Stage: train, iter: 12100, lr: 3.380e-06, loss 0.068968\n",
      "Stage: train, iter: 12120, lr: 3.365e-06, loss 0.113276\n",
      "Stage: train, iter: 12140, lr: 3.350e-06, loss 0.117116\n",
      "Stage: train, iter: 12160, lr: 3.335e-06, loss 0.108316\n",
      "Stage: train, iter: 12180, lr: 3.321e-06, loss 0.050909\n",
      "Stage: train, iter: 12200, lr: 3.306e-06, loss 0.071628\n",
      "Stage: train, iter: 12220, lr: 3.291e-06, loss 0.130169\n",
      "Stage: train, iter: 12240, lr: 3.276e-06, loss 0.067279\n",
      "Stage: train, iter: 12260, lr: 3.262e-06, loss 0.053378\n",
      "Stage: train, iter: 12280, lr: 3.247e-06, loss 0.108927\n",
      "Stage: train, iter: 12300, lr: 3.232e-06, loss 0.063604\n",
      "Stage: train, iter: 12320, lr: 3.217e-06, loss 0.092352\n",
      "Stage: train, iter: 12340, lr: 3.203e-06, loss 0.116612\n",
      "Stage: train, iter: 12360, lr: 3.188e-06, loss 0.058094\n",
      "Stage: train, iter: 12380, lr: 3.174e-06, loss 0.094637\n",
      "Stage: train, iter: 12400, lr: 3.159e-06, loss 0.091526\n",
      "Stage: train, iter: 12420, lr: 3.144e-06, loss 0.097743\n",
      "Stage: train, iter: 12440, lr: 3.130e-06, loss 0.107136\n",
      "Stage: train, iter: 12460, lr: 3.115e-06, loss 0.088219\n",
      "Stage: train, iter: 12480, lr: 3.101e-06, loss 0.166518\n",
      "Stage: train, iter: 12500, lr: 3.086e-06, loss 0.084779\n",
      "Stage: train, iter: 12520, lr: 3.072e-06, loss 0.119584\n",
      "Stage: train, iter: 12540, lr: 3.057e-06, loss 0.080558\n",
      "Stage: train, iter: 12560, lr: 3.043e-06, loss 0.105797\n",
      "Stage: train, iter: 12580, lr: 3.028e-06, loss 0.068340\n",
      "Stage: train, iter: 12600, lr: 3.014e-06, loss 0.062568\n",
      "Stage: train, iter: 12620, lr: 2.999e-06, loss 0.083928\n",
      "Stage: train, iter: 12640, lr: 2.985e-06, loss 0.071489\n",
      "Stage: train, iter: 12660, lr: 2.971e-06, loss 0.079375\n",
      "Stage: train, iter: 12680, lr: 2.956e-06, loss 0.084039\n",
      "Stage: train, iter: 12700, lr: 2.942e-06, loss 0.095294\n",
      "Stage: train, iter: 12720, lr: 2.928e-06, loss 0.058955\n",
      "Stage: train, iter: 12740, lr: 2.913e-06, loss 0.052155\n",
      "Stage: train, iter: 12760, lr: 2.899e-06, loss 0.078603\n",
      "Stage: train, iter: 12780, lr: 2.885e-06, loss 0.085663\n",
      "Stage: train, iter: 12800, lr: 2.871e-06, loss 0.058808\n",
      "Stage: train, iter: 12820, lr: 2.856e-06, loss 0.098594\n",
      "Stage: train, iter: 12840, lr: 2.842e-06, loss 0.108902\n",
      "Stage: train, iter: 12860, lr: 2.828e-06, loss 0.043972\n",
      "Stage: train, iter: 12880, lr: 2.814e-06, loss 0.100854\n",
      "Stage: train, iter: 12900, lr: 2.800e-06, loss 0.081844\n",
      "Stage: train, iter: 12920, lr: 2.786e-06, loss 0.063183\n",
      "Stage: train, iter: 12940, lr: 2.772e-06, loss 0.087046\n",
      "Stage: train, iter: 12960, lr: 2.758e-06, loss 0.139515\n",
      "Stage: train, iter: 12980, lr: 2.744e-06, loss 0.107592\n",
      "Stage: train, iter: 13000, lr: 2.730e-06, loss 0.070680\n",
      "Stage: train, iter: 13020, lr: 2.716e-06, loss 0.099157\n",
      "Stage: train, iter: 13040, lr: 2.702e-06, loss 0.066378\n",
      "Stage: train, iter: 13060, lr: 2.688e-06, loss 0.084686\n",
      "Stage: train, iter: 13080, lr: 2.674e-06, loss 0.086515\n",
      "Stage: train, iter: 13100, lr: 2.660e-06, loss 0.060533\n",
      "Stage: train, iter: 13120, lr: 2.646e-06, loss 0.107672\n",
      "Stage: train, iter: 13140, lr: 2.632e-06, loss 0.092638\n",
      "Stage: train, iter: 13160, lr: 2.618e-06, loss 0.118879\n",
      "Stage: train, iter: 13180, lr: 2.605e-06, loss 0.071410\n",
      "Stage: train, iter: 13200, lr: 2.591e-06, loss 0.102065\n",
      "Stage: train, iter: 13220, lr: 2.577e-06, loss 0.120907\n",
      "Stage: train, iter: 13240, lr: 2.563e-06, loss 0.133911\n",
      "Stage: train, iter: 13260, lr: 2.550e-06, loss 0.097334\n",
      "Stage: train, iter: 13280, lr: 2.536e-06, loss 0.060756\n",
      "Stage: train, iter: 13300, lr: 2.522e-06, loss 0.081003\n",
      "Stage: train, iter: 13320, lr: 2.509e-06, loss 0.054056\n",
      "Stage: train, iter: 13340, lr: 2.495e-06, loss 0.065622\n",
      "Stage: train, iter: 13360, lr: 2.481e-06, loss 0.093501\n",
      "Stage: train, iter: 13380, lr: 2.468e-06, loss 0.089535\n",
      "Stage: train, iter: 13400, lr: 2.454e-06, loss 0.123050\n",
      "Stage: train, iter: 13420, lr: 2.441e-06, loss 0.091689\n",
      "Stage: train, iter: 13440, lr: 2.427e-06, loss 0.129983\n",
      "Stage: train, iter: 13460, lr: 2.414e-06, loss 0.097199\n",
      "Stage: train, iter: 13480, lr: 2.400e-06, loss 0.079747\n",
      "Stage: train, iter: 13500, lr: 2.387e-06, loss 0.074515\n",
      "Stage: train, iter: 13520, lr: 2.374e-06, loss 0.045053\n",
      "Stage: train, iter: 13540, lr: 2.360e-06, loss 0.077124\n",
      "Stage: train, iter: 13560, lr: 2.347e-06, loss 0.087250\n",
      "Stage: train, iter: 13580, lr: 2.334e-06, loss 0.093899\n",
      "Stage: train, iter: 13600, lr: 2.320e-06, loss 0.083976\n",
      "Stage: train, iter: 13620, lr: 2.307e-06, loss 0.076263\n",
      "Stage: train, iter: 13640, lr: 2.294e-06, loss 0.091140\n",
      "Stage: train, iter: 13660, lr: 2.281e-06, loss 0.081108\n",
      "Stage: train, iter: 13680, lr: 2.268e-06, loss 0.111383\n",
      "Stage: train, iter: 13700, lr: 2.254e-06, loss 0.082695\n",
      "Stage: train, iter: 13720, lr: 2.241e-06, loss 0.091997\n",
      "Stage: train, iter: 13740, lr: 2.228e-06, loss 0.080415\n",
      "Stage: train, iter: 13760, lr: 2.215e-06, loss 0.061753\n",
      "Stage: train, iter: 13780, lr: 2.202e-06, loss 0.115078\n",
      "Stage: train, iter: 13800, lr: 2.189e-06, loss 0.092337\n",
      "Stage: train, iter: 13820, lr: 2.176e-06, loss 0.089918\n",
      "Stage: train, iter: 13840, lr: 2.163e-06, loss 0.080596\n",
      "Stage: train, iter: 13860, lr: 2.150e-06, loss 0.075226\n",
      "Stage: train, iter: 13880, lr: 2.137e-06, loss 0.122616\n",
      "Stage: train, iter: 13900, lr: 2.125e-06, loss 0.092695\n",
      "Stage: train, iter: 13920, lr: 2.112e-06, loss 0.089893\n",
      "Stage: train, iter: 13940, lr: 2.099e-06, loss 0.086780\n",
      "Stage: train, iter: 13960, lr: 2.086e-06, loss 0.114269\n",
      "Stage: train, iter: 13980, lr: 2.073e-06, loss 0.075324\n",
      "Stage: train, iter: 14000, lr: 2.061e-06, loss 0.083254\n",
      "Stage: train, iter: 14020, lr: 2.048e-06, loss 0.086993\n",
      "Stage: train, iter: 14040, lr: 2.035e-06, loss 0.096837\n",
      "Stage: train, iter: 14060, lr: 2.023e-06, loss 0.107423\n",
      "Stage: train, iter: 14080, lr: 2.010e-06, loss 0.043713\n",
      "Stage: train, iter: 14100, lr: 1.997e-06, loss 0.109688\n",
      "Stage: train, iter: 14120, lr: 1.985e-06, loss 0.107431\n",
      "Stage: train, iter: 14140, lr: 1.972e-06, loss 0.137995\n",
      "Stage: train, iter: 14160, lr: 1.960e-06, loss 0.104346\n",
      "Stage: train, iter: 14180, lr: 1.947e-06, loss 0.087601\n",
      "Stage: train, iter: 14200, lr: 1.935e-06, loss 0.070162\n",
      "Stage: train, iter: 14220, lr: 1.923e-06, loss 0.108060\n",
      "Stage: train, iter: 14240, lr: 1.910e-06, loss 0.071147\n",
      "Stage: train, iter: 14260, lr: 1.898e-06, loss 0.047113\n",
      "Stage: train, iter: 14280, lr: 1.886e-06, loss 0.131327\n",
      "Stage: train, iter: 14300, lr: 1.873e-06, loss 0.097238\n",
      "Stage: train, iter: 14320, lr: 1.861e-06, loss 0.094061\n",
      "Stage: train, iter: 14340, lr: 1.849e-06, loss 0.050993\n",
      "Stage: train, iter: 14360, lr: 1.837e-06, loss 0.090314\n",
      "Stage: train, iter: 14380, lr: 1.825e-06, loss 0.077206\n",
      "Stage: train, iter: 14400, lr: 1.812e-06, loss 0.072001\n",
      "Stage: train, iter: 14420, lr: 1.800e-06, loss 0.098247\n",
      "Stage: train, iter: 14440, lr: 1.788e-06, loss 0.065128\n",
      "Stage: train, iter: 14460, lr: 1.776e-06, loss 0.069874\n",
      "Stage: train, iter: 14480, lr: 1.764e-06, loss 0.101771\n",
      "Stage: train, iter: 14500, lr: 1.752e-06, loss 0.082973\n",
      "Stage: train, iter: 14520, lr: 1.740e-06, loss 0.083516\n",
      "Stage: train, iter: 14540, lr: 1.729e-06, loss 0.059632\n",
      "Stage: train, iter: 14560, lr: 1.717e-06, loss 0.050425\n",
      "Stage: train, iter: 14580, lr: 1.705e-06, loss 0.084460\n",
      "Stage: train, iter: 14600, lr: 1.693e-06, loss 0.127296\n",
      "Stage: train, iter: 14620, lr: 1.681e-06, loss 0.074792\n",
      "Stage: train, iter: 14640, lr: 1.670e-06, loss 0.092950\n",
      "Stage: train, iter: 14660, lr: 1.658e-06, loss 0.119481\n",
      "Stage: train, iter: 14680, lr: 1.646e-06, loss 0.109432\n",
      "Stage: train, iter: 14700, lr: 1.635e-06, loss 0.087771\n",
      "Stage: train, iter: 14720, lr: 1.623e-06, loss 0.072699\n",
      "Stage: train, iter: 14740, lr: 1.611e-06, loss 0.069819\n",
      "Stage: train, iter: 14760, lr: 1.600e-06, loss 0.088686\n",
      "Stage: train, iter: 14780, lr: 1.588e-06, loss 0.073741\n",
      "Stage: train, iter: 14800, lr: 1.577e-06, loss 0.081046\n",
      "Stage: train, iter: 14820, lr: 1.565e-06, loss 0.081768\n",
      "Stage: train, iter: 14840, lr: 1.554e-06, loss 0.096194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 14860, lr: 1.543e-06, loss 0.058919\n",
      "Stage: train, iter: 14880, lr: 1.531e-06, loss 0.078601\n",
      "Stage: train, iter: 14900, lr: 1.520e-06, loss 0.106835\n",
      "Stage: train, iter: 14920, lr: 1.509e-06, loss 0.088112\n",
      "Stage: train, iter: 14940, lr: 1.498e-06, loss 0.084346\n",
      "Stage: train, iter: 14960, lr: 1.486e-06, loss 0.076611\n",
      "Stage: train, iter: 14980, lr: 1.475e-06, loss 0.115058\n",
      "Stage: train, iter: 15000, lr: 1.464e-06, loss 0.073730\n",
      "Stage: train, iter: 15020, lr: 1.453e-06, loss 0.125742\n",
      "Stage: train, iter: 15040, lr: 1.442e-06, loss 0.105088\n",
      "Stage: train, iter: 15060, lr: 1.431e-06, loss 0.088824\n",
      "Stage: train, iter: 15080, lr: 1.420e-06, loss 0.119737\n",
      "Stage: train, iter: 15100, lr: 1.409e-06, loss 0.079703\n",
      "Stage: train, iter: 15120, lr: 1.398e-06, loss 0.102601\n",
      "Stage: train, iter: 15140, lr: 1.387e-06, loss 0.062718\n",
      "Stage: train, iter: 15160, lr: 1.376e-06, loss 0.058792\n",
      "Stage: train, iter: 15180, lr: 1.366e-06, loss 0.086414\n",
      "Stage: train, iter: 15200, lr: 1.355e-06, loss 0.098716\n",
      "Stage: train, iter: 15220, lr: 1.344e-06, loss 0.085994\n",
      "Stage: train, iter: 15240, lr: 1.333e-06, loss 0.076588\n",
      "Stage: train, iter: 15260, lr: 1.323e-06, loss 0.045184\n",
      "Stage: train, iter: 15280, lr: 1.312e-06, loss 0.093516\n",
      "Stage: train, iter: 15300, lr: 1.301e-06, loss 0.125665\n",
      "Stage: train, iter: 15320, lr: 1.291e-06, loss 0.055159\n",
      "Stage: train, iter: 15340, lr: 1.280e-06, loss 0.071930\n",
      "Stage: train, iter: 15360, lr: 1.270e-06, loss 0.086962\n",
      "Stage: train, iter: 15380, lr: 1.259e-06, loss 0.128916\n",
      "Stage: train, iter: 15400, lr: 1.249e-06, loss 0.093098\n",
      "Stage: train, iter: 15420, lr: 1.239e-06, loss 0.089730\n",
      "Stage: train, iter: 15440, lr: 1.228e-06, loss 0.048618\n",
      "Stage: train, iter: 15460, lr: 1.218e-06, loss 0.066768\n",
      "Stage: train, iter: 15480, lr: 1.208e-06, loss 0.058694\n",
      "Stage: train, iter: 15500, lr: 1.198e-06, loss 0.090722\n",
      "Stage: train, iter: 15520, lr: 1.187e-06, loss 0.095417\n",
      "Stage: train, iter: 15540, lr: 1.177e-06, loss 0.068468\n",
      "Stage: train, iter: 15560, lr: 1.167e-06, loss 0.092148\n",
      "Stage: train, iter: 15580, lr: 1.157e-06, loss 0.123181\n",
      "Stage: train, iter: 15600, lr: 1.147e-06, loss 0.134252\n",
      "Stage: train, iter: 15620, lr: 1.137e-06, loss 0.069444\n",
      "Stage: train, iter: 15640, lr: 1.127e-06, loss 0.080049\n",
      "Stage: train, iter: 15660, lr: 1.117e-06, loss 0.078732\n",
      "Stage: train, iter: 15680, lr: 1.107e-06, loss 0.049911\n",
      "Stage: train, iter: 15700, lr: 1.097e-06, loss 0.098541\n",
      "Stage: train, iter: 15720, lr: 1.088e-06, loss 0.073553\n",
      "Stage: train, iter: 15740, lr: 1.078e-06, loss 0.088085\n",
      "Stage: train, iter: 15760, lr: 1.068e-06, loss 0.090831\n",
      "Stage: train, iter: 15780, lr: 1.058e-06, loss 0.143486\n",
      "Stage: train, iter: 15800, lr: 1.049e-06, loss 0.151371\n",
      "Stage: train, iter: 15820, lr: 1.039e-06, loss 0.072876\n",
      "Stage: train, iter: 15840, lr: 1.030e-06, loss 0.065856\n",
      "Stage: train, iter: 15860, lr: 1.020e-06, loss 0.076517\n",
      "Stage: train, iter: 15880, lr: 1.011e-06, loss 0.083825\n",
      "Stage: train, iter: 15900, lr: 1.001e-06, loss 0.061985\n",
      "Stage: train, iter: 15920, lr: 9.918e-07, loss 0.075015\n",
      "Stage: train, iter: 15940, lr: 9.824e-07, loss 0.086672\n",
      "Stage: train, iter: 15960, lr: 9.731e-07, loss 0.064697\n",
      "Stage: train, iter: 15980, lr: 9.638e-07, loss 0.057452\n",
      "Stage: train, iter: 16000, lr: 9.545e-07, loss 0.107588\n",
      "Stage: train, iter: 16020, lr: 9.453e-07, loss 0.051154\n",
      "Stage: train, iter: 16040, lr: 9.362e-07, loss 0.075226\n",
      "Stage: train, iter: 16060, lr: 9.270e-07, loss 0.093169\n",
      "Stage: train, iter: 16080, lr: 9.179e-07, loss 0.078077\n",
      "Stage: train, iter: 16100, lr: 9.089e-07, loss 0.080827\n",
      "Stage: train, iter: 16120, lr: 8.999e-07, loss 0.087337\n",
      "Stage: train, iter: 16140, lr: 8.909e-07, loss 0.069529\n",
      "Stage: train, iter: 16160, lr: 8.820e-07, loss 0.050698\n",
      "Stage: train, iter: 16180, lr: 8.731e-07, loss 0.068652\n",
      "Stage: train, iter: 16200, lr: 8.642e-07, loss 0.065451\n",
      "Stage: train, iter: 16220, lr: 8.554e-07, loss 0.133339\n",
      "Stage: train, iter: 16240, lr: 8.467e-07, loss 0.060362\n",
      "Stage: train, iter: 16260, lr: 8.379e-07, loss 0.111652\n",
      "Stage: train, iter: 16280, lr: 8.293e-07, loss 0.110132\n",
      "Stage: train, iter: 16300, lr: 8.206e-07, loss 0.062849\n",
      "Stage: train, iter: 16320, lr: 8.120e-07, loss 0.074650\n",
      "Stage: train, iter: 16340, lr: 8.034e-07, loss 0.146946\n",
      "Stage: train, iter: 16360, lr: 7.949e-07, loss 0.063897\n",
      "Stage: train, iter: 16380, lr: 7.865e-07, loss 0.070583\n",
      "Stage: train, iter: 16400, lr: 7.780e-07, loss 0.098526\n",
      "Stage: train, iter: 16420, lr: 7.696e-07, loss 0.063317\n",
      "Stage: train, iter: 16440, lr: 7.613e-07, loss 0.105673\n",
      "Stage: train, iter: 16460, lr: 7.530e-07, loss 0.068574\n",
      "Stage: train, iter: 16480, lr: 7.447e-07, loss 0.063097\n",
      "Stage: train, iter: 16500, lr: 7.365e-07, loss 0.047944\n",
      "Stage: train, iter: 16520, lr: 7.283e-07, loss 0.109062\n",
      "Stage: train, iter: 16540, lr: 7.201e-07, loss 0.085888\n",
      "Stage: train, iter: 16560, lr: 7.120e-07, loss 0.107330\n",
      "Stage: train, iter: 16580, lr: 7.040e-07, loss 0.089985\n",
      "Stage: train, iter: 16600, lr: 6.960e-07, loss 0.060281\n",
      "Stage: train, iter: 16620, lr: 6.880e-07, loss 0.097052\n",
      "Stage: train, iter: 16640, lr: 6.801e-07, loss 0.091513\n",
      "Stage: train, iter: 16660, lr: 6.722e-07, loss 0.060553\n",
      "Stage: train, iter: 16680, lr: 6.643e-07, loss 0.082202\n",
      "Stage: train, iter: 16700, lr: 6.565e-07, loss 0.096738\n",
      "Stage: train, iter: 16720, lr: 6.488e-07, loss 0.067449\n",
      "Stage: train, iter: 16740, lr: 6.410e-07, loss 0.092426\n",
      "Stage: train, iter: 16760, lr: 6.334e-07, loss 0.099208\n",
      "Stage: train, iter: 16780, lr: 6.257e-07, loss 0.082004\n",
      "Stage: train, iter: 16800, lr: 6.181e-07, loss 0.075299\n",
      "Stage: train, iter: 16820, lr: 6.106e-07, loss 0.098511\n",
      "Stage: train, iter: 16840, lr: 6.031e-07, loss 0.079439\n",
      "Stage: train, iter: 16860, lr: 5.956e-07, loss 0.084005\n",
      "Stage: train, iter: 16880, lr: 5.882e-07, loss 0.081725\n",
      "Stage: train, iter: 16900, lr: 5.809e-07, loss 0.119593\n",
      "Stage: train, iter: 16920, lr: 5.735e-07, loss 0.095890\n",
      "Stage: train, iter: 16940, lr: 5.663e-07, loss 0.077177\n",
      "Stage: train, iter: 16960, lr: 5.590e-07, loss 0.105293\n",
      "Stage: train, iter: 16980, lr: 5.518e-07, loss 0.083671\n",
      "Stage: train, iter: 17000, lr: 5.447e-07, loss 0.103698\n",
      "Stage: train, iter: 17020, lr: 5.376e-07, loss 0.106692\n",
      "Stage: train, iter: 17040, lr: 5.305e-07, loss 0.105758\n",
      "Stage: train, iter: 17060, lr: 5.235e-07, loss 0.102278\n",
      "Stage: train, iter: 17080, lr: 5.165e-07, loss 0.092096\n",
      "Stage: train, iter: 17100, lr: 5.096e-07, loss 0.048010\n",
      "Stage: train, iter: 17120, lr: 5.027e-07, loss 0.072441\n",
      "Stage: train, iter: 17140, lr: 4.958e-07, loss 0.054412\n",
      "Stage: train, iter: 17160, lr: 4.890e-07, loss 0.107945\n",
      "Stage: train, iter: 17180, lr: 4.823e-07, loss 0.088889\n",
      "Stage: train, iter: 17200, lr: 4.756e-07, loss 0.099471\n",
      "Stage: train, iter: 17220, lr: 4.689e-07, loss 0.080792\n",
      "Stage: train, iter: 17240, lr: 4.623e-07, loss 0.083720\n",
      "Stage: train, iter: 17260, lr: 4.557e-07, loss 0.125699\n",
      "Stage: train, iter: 17280, lr: 4.492e-07, loss 0.105061\n",
      "Stage: train, iter: 17300, lr: 4.427e-07, loss 0.078453\n",
      "Stage: train, iter: 17320, lr: 4.363e-07, loss 0.097691\n",
      "Stage: train, iter: 17340, lr: 4.299e-07, loss 0.072573\n",
      "Stage: train, iter: 17360, lr: 4.235e-07, loss 0.112207\n",
      "Stage: train, iter: 17380, lr: 4.172e-07, loss 0.113273\n",
      "Stage: train, iter: 17400, lr: 4.110e-07, loss 0.140496\n",
      "Stage: train, iter: 17420, lr: 4.047e-07, loss 0.077423\n",
      "Stage: train, iter: 17440, lr: 3.986e-07, loss 0.084719\n",
      "Stage: train, iter: 17460, lr: 3.924e-07, loss 0.061060\n",
      "Stage: train, iter: 17480, lr: 3.864e-07, loss 0.069588\n",
      "Stage: train, iter: 17500, lr: 3.803e-07, loss 0.076093\n",
      "Stage: train, iter: 17520, lr: 3.744e-07, loss 0.098526\n",
      "Stage: train, iter: 17540, lr: 3.684e-07, loss 0.087613\n",
      "Stage: train, iter: 17560, lr: 3.625e-07, loss 0.096225\n",
      "Stage: train, iter: 17580, lr: 3.567e-07, loss 0.133077\n",
      "Stage: train, iter: 17600, lr: 3.509e-07, loss 0.089116\n",
      "Stage: train, iter: 17620, lr: 3.451e-07, loss 0.102943\n",
      "Stage: train, iter: 17640, lr: 3.394e-07, loss 0.111691\n",
      "Stage: train, iter: 17660, lr: 3.337e-07, loss 0.080288\n",
      "Stage: train, iter: 17680, lr: 3.281e-07, loss 0.103081\n",
      "Stage: train, iter: 17700, lr: 3.225e-07, loss 0.085646\n",
      "Stage: train, iter: 17720, lr: 3.170e-07, loss 0.086797\n",
      "Stage: train, iter: 17740, lr: 3.115e-07, loss 0.099167\n",
      "Stage: train, iter: 17760, lr: 3.061e-07, loss 0.127185\n",
      "Stage: train, iter: 17780, lr: 3.007e-07, loss 0.064122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 17800, lr: 2.954e-07, loss 0.110032\n",
      "Stage: train, iter: 17820, lr: 2.901e-07, loss 0.071944\n",
      "Stage: train, iter: 17840, lr: 2.848e-07, loss 0.077446\n",
      "Stage: train, iter: 17860, lr: 2.796e-07, loss 0.084585\n",
      "Stage: train, iter: 17880, lr: 2.745e-07, loss 0.069104\n",
      "Stage: train, iter: 17900, lr: 2.693e-07, loss 0.075485\n",
      "Stage: train, iter: 17920, lr: 2.643e-07, loss 0.086572\n",
      "Stage: train, iter: 17940, lr: 2.593e-07, loss 0.083748\n",
      "Stage: train, iter: 17960, lr: 2.543e-07, loss 0.106548\n",
      "Stage: train, iter: 17980, lr: 2.494e-07, loss 0.081253\n",
      "Stage: train, iter: 18000, lr: 2.445e-07, loss 0.068190\n",
      "Stage: train, iter: 18020, lr: 2.397e-07, loss 0.083091\n",
      "Stage: train, iter: 18040, lr: 2.349e-07, loss 0.073647\n",
      "Stage: train, iter: 18060, lr: 2.302e-07, loss 0.064739\n",
      "Stage: train, iter: 18080, lr: 2.255e-07, loss 0.038471\n",
      "Stage: train, iter: 18100, lr: 2.208e-07, loss 0.073384\n",
      "Stage: train, iter: 18120, lr: 2.162e-07, loss 0.086748\n",
      "Stage: train, iter: 18140, lr: 2.117e-07, loss 0.062539\n",
      "Stage: train, iter: 18160, lr: 2.072e-07, loss 0.053252\n",
      "Stage: train, iter: 18180, lr: 2.027e-07, loss 0.088998\n",
      "Stage: train, iter: 18200, lr: 1.983e-07, loss 0.094248\n",
      "Stage: train, iter: 18220, lr: 1.940e-07, loss 0.103735\n",
      "Stage: train, iter: 18240, lr: 1.897e-07, loss 0.102324\n",
      "Stage: train, iter: 18260, lr: 1.854e-07, loss 0.067090\n",
      "Stage: train, iter: 18280, lr: 1.812e-07, loss 0.099977\n",
      "Stage: train, iter: 18300, lr: 1.770e-07, loss 0.099401\n",
      "Stage: train, iter: 18320, lr: 1.729e-07, loss 0.074792\n",
      "Stage: train, iter: 18340, lr: 1.688e-07, loss 0.062344\n",
      "Stage: train, iter: 18360, lr: 1.648e-07, loss 0.082393\n",
      "Stage: train, iter: 18380, lr: 1.608e-07, loss 0.040515\n",
      "Stage: train, iter: 18400, lr: 1.569e-07, loss 0.062452\n",
      "Stage: train, iter: 18420, lr: 1.530e-07, loss 0.087971\n",
      "Stage: train, iter: 18440, lr: 1.492e-07, loss 0.077466\n",
      "Stage: train, iter: 18460, lr: 1.454e-07, loss 0.051950\n",
      "Stage: train, iter: 18480, lr: 1.417e-07, loss 0.056923\n",
      "Stage: train, iter: 18500, lr: 1.380e-07, loss 0.102203\n",
      "Stage: train, iter: 18520, lr: 1.343e-07, loss 0.130166\n",
      "Stage: train, iter: 18540, lr: 1.307e-07, loss 0.091606\n",
      "Stage: train, iter: 18560, lr: 1.272e-07, loss 0.108275\n",
      "Stage: train, iter: 18580, lr: 1.237e-07, loss 0.056612\n",
      "Stage: train, iter: 18600, lr: 1.203e-07, loss 0.090302\n",
      "Stage: train, iter: 18620, lr: 1.169e-07, loss 0.156886\n",
      "Stage: train, iter: 18640, lr: 1.135e-07, loss 0.111347\n",
      "Stage: train, iter: 18660, lr: 1.102e-07, loss 0.086380\n",
      "Stage: train, iter: 18680, lr: 1.069e-07, loss 0.047241\n",
      "Stage: train, iter: 18700, lr: 1.037e-07, loss 0.083970\n",
      "Stage: train, iter: 18720, lr: 1.006e-07, loss 0.099113\n",
      "Stage: train, iter: 18740, lr: 9.747e-08, loss 0.075096\n",
      "Stage: train, iter: 18760, lr: 9.440e-08, loss 0.129264\n",
      "Stage: train, iter: 18780, lr: 9.139e-08, loss 0.106740\n",
      "Stage: train, iter: 18800, lr: 8.843e-08, loss 0.056624\n",
      "Stage: train, iter: 18820, lr: 8.551e-08, loss 0.093411\n",
      "Stage: train, iter: 18840, lr: 8.264e-08, loss 0.075685\n",
      "Stage: train, iter: 18860, lr: 7.982e-08, loss 0.105919\n",
      "Stage: train, iter: 18880, lr: 7.705e-08, loss 0.097980\n",
      "Stage: train, iter: 18900, lr: 7.433e-08, loss 0.048551\n",
      "Stage: train, iter: 18920, lr: 7.165e-08, loss 0.059071\n",
      "Stage: train, iter: 18940, lr: 6.903e-08, loss 0.049366\n",
      "Stage: train, iter: 18960, lr: 6.645e-08, loss 0.084322\n",
      "Stage: train, iter: 18980, lr: 6.392e-08, loss 0.080236\n",
      "Stage: train, iter: 19000, lr: 6.144e-08, loss 0.094428\n",
      "Stage: train, iter: 19020, lr: 5.901e-08, loss 0.067031\n",
      "Stage: train, iter: 19040, lr: 5.663e-08, loss 0.091844\n",
      "Stage: train, iter: 19060, lr: 5.430e-08, loss 0.132083\n",
      "Stage: train, iter: 19080, lr: 5.201e-08, loss 0.092721\n",
      "Stage: train, iter: 19100, lr: 4.978e-08, loss 0.088476\n",
      "Stage: train, iter: 19120, lr: 4.759e-08, loss 0.096605\n",
      "Stage: train, iter: 19140, lr: 4.545e-08, loss 0.096721\n",
      "Stage: train, iter: 19160, lr: 4.336e-08, loss 0.058860\n",
      "Stage: train, iter: 19180, lr: 4.132e-08, loss 0.072797\n",
      "Stage: train, iter: 19200, lr: 3.933e-08, loss 0.085511\n",
      "Stage: train, iter: 19220, lr: 3.739e-08, loss 0.089496\n",
      "Stage: train, iter: 19240, lr: 3.550e-08, loss 0.100285\n",
      "Stage: train, iter: 19260, lr: 3.365e-08, loss 0.064173\n",
      "Stage: train, iter: 19280, lr: 3.186e-08, loss 0.144478\n",
      "Stage: train, iter: 19300, lr: 3.011e-08, loss 0.063969\n",
      "Stage: train, iter: 19320, lr: 2.842e-08, loss 0.099692\n",
      "Stage: train, iter: 19340, lr: 2.677e-08, loss 0.185221\n",
      "Stage: train, iter: 19360, lr: 2.517e-08, loss 0.121749\n",
      "Stage: train, iter: 19380, lr: 2.362e-08, loss 0.118744\n",
      "Stage: train, iter: 19400, lr: 2.212e-08, loss 0.113218\n",
      "Stage: train, iter: 19420, lr: 2.067e-08, loss 0.048902\n",
      "Stage: train, iter: 19440, lr: 1.926e-08, loss 0.094331\n",
      "Stage: train, iter: 19460, lr: 1.791e-08, loss 0.113479\n",
      "Stage: train, iter: 19480, lr: 1.661e-08, loss 0.069046\n",
      "Stage: train, iter: 19500, lr: 1.535e-08, loss 0.068487\n",
      "Stage: train, iter: 19520, lr: 1.415e-08, loss 0.090396\n",
      "Stage: train, iter: 19540, lr: 1.299e-08, loss 0.118129\n",
      "Stage: train, iter: 19560, lr: 1.188e-08, loss 0.112022\n",
      "Stage: train, iter: 19580, lr: 1.083e-08, loss 0.087955\n",
      "Stage: train, iter: 19600, lr: 9.818e-09, loss 0.092297\n",
      "Stage: train, iter: 19620, lr: 8.859e-09, loss 0.089290\n",
      "Stage: train, iter: 19640, lr: 7.949e-09, loss 0.068641\n",
      "Stage: train, iter: 19660, lr: 7.088e-09, loss 0.094366\n",
      "Stage: train, iter: 19680, lr: 6.276e-09, loss 0.067694\n",
      "Stage: train, iter: 19700, lr: 5.514e-09, loss 0.068905\n",
      "Stage: train, iter: 19720, lr: 4.801e-09, loss 0.092394\n",
      "Stage: train, iter: 19740, lr: 4.138e-09, loss 0.113552\n",
      "Stage: train, iter: 19760, lr: 3.523e-09, loss 0.063089\n",
      "Stage: train, iter: 19780, lr: 2.958e-09, loss 0.062975\n",
      "Stage: train, iter: 19800, lr: 2.443e-09, loss 0.088244\n",
      "Stage: train, iter: 19820, lr: 1.977e-09, loss 0.066230\n",
      "Stage: train, iter: 19840, lr: 1.560e-09, loss 0.093707\n",
      "Stage: train, iter: 19860, lr: 1.192e-09, loss 0.101958\n",
      "Stage: train, iter: 19880, lr: 8.736e-10, loss 0.049696\n",
      "Stage: train, iter: 19900, lr: 6.046e-10, loss 0.093594\n",
      "Stage: train, iter: 19920, lr: 3.850e-10, loss 0.128642\n",
      "Stage: train, iter: 19940, lr: 2.147e-10, loss 0.066308\n",
      "Stage: train, iter: 19960, lr: 9.383e-11, loss 0.104304\n",
      "Stage: train, iter: 19980, lr: 2.227e-11, loss 0.074764\n",
      "Stage: train, iter: 20000, lr: 1.000e-05, loss 0.061884\n",
      "Stage: train, iter: 20020, lr: 1.000e-05, loss 0.076648\n",
      "Stage: train, iter: 20040, lr: 1.000e-05, loss 0.113962\n",
      "Stage: train, iter: 20060, lr: 1.000e-05, loss 0.095122\n",
      "Stage: train, iter: 20080, lr: 1.000e-05, loss 0.129112\n",
      "Stage: train, iter: 20100, lr: 9.999e-06, loss 0.066285\n",
      "Stage: train, iter: 20120, lr: 9.999e-06, loss 0.090059\n",
      "Stage: train, iter: 20140, lr: 9.999e-06, loss 0.044816\n",
      "Stage: train, iter: 20160, lr: 9.998e-06, loss 0.086093\n",
      "Stage: train, iter: 20180, lr: 9.998e-06, loss 0.088933\n",
      "Stage: train, iter: 20200, lr: 9.998e-06, loss 0.105269\n",
      "Stage: train, iter: 20220, lr: 9.997e-06, loss 0.083806\n",
      "Stage: train, iter: 20240, lr: 9.996e-06, loss 0.114254\n",
      "Stage: train, iter: 20260, lr: 9.996e-06, loss 0.073454\n",
      "Stage: train, iter: 20280, lr: 9.995e-06, loss 0.056964\n",
      "Stage: train, iter: 20300, lr: 9.994e-06, loss 0.139479\n",
      "Stage: train, iter: 20320, lr: 9.994e-06, loss 0.103967\n",
      "Stage: train, iter: 20340, lr: 9.993e-06, loss 0.096932\n",
      "Stage: train, iter: 20360, lr: 9.992e-06, loss 0.076529\n",
      "Stage: train, iter: 20380, lr: 9.991e-06, loss 0.097800\n",
      "Stage: train, iter: 20400, lr: 9.990e-06, loss 0.069439\n",
      "Stage: train, iter: 20420, lr: 9.989e-06, loss 0.118491\n",
      "Stage: train, iter: 20440, lr: 9.988e-06, loss 0.074308\n",
      "Stage: train, iter: 20460, lr: 9.987e-06, loss 0.122526\n",
      "Stage: train, iter: 20480, lr: 9.986e-06, loss 0.111062\n",
      "Stage: train, iter: 20500, lr: 9.985e-06, loss 0.103703\n",
      "Stage: train, iter: 20520, lr: 9.983e-06, loss 0.081255\n",
      "Stage: train, iter: 20540, lr: 9.982e-06, loss 0.068614\n",
      "Stage: train, iter: 20560, lr: 9.981e-06, loss 0.091485\n",
      "Stage: train, iter: 20580, lr: 9.979e-06, loss 0.094117\n",
      "Stage: train, iter: 20600, lr: 9.978e-06, loss 0.082688\n",
      "Stage: train, iter: 20620, lr: 9.976e-06, loss 0.069964\n",
      "Stage: train, iter: 20640, lr: 9.975e-06, loss 0.103632\n",
      "Stage: train, iter: 20660, lr: 9.973e-06, loss 0.104662\n",
      "Stage: train, iter: 20680, lr: 9.972e-06, loss 0.050716\n",
      "Stage: train, iter: 20700, lr: 9.970e-06, loss 0.093121\n",
      "Stage: train, iter: 20720, lr: 9.968e-06, loss 0.094520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 20740, lr: 9.966e-06, loss 0.132160\n",
      "Stage: train, iter: 20760, lr: 9.964e-06, loss 0.059315\n",
      "Stage: train, iter: 20780, lr: 9.963e-06, loss 0.058633\n",
      "Stage: train, iter: 20800, lr: 9.961e-06, loss 0.110928\n",
      "Stage: train, iter: 20820, lr: 9.959e-06, loss 0.061287\n",
      "Stage: train, iter: 20840, lr: 9.957e-06, loss 0.109088\n",
      "Stage: train, iter: 20860, lr: 9.954e-06, loss 0.091992\n",
      "Stage: train, iter: 20880, lr: 9.952e-06, loss 0.068563\n",
      "Stage: train, iter: 20900, lr: 9.950e-06, loss 0.076753\n",
      "Stage: train, iter: 20920, lr: 9.948e-06, loss 0.085378\n",
      "Stage: train, iter: 20940, lr: 9.946e-06, loss 0.107951\n",
      "Stage: train, iter: 20960, lr: 9.943e-06, loss 0.091308\n",
      "Stage: train, iter: 20980, lr: 9.941e-06, loss 0.066917\n",
      "Stage: train, iter: 21000, lr: 9.938e-06, loss 0.098881\n",
      "Stage: train, iter: 21020, lr: 9.936e-06, loss 0.081538\n",
      "Stage: train, iter: 21040, lr: 9.933e-06, loss 0.100017\n",
      "Stage: train, iter: 21060, lr: 9.931e-06, loss 0.072821\n",
      "Stage: train, iter: 21080, lr: 9.928e-06, loss 0.079878\n",
      "Stage: train, iter: 21100, lr: 9.926e-06, loss 0.112073\n",
      "Stage: train, iter: 21120, lr: 9.923e-06, loss 0.071513\n",
      "Stage: train, iter: 21140, lr: 9.920e-06, loss 0.102261\n",
      "Stage: train, iter: 21160, lr: 9.917e-06, loss 0.092930\n",
      "Stage: train, iter: 21180, lr: 9.914e-06, loss 0.077063\n",
      "Stage: train, iter: 21200, lr: 9.911e-06, loss 0.071369\n",
      "Stage: train, iter: 21220, lr: 9.908e-06, loss 0.081395\n",
      "Stage: train, iter: 21240, lr: 9.905e-06, loss 0.077836\n",
      "Stage: train, iter: 21260, lr: 9.902e-06, loss 0.065722\n",
      "Stage: train, iter: 21280, lr: 9.899e-06, loss 0.058198\n",
      "Stage: train, iter: 21300, lr: 9.896e-06, loss 0.055895\n",
      "Stage: train, iter: 21320, lr: 9.893e-06, loss 0.085840\n",
      "Stage: train, iter: 21340, lr: 9.890e-06, loss 0.097724\n",
      "Stage: train, iter: 21360, lr: 9.886e-06, loss 0.135194\n",
      "Stage: train, iter: 21380, lr: 9.883e-06, loss 0.139531\n",
      "Stage: train, iter: 21400, lr: 9.880e-06, loss 0.088155\n",
      "Stage: train, iter: 21420, lr: 9.876e-06, loss 0.078581\n",
      "Stage: train, iter: 21440, lr: 9.873e-06, loss 0.051703\n",
      "Stage: train, iter: 21460, lr: 9.869e-06, loss 0.070568\n",
      "Stage: train, iter: 21480, lr: 9.865e-06, loss 0.072576\n",
      "Stage: train, iter: 21500, lr: 9.862e-06, loss 0.073312\n",
      "Stage: train, iter: 21520, lr: 9.858e-06, loss 0.118336\n",
      "Stage: train, iter: 21540, lr: 9.854e-06, loss 0.112678\n",
      "Stage: train, iter: 21560, lr: 9.851e-06, loss 0.084649\n",
      "Stage: train, iter: 21580, lr: 9.847e-06, loss 0.151846\n",
      "Stage: train, iter: 21600, lr: 9.843e-06, loss 0.078001\n",
      "Stage: train, iter: 21620, lr: 9.839e-06, loss 0.074446\n",
      "Stage: train, iter: 21640, lr: 9.835e-06, loss 0.085321\n",
      "Stage: train, iter: 21660, lr: 9.831e-06, loss 0.054182\n",
      "Stage: train, iter: 21680, lr: 9.827e-06, loss 0.107572\n",
      "Stage: train, iter: 21700, lr: 9.823e-06, loss 0.094423\n",
      "Stage: train, iter: 21720, lr: 9.819e-06, loss 0.110624\n",
      "Stage: train, iter: 21740, lr: 9.814e-06, loss 0.089919\n",
      "Stage: train, iter: 21760, lr: 9.810e-06, loss 0.083085\n",
      "Stage: train, iter: 21780, lr: 9.806e-06, loss 0.077613\n",
      "Stage: train, iter: 21800, lr: 9.801e-06, loss 0.112386\n",
      "Stage: train, iter: 21820, lr: 9.797e-06, loss 0.083859\n",
      "Stage: train, iter: 21840, lr: 9.793e-06, loss 0.093332\n",
      "Stage: train, iter: 21860, lr: 9.788e-06, loss 0.096564\n",
      "Stage: train, iter: 21880, lr: 9.784e-06, loss 0.099439\n",
      "Stage: train, iter: 21900, lr: 9.779e-06, loss 0.127150\n",
      "Stage: train, iter: 21920, lr: 9.774e-06, loss 0.064753\n",
      "Stage: train, iter: 21940, lr: 9.770e-06, loss 0.068881\n",
      "Stage: train, iter: 21960, lr: 9.765e-06, loss 0.087566\n",
      "Stage: train, iter: 21980, lr: 9.760e-06, loss 0.082663\n",
      "Stage: train, iter: 22000, lr: 9.755e-06, loss 0.091458\n",
      "Stage: train, iter: 22020, lr: 9.750e-06, loss 0.029589\n",
      "Stage: train, iter: 22040, lr: 9.745e-06, loss 0.102006\n",
      "Stage: train, iter: 22060, lr: 9.740e-06, loss 0.094929\n",
      "Stage: train, iter: 22080, lr: 9.735e-06, loss 0.082309\n",
      "Stage: train, iter: 22100, lr: 9.730e-06, loss 0.107952\n",
      "Stage: train, iter: 22120, lr: 9.725e-06, loss 0.089762\n",
      "Stage: train, iter: 22140, lr: 9.720e-06, loss 0.123515\n",
      "Stage: train, iter: 22160, lr: 9.715e-06, loss 0.081138\n",
      "Stage: train, iter: 22180, lr: 9.710e-06, loss 0.132572\n",
      "Stage: train, iter: 22200, lr: 9.704e-06, loss 0.105759\n",
      "Stage: train, iter: 22220, lr: 9.699e-06, loss 0.088120\n",
      "Stage: train, iter: 22240, lr: 9.694e-06, loss 0.062372\n",
      "Stage: train, iter: 22260, lr: 9.688e-06, loss 0.097740\n",
      "Stage: train, iter: 22280, lr: 9.683e-06, loss 0.080254\n",
      "Stage: train, iter: 22300, lr: 9.677e-06, loss 0.088169\n",
      "Stage: train, iter: 22320, lr: 9.672e-06, loss 0.114106\n",
      "Stage: train, iter: 22340, lr: 9.666e-06, loss 0.114097\n",
      "Stage: train, iter: 22360, lr: 9.660e-06, loss 0.075119\n",
      "Stage: train, iter: 22380, lr: 9.655e-06, loss 0.064982\n",
      "Stage: train, iter: 22400, lr: 9.649e-06, loss 0.059014\n",
      "Stage: train, iter: 22420, lr: 9.643e-06, loss 0.117183\n",
      "Stage: train, iter: 22440, lr: 9.637e-06, loss 0.095559\n",
      "Stage: train, iter: 22460, lr: 9.631e-06, loss 0.065389\n",
      "Stage: train, iter: 22480, lr: 9.625e-06, loss 0.105191\n",
      "Stage: train, iter: 22500, lr: 9.619e-06, loss 0.054064\n",
      "Stage: train, iter: 22520, lr: 9.613e-06, loss 0.088075\n",
      "Stage: train, iter: 22540, lr: 9.607e-06, loss 0.065987\n",
      "Stage: train, iter: 22560, lr: 9.601e-06, loss 0.082193\n",
      "Stage: train, iter: 22580, lr: 9.595e-06, loss 0.135399\n",
      "Stage: train, iter: 22600, lr: 9.589e-06, loss 0.055448\n",
      "Stage: train, iter: 22620, lr: 9.582e-06, loss 0.073438\n",
      "Stage: train, iter: 22640, lr: 9.576e-06, loss 0.092097\n",
      "Stage: train, iter: 22660, lr: 9.570e-06, loss 0.081148\n",
      "Stage: train, iter: 22680, lr: 9.563e-06, loss 0.066752\n",
      "Stage: train, iter: 22700, lr: 9.557e-06, loss 0.069300\n",
      "Stage: train, iter: 22720, lr: 9.550e-06, loss 0.098691\n",
      "Stage: train, iter: 22740, lr: 9.544e-06, loss 0.118917\n",
      "Stage: train, iter: 22760, lr: 9.537e-06, loss 0.107330\n",
      "Stage: train, iter: 22780, lr: 9.531e-06, loss 0.068629\n",
      "Stage: train, iter: 22800, lr: 9.524e-06, loss 0.064401\n",
      "Stage: train, iter: 22820, lr: 9.517e-06, loss 0.061076\n",
      "Stage: train, iter: 22840, lr: 9.511e-06, loss 0.078386\n",
      "Stage: train, iter: 22860, lr: 9.504e-06, loss 0.106573\n",
      "Stage: train, iter: 22880, lr: 9.497e-06, loss 0.071404\n",
      "Stage: train, iter: 22900, lr: 9.490e-06, loss 0.094501\n",
      "Stage: train, iter: 22920, lr: 9.483e-06, loss 0.087128\n",
      "Stage: train, iter: 22940, lr: 9.476e-06, loss 0.092353\n",
      "Stage: train, iter: 22960, lr: 9.469e-06, loss 0.133388\n",
      "Stage: train, iter: 22980, lr: 9.462e-06, loss 0.099778\n",
      "Stage: train, iter: 23000, lr: 9.455e-06, loss 0.107199\n",
      "Stage: train, iter: 23020, lr: 9.448e-06, loss 0.084655\n",
      "Stage: train, iter: 23040, lr: 9.441e-06, loss 0.066259\n",
      "Stage: train, iter: 23060, lr: 9.433e-06, loss 0.102173\n",
      "Stage: train, iter: 23080, lr: 9.426e-06, loss 0.081306\n",
      "Stage: train, iter: 23100, lr: 9.419e-06, loss 0.099657\n",
      "Stage: train, iter: 23120, lr: 9.411e-06, loss 0.123997\n",
      "Stage: train, iter: 23140, lr: 9.404e-06, loss 0.056719\n",
      "Stage: train, iter: 23160, lr: 9.397e-06, loss 0.057760\n",
      "Stage: train, iter: 23180, lr: 9.389e-06, loss 0.099815\n",
      "Stage: train, iter: 23200, lr: 9.381e-06, loss 0.145549\n",
      "Stage: train, iter: 23220, lr: 9.374e-06, loss 0.078561\n",
      "Stage: train, iter: 23240, lr: 9.366e-06, loss 0.082315\n",
      "Stage: train, iter: 23260, lr: 9.359e-06, loss 0.106345\n",
      "Stage: train, iter: 23280, lr: 9.351e-06, loss 0.083837\n",
      "Stage: train, iter: 23300, lr: 9.343e-06, loss 0.093986\n",
      "Stage: train, iter: 23320, lr: 9.335e-06, loss 0.130765\n",
      "Stage: train, iter: 23340, lr: 9.327e-06, loss 0.082907\n",
      "Stage: train, iter: 23360, lr: 9.320e-06, loss 0.069209\n",
      "Stage: train, iter: 23380, lr: 9.312e-06, loss 0.082556\n",
      "Stage: train, iter: 23400, lr: 9.304e-06, loss 0.093005\n",
      "Stage: train, iter: 23420, lr: 9.296e-06, loss 0.070543\n",
      "Stage: train, iter: 23440, lr: 9.288e-06, loss 0.106670\n",
      "Stage: train, iter: 23460, lr: 9.279e-06, loss 0.090339\n",
      "Stage: train, iter: 23480, lr: 9.271e-06, loss 0.118907\n",
      "Stage: train, iter: 23500, lr: 9.263e-06, loss 0.141810\n",
      "Stage: train, iter: 23520, lr: 9.255e-06, loss 0.106278\n",
      "Stage: train, iter: 23540, lr: 9.247e-06, loss 0.072948\n",
      "Stage: train, iter: 23560, lr: 9.238e-06, loss 0.084240\n",
      "Stage: train, iter: 23580, lr: 9.230e-06, loss 0.087831\n",
      "Stage: train, iter: 23600, lr: 9.222e-06, loss 0.092843\n",
      "Stage: train, iter: 23620, lr: 9.213e-06, loss 0.088981\n",
      "Stage: train, iter: 23640, lr: 9.205e-06, loss 0.067161\n",
      "Stage: train, iter: 23660, lr: 9.196e-06, loss 0.072078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 23680, lr: 9.188e-06, loss 0.076126\n",
      "Stage: train, iter: 23700, lr: 9.179e-06, loss 0.088148\n",
      "Stage: train, iter: 23720, lr: 9.170e-06, loss 0.122355\n",
      "Stage: train, iter: 23740, lr: 9.162e-06, loss 0.108929\n",
      "Stage: train, iter: 23760, lr: 9.153e-06, loss 0.091659\n",
      "Stage: train, iter: 23780, lr: 9.144e-06, loss 0.098385\n",
      "Stage: train, iter: 23800, lr: 9.135e-06, loss 0.068022\n",
      "Stage: train, iter: 23820, lr: 9.126e-06, loss 0.103003\n",
      "Stage: train, iter: 23840, lr: 9.118e-06, loss 0.055046\n",
      "Stage: train, iter: 23860, lr: 9.109e-06, loss 0.113454\n",
      "Stage: train, iter: 23880, lr: 9.100e-06, loss 0.151618\n",
      "Stage: train, iter: 23900, lr: 9.091e-06, loss 0.099705\n",
      "Stage: train, iter: 23920, lr: 9.082e-06, loss 0.069926\n",
      "Stage: train, iter: 23940, lr: 9.073e-06, loss 0.122189\n",
      "Stage: train, iter: 23960, lr: 9.063e-06, loss 0.099802\n",
      "Stage: train, iter: 23980, lr: 9.054e-06, loss 0.074535\n",
      "Stage: train, iter: 24000, lr: 9.045e-06, loss 0.124879\n",
      "Stage: train, iter: 24020, lr: 9.036e-06, loss 0.114897\n",
      "Stage: train, iter: 24040, lr: 9.026e-06, loss 0.076612\n",
      "Stage: train, iter: 24060, lr: 9.017e-06, loss 0.096080\n",
      "Stage: train, iter: 24080, lr: 9.008e-06, loss 0.057420\n",
      "Stage: train, iter: 24100, lr: 8.998e-06, loss 0.133078\n",
      "Stage: train, iter: 24120, lr: 8.989e-06, loss 0.082465\n",
      "Stage: train, iter: 24140, lr: 8.979e-06, loss 0.031776\n",
      "Stage: train, iter: 24160, lr: 8.970e-06, loss 0.037358\n",
      "Stage: train, iter: 24180, lr: 8.960e-06, loss 0.052620\n",
      "Stage: train, iter: 24200, lr: 8.951e-06, loss 0.099759\n",
      "Stage: train, iter: 24220, lr: 8.941e-06, loss 0.120978\n",
      "Stage: train, iter: 24240, lr: 8.931e-06, loss 0.083426\n",
      "Stage: train, iter: 24260, lr: 8.922e-06, loss 0.083812\n",
      "Stage: train, iter: 24280, lr: 8.912e-06, loss 0.109756\n",
      "Stage: train, iter: 24300, lr: 8.902e-06, loss 0.089356\n",
      "Stage: train, iter: 24320, lr: 8.892e-06, loss 0.104753\n",
      "Stage: train, iter: 24340, lr: 8.882e-06, loss 0.075550\n",
      "Stage: train, iter: 24360, lr: 8.872e-06, loss 0.049616\n",
      "Stage: train, iter: 24380, lr: 8.862e-06, loss 0.095567\n",
      "Stage: train, iter: 24400, lr: 8.852e-06, loss 0.059160\n",
      "Stage: train, iter: 24420, lr: 8.842e-06, loss 0.119303\n",
      "Stage: train, iter: 24440, lr: 8.832e-06, loss 0.091199\n",
      "Stage: train, iter: 24460, lr: 8.822e-06, loss 0.089115\n",
      "Stage: train, iter: 24480, lr: 8.812e-06, loss 0.079042\n",
      "Stage: train, iter: 24500, lr: 8.802e-06, loss 0.134991\n",
      "Stage: train, iter: 24520, lr: 8.792e-06, loss 0.117620\n",
      "Stage: train, iter: 24540, lr: 8.781e-06, loss 0.048731\n",
      "Stage: train, iter: 24560, lr: 8.771e-06, loss 0.118953\n",
      "Stage: train, iter: 24580, lr: 8.761e-06, loss 0.136971\n",
      "Stage: train, iter: 24600, lr: 8.750e-06, loss 0.087490\n",
      "Stage: train, iter: 24620, lr: 8.740e-06, loss 0.102013\n",
      "Stage: train, iter: 24640, lr: 8.730e-06, loss 0.045960\n",
      "Stage: train, iter: 24660, lr: 8.719e-06, loss 0.066717\n",
      "Stage: train, iter: 24680, lr: 8.709e-06, loss 0.072804\n",
      "Stage: train, iter: 24700, lr: 8.698e-06, loss 0.056777\n",
      "Stage: train, iter: 24720, lr: 8.687e-06, loss 0.081985\n",
      "Stage: train, iter: 24740, lr: 8.677e-06, loss 0.108471\n",
      "Stage: train, iter: 24760, lr: 8.666e-06, loss 0.060996\n",
      "Stage: train, iter: 24780, lr: 8.655e-06, loss 0.078513\n",
      "Stage: train, iter: 24800, lr: 8.645e-06, loss 0.080370\n",
      "Stage: train, iter: 24820, lr: 8.634e-06, loss 0.064965\n",
      "Stage: train, iter: 24840, lr: 8.623e-06, loss 0.102110\n",
      "Stage: train, iter: 24860, lr: 8.612e-06, loss 0.107048\n",
      "Stage: train, iter: 24880, lr: 8.601e-06, loss 0.132878\n",
      "Stage: train, iter: 24900, lr: 8.590e-06, loss 0.078902\n",
      "Stage: train, iter: 24920, lr: 8.580e-06, loss 0.073690\n",
      "Stage: train, iter: 24940, lr: 8.569e-06, loss 0.086089\n",
      "Stage: train, iter: 24960, lr: 8.558e-06, loss 0.096441\n",
      "Stage: train, iter: 24980, lr: 8.546e-06, loss 0.109601\n",
      "Stage: train, iter: 25000, lr: 8.535e-06, loss 0.071815\n",
      "Stage: train, iter: 25020, lr: 8.524e-06, loss 0.063972\n",
      "Stage: train, iter: 25040, lr: 8.513e-06, loss 0.064614\n",
      "Stage: train, iter: 25060, lr: 8.502e-06, loss 0.095813\n",
      "Stage: train, iter: 25080, lr: 8.491e-06, loss 0.131765\n",
      "Stage: train, iter: 25100, lr: 8.479e-06, loss 0.112566\n",
      "Stage: train, iter: 25120, lr: 8.468e-06, loss 0.112830\n",
      "Stage: train, iter: 25140, lr: 8.457e-06, loss 0.113440\n",
      "Stage: train, iter: 25160, lr: 8.445e-06, loss 0.076807\n",
      "Stage: train, iter: 25180, lr: 8.434e-06, loss 0.071653\n",
      "Stage: train, iter: 25200, lr: 8.423e-06, loss 0.102529\n",
      "Stage: train, iter: 25220, lr: 8.411e-06, loss 0.060594\n",
      "Stage: train, iter: 25240, lr: 8.400e-06, loss 0.078689\n",
      "Stage: train, iter: 25260, lr: 8.388e-06, loss 0.062728\n",
      "Stage: train, iter: 25280, lr: 8.377e-06, loss 0.060344\n",
      "Stage: train, iter: 25300, lr: 8.365e-06, loss 0.053776\n",
      "Stage: train, iter: 25320, lr: 8.353e-06, loss 0.062727\n",
      "Stage: train, iter: 25340, lr: 8.342e-06, loss 0.121484\n",
      "Stage: train, iter: 25360, lr: 8.330e-06, loss 0.072736\n",
      "Stage: train, iter: 25380, lr: 8.318e-06, loss 0.123771\n",
      "Stage: train, iter: 25400, lr: 8.306e-06, loss 0.097461\n",
      "Stage: train, iter: 25420, lr: 8.295e-06, loss 0.074326\n",
      "Stage: train, iter: 25440, lr: 8.283e-06, loss 0.066131\n",
      "Stage: train, iter: 25460, lr: 8.271e-06, loss 0.051388\n",
      "Stage: train, iter: 25480, lr: 8.259e-06, loss 0.110938\n",
      "Stage: train, iter: 25500, lr: 8.247e-06, loss 0.126848\n",
      "Stage: train, iter: 25520, lr: 8.235e-06, loss 0.087376\n",
      "Stage: train, iter: 25540, lr: 8.223e-06, loss 0.088853\n",
      "Stage: train, iter: 25560, lr: 8.211e-06, loss 0.070962\n",
      "Stage: train, iter: 25580, lr: 8.199e-06, loss 0.132296\n",
      "Stage: train, iter: 25600, lr: 8.187e-06, loss 0.098134\n",
      "Stage: train, iter: 25620, lr: 8.175e-06, loss 0.087078\n",
      "Stage: train, iter: 25640, lr: 8.163e-06, loss 0.088386\n",
      "Stage: train, iter: 25660, lr: 8.150e-06, loss 0.074930\n",
      "Stage: train, iter: 25680, lr: 8.138e-06, loss 0.088029\n",
      "Stage: train, iter: 25700, lr: 8.126e-06, loss 0.045859\n",
      "Stage: train, iter: 25720, lr: 8.114e-06, loss 0.072854\n",
      "Stage: train, iter: 25740, lr: 8.101e-06, loss 0.099418\n",
      "Stage: train, iter: 25760, lr: 8.089e-06, loss 0.078313\n",
      "Stage: train, iter: 25780, lr: 8.077e-06, loss 0.057549\n",
      "Stage: train, iter: 25800, lr: 8.064e-06, loss 0.109831\n",
      "Stage: train, iter: 25820, lr: 8.052e-06, loss 0.052250\n",
      "Stage: train, iter: 25840, lr: 8.039e-06, loss 0.105192\n",
      "Stage: train, iter: 25860, lr: 8.027e-06, loss 0.077766\n",
      "Stage: train, iter: 25880, lr: 8.014e-06, loss 0.090303\n",
      "Stage: train, iter: 25900, lr: 8.002e-06, loss 0.098462\n",
      "Stage: train, iter: 25920, lr: 7.989e-06, loss 0.098264\n",
      "Stage: train, iter: 25940, lr: 7.977e-06, loss 0.088909\n",
      "Stage: train, iter: 25960, lr: 7.964e-06, loss 0.069657\n",
      "Stage: train, iter: 25980, lr: 7.951e-06, loss 0.080793\n",
      "Stage: train, iter: 26000, lr: 7.939e-06, loss 0.130719\n",
      "Stage: train, iter: 26020, lr: 7.926e-06, loss 0.069497\n",
      "Stage: train, iter: 26040, lr: 7.913e-06, loss 0.101816\n",
      "Stage: train, iter: 26060, lr: 7.900e-06, loss 0.071911\n",
      "Stage: train, iter: 26080, lr: 7.888e-06, loss 0.094878\n",
      "Stage: train, iter: 26100, lr: 7.875e-06, loss 0.078618\n",
      "Stage: train, iter: 26120, lr: 7.862e-06, loss 0.071429\n",
      "Stage: train, iter: 26140, lr: 7.849e-06, loss 0.091324\n",
      "Stage: train, iter: 26160, lr: 7.836e-06, loss 0.063077\n",
      "Stage: train, iter: 26180, lr: 7.823e-06, loss 0.090767\n",
      "Stage: train, iter: 26200, lr: 7.810e-06, loss 0.089043\n",
      "Stage: train, iter: 26220, lr: 7.797e-06, loss 0.132105\n",
      "Stage: train, iter: 26240, lr: 7.784e-06, loss 0.073558\n",
      "Stage: train, iter: 26260, lr: 7.771e-06, loss 0.084020\n",
      "Stage: train, iter: 26280, lr: 7.758e-06, loss 0.064240\n",
      "Stage: train, iter: 26300, lr: 7.745e-06, loss 0.091019\n",
      "Stage: train, iter: 26320, lr: 7.732e-06, loss 0.071122\n",
      "Stage: train, iter: 26340, lr: 7.719e-06, loss 0.042107\n",
      "Stage: train, iter: 26360, lr: 7.705e-06, loss 0.118884\n",
      "Stage: train, iter: 26380, lr: 7.692e-06, loss 0.085112\n",
      "Stage: train, iter: 26400, lr: 7.679e-06, loss 0.078772\n",
      "Stage: train, iter: 26420, lr: 7.666e-06, loss 0.107813\n",
      "Stage: train, iter: 26440, lr: 7.652e-06, loss 0.100883\n",
      "Stage: train, iter: 26460, lr: 7.639e-06, loss 0.091475\n",
      "Stage: train, iter: 26480, lr: 7.626e-06, loss 0.093261\n",
      "Stage: train, iter: 26500, lr: 7.612e-06, loss 0.042020\n",
      "Stage: train, iter: 26520, lr: 7.599e-06, loss 0.058472\n",
      "Stage: train, iter: 26540, lr: 7.585e-06, loss 0.080459\n",
      "Stage: train, iter: 26560, lr: 7.572e-06, loss 0.101413\n",
      "Stage: train, iter: 26580, lr: 7.558e-06, loss 0.110446\n",
      "Stage: train, iter: 26600, lr: 7.545e-06, loss 0.043459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 26620, lr: 7.531e-06, loss 0.049644\n",
      "Stage: train, iter: 26640, lr: 7.518e-06, loss 0.102767\n",
      "Stage: train, iter: 26660, lr: 7.504e-06, loss 0.096558\n",
      "Stage: train, iter: 26680, lr: 7.491e-06, loss 0.106624\n",
      "Stage: train, iter: 26700, lr: 7.477e-06, loss 0.093307\n",
      "Stage: train, iter: 26720, lr: 7.463e-06, loss 0.089659\n",
      "Stage: train, iter: 26740, lr: 7.450e-06, loss 0.068931\n",
      "Stage: train, iter: 26760, lr: 7.436e-06, loss 0.056890\n",
      "Stage: train, iter: 26780, lr: 7.422e-06, loss 0.119710\n",
      "Stage: train, iter: 26800, lr: 7.409e-06, loss 0.082691\n",
      "Stage: train, iter: 26820, lr: 7.395e-06, loss 0.068369\n",
      "Stage: train, iter: 26840, lr: 7.381e-06, loss 0.063104\n",
      "Stage: train, iter: 26860, lr: 7.367e-06, loss 0.069787\n",
      "Stage: train, iter: 26880, lr: 7.353e-06, loss 0.064659\n",
      "Stage: train, iter: 26900, lr: 7.339e-06, loss 0.089744\n",
      "Stage: train, iter: 26920, lr: 7.326e-06, loss 0.050547\n",
      "Stage: train, iter: 26940, lr: 7.312e-06, loss 0.080461\n",
      "Stage: train, iter: 26960, lr: 7.298e-06, loss 0.039945\n",
      "Stage: train, iter: 26980, lr: 7.284e-06, loss 0.086632\n",
      "Stage: train, iter: 27000, lr: 7.270e-06, loss 0.062693\n",
      "Stage: train, iter: 27020, lr: 7.256e-06, loss 0.093338\n",
      "Stage: train, iter: 27040, lr: 7.242e-06, loss 0.077833\n",
      "Stage: train, iter: 27060, lr: 7.228e-06, loss 0.089454\n",
      "Stage: train, iter: 27080, lr: 7.214e-06, loss 0.092616\n",
      "Stage: train, iter: 27100, lr: 7.199e-06, loss 0.058162\n",
      "Stage: train, iter: 27120, lr: 7.185e-06, loss 0.109952\n",
      "Stage: train, iter: 27140, lr: 7.171e-06, loss 0.109844\n",
      "Stage: train, iter: 27160, lr: 7.157e-06, loss 0.088597\n",
      "Stage: train, iter: 27180, lr: 7.143e-06, loss 0.082298\n",
      "Stage: train, iter: 27200, lr: 7.129e-06, loss 0.089740\n",
      "Stage: train, iter: 27220, lr: 7.114e-06, loss 0.065271\n",
      "Stage: train, iter: 27240, lr: 7.100e-06, loss 0.071021\n",
      "Stage: train, iter: 27260, lr: 7.086e-06, loss 0.065861\n",
      "Stage: train, iter: 27280, lr: 7.072e-06, loss 0.054893\n",
      "Stage: train, iter: 27300, lr: 7.057e-06, loss 0.064213\n",
      "Stage: train, iter: 27320, lr: 7.043e-06, loss 0.060893\n",
      "Stage: train, iter: 27340, lr: 7.029e-06, loss 0.100089\n",
      "Stage: train, iter: 27360, lr: 7.014e-06, loss 0.050943\n",
      "Stage: train, iter: 27380, lr: 7.000e-06, loss 0.105492\n",
      "Stage: train, iter: 27400, lr: 6.985e-06, loss 0.093868\n",
      "Stage: train, iter: 27420, lr: 6.971e-06, loss 0.093949\n",
      "Stage: train, iter: 27440, lr: 6.957e-06, loss 0.061514\n",
      "Stage: train, iter: 27460, lr: 6.942e-06, loss 0.053624\n",
      "Stage: train, iter: 27480, lr: 6.928e-06, loss 0.080621\n",
      "Stage: train, iter: 27500, lr: 6.913e-06, loss 0.087080\n",
      "Stage: train, iter: 27520, lr: 6.899e-06, loss 0.098954\n",
      "Stage: train, iter: 27540, lr: 6.884e-06, loss 0.068586\n",
      "Stage: train, iter: 27560, lr: 6.870e-06, loss 0.065667\n",
      "Stage: train, iter: 27580, lr: 6.855e-06, loss 0.073135\n",
      "Stage: train, iter: 27600, lr: 6.840e-06, loss 0.079428\n",
      "Stage: train, iter: 27620, lr: 6.826e-06, loss 0.053147\n",
      "Stage: train, iter: 27640, lr: 6.811e-06, loss 0.043619\n",
      "Stage: train, iter: 27660, lr: 6.796e-06, loss 0.090774\n",
      "Stage: train, iter: 27680, lr: 6.782e-06, loss 0.105785\n",
      "Stage: train, iter: 27700, lr: 6.767e-06, loss 0.069247\n",
      "Stage: train, iter: 27720, lr: 6.752e-06, loss 0.093545\n",
      "Stage: train, iter: 27740, lr: 6.738e-06, loss 0.064908\n",
      "Stage: train, iter: 27760, lr: 6.723e-06, loss 0.093381\n",
      "Stage: train, iter: 27780, lr: 6.708e-06, loss 0.072985\n",
      "Stage: train, iter: 27800, lr: 6.693e-06, loss 0.091715\n",
      "Stage: train, iter: 27820, lr: 6.679e-06, loss 0.052045\n",
      "Stage: train, iter: 27840, lr: 6.664e-06, loss 0.073530\n",
      "Stage: train, iter: 27860, lr: 6.649e-06, loss 0.092096\n",
      "Stage: train, iter: 27880, lr: 6.634e-06, loss 0.064447\n",
      "Stage: train, iter: 27900, lr: 6.619e-06, loss 0.061304\n",
      "Stage: train, iter: 27920, lr: 6.604e-06, loss 0.104836\n",
      "Stage: train, iter: 27940, lr: 6.590e-06, loss 0.076044\n",
      "Stage: train, iter: 27960, lr: 6.575e-06, loss 0.072621\n",
      "Stage: train, iter: 27980, lr: 6.560e-06, loss 0.067627\n",
      "Stage: train, iter: 28000, lr: 6.545e-06, loss 0.091342\n",
      "Stage: train, iter: 28020, lr: 6.530e-06, loss 0.076679\n",
      "Stage: train, iter: 28040, lr: 6.515e-06, loss 0.075007\n",
      "Stage: train, iter: 28060, lr: 6.500e-06, loss 0.067084\n",
      "Stage: train, iter: 28080, lr: 6.485e-06, loss 0.091693\n",
      "Stage: train, iter: 28100, lr: 6.470e-06, loss 0.094694\n",
      "Stage: train, iter: 28120, lr: 6.455e-06, loss 0.085061\n",
      "Stage: train, iter: 28140, lr: 6.440e-06, loss 0.093012\n",
      "Stage: train, iter: 28160, lr: 6.425e-06, loss 0.057095\n",
      "Stage: train, iter: 28180, lr: 6.410e-06, loss 0.089763\n",
      "Stage: train, iter: 28200, lr: 6.395e-06, loss 0.079585\n",
      "Stage: train, iter: 28220, lr: 6.380e-06, loss 0.084981\n",
      "Stage: train, iter: 28240, lr: 6.364e-06, loss 0.062645\n",
      "Stage: train, iter: 28260, lr: 6.349e-06, loss 0.082986\n",
      "Stage: train, iter: 28280, lr: 6.334e-06, loss 0.106314\n",
      "Stage: train, iter: 28300, lr: 6.319e-06, loss 0.096781\n",
      "Stage: train, iter: 28320, lr: 6.304e-06, loss 0.104876\n",
      "Stage: train, iter: 28340, lr: 6.289e-06, loss 0.079244\n",
      "Stage: train, iter: 28360, lr: 6.274e-06, loss 0.080511\n",
      "Stage: train, iter: 28380, lr: 6.258e-06, loss 0.103332\n",
      "Stage: train, iter: 28400, lr: 6.243e-06, loss 0.071460\n",
      "Stage: train, iter: 28420, lr: 6.228e-06, loss 0.087587\n",
      "Stage: train, iter: 28440, lr: 6.213e-06, loss 0.089608\n",
      "Stage: train, iter: 28460, lr: 6.197e-06, loss 0.058340\n",
      "Stage: train, iter: 28480, lr: 6.182e-06, loss 0.063118\n",
      "Stage: train, iter: 28500, lr: 6.167e-06, loss 0.071662\n",
      "Stage: train, iter: 28520, lr: 6.152e-06, loss 0.069053\n",
      "Stage: train, iter: 28540, lr: 6.136e-06, loss 0.108131\n",
      "Stage: train, iter: 28560, lr: 6.121e-06, loss 0.135346\n",
      "Stage: train, iter: 28580, lr: 6.106e-06, loss 0.097528\n",
      "Stage: train, iter: 28600, lr: 6.090e-06, loss 0.086173\n",
      "Stage: train, iter: 28620, lr: 6.075e-06, loss 0.134054\n",
      "Stage: train, iter: 28640, lr: 6.060e-06, loss 0.088821\n",
      "Stage: train, iter: 28660, lr: 6.044e-06, loss 0.079741\n",
      "Stage: train, iter: 28680, lr: 6.029e-06, loss 0.075088\n",
      "Stage: train, iter: 28700, lr: 6.014e-06, loss 0.113764\n",
      "Stage: train, iter: 28720, lr: 5.998e-06, loss 0.068122\n",
      "Stage: train, iter: 28740, lr: 5.983e-06, loss 0.112974\n",
      "Stage: train, iter: 28760, lr: 5.967e-06, loss 0.094149\n",
      "Stage: train, iter: 28780, lr: 5.952e-06, loss 0.060585\n",
      "Stage: train, iter: 28800, lr: 5.937e-06, loss 0.081474\n",
      "Stage: train, iter: 28820, lr: 5.921e-06, loss 0.111667\n",
      "Stage: train, iter: 28840, lr: 5.906e-06, loss 0.067016\n",
      "Stage: train, iter: 28860, lr: 5.890e-06, loss 0.058679\n",
      "Stage: train, iter: 28880, lr: 5.875e-06, loss 0.118900\n",
      "Stage: train, iter: 28900, lr: 5.859e-06, loss 0.079442\n",
      "Stage: train, iter: 28920, lr: 5.844e-06, loss 0.042869\n",
      "Stage: train, iter: 28940, lr: 5.828e-06, loss 0.060319\n",
      "Stage: train, iter: 28960, lr: 5.813e-06, loss 0.105362\n",
      "Stage: train, iter: 28980, lr: 5.797e-06, loss 0.080646\n",
      "Stage: train, iter: 29000, lr: 5.782e-06, loss 0.065811\n",
      "Stage: train, iter: 29020, lr: 5.766e-06, loss 0.094550\n",
      "Stage: train, iter: 29040, lr: 5.751e-06, loss 0.123191\n",
      "Stage: train, iter: 29060, lr: 5.735e-06, loss 0.058540\n",
      "Stage: train, iter: 29080, lr: 5.720e-06, loss 0.058126\n",
      "Stage: train, iter: 29100, lr: 5.704e-06, loss 0.079218\n",
      "Stage: train, iter: 29120, lr: 5.689e-06, loss 0.052786\n",
      "Stage: train, iter: 29140, lr: 5.673e-06, loss 0.046885\n",
      "Stage: train, iter: 29160, lr: 5.657e-06, loss 0.088490\n",
      "Stage: train, iter: 29180, lr: 5.642e-06, loss 0.096241\n",
      "Stage: train, iter: 29200, lr: 5.626e-06, loss 0.111021\n",
      "Stage: train, iter: 29220, lr: 5.611e-06, loss 0.076218\n",
      "Stage: train, iter: 29240, lr: 5.595e-06, loss 0.109464\n",
      "Stage: train, iter: 29260, lr: 5.580e-06, loss 0.089184\n",
      "Stage: train, iter: 29280, lr: 5.564e-06, loss 0.059684\n",
      "Stage: train, iter: 29300, lr: 5.548e-06, loss 0.110924\n",
      "Stage: train, iter: 29320, lr: 5.533e-06, loss 0.066675\n",
      "Stage: train, iter: 29340, lr: 5.517e-06, loss 0.079531\n",
      "Stage: train, iter: 29360, lr: 5.501e-06, loss 0.128766\n",
      "Stage: train, iter: 29380, lr: 5.486e-06, loss 0.103101\n",
      "Stage: train, iter: 29400, lr: 5.470e-06, loss 0.134963\n",
      "Stage: train, iter: 29420, lr: 5.455e-06, loss 0.073548\n",
      "Stage: train, iter: 29440, lr: 5.439e-06, loss 0.112482\n",
      "Stage: train, iter: 29460, lr: 5.423e-06, loss 0.086313\n",
      "Stage: train, iter: 29480, lr: 5.408e-06, loss 0.117598\n",
      "Stage: train, iter: 29500, lr: 5.392e-06, loss 0.070584\n",
      "Stage: train, iter: 29520, lr: 5.376e-06, loss 0.071966\n",
      "Stage: train, iter: 29540, lr: 5.361e-06, loss 0.078751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 29560, lr: 5.345e-06, loss 0.100932\n",
      "Stage: train, iter: 29580, lr: 5.329e-06, loss 0.076867\n",
      "Stage: train, iter: 29600, lr: 5.314e-06, loss 0.109080\n",
      "Stage: train, iter: 29620, lr: 5.298e-06, loss 0.093969\n",
      "Stage: train, iter: 29640, lr: 5.282e-06, loss 0.093567\n",
      "Stage: train, iter: 29660, lr: 5.267e-06, loss 0.063790\n",
      "Stage: train, iter: 29680, lr: 5.251e-06, loss 0.092972\n",
      "Stage: train, iter: 29700, lr: 5.235e-06, loss 0.067166\n",
      "Stage: train, iter: 29720, lr: 5.219e-06, loss 0.089547\n",
      "Stage: train, iter: 29740, lr: 5.204e-06, loss 0.079011\n",
      "Stage: train, iter: 29760, lr: 5.188e-06, loss 0.093180\n",
      "Stage: train, iter: 29780, lr: 5.172e-06, loss 0.075034\n",
      "Stage: train, iter: 29800, lr: 5.157e-06, loss 0.117758\n",
      "Stage: train, iter: 29820, lr: 5.141e-06, loss 0.062221\n",
      "Stage: train, iter: 29840, lr: 5.125e-06, loss 0.095977\n",
      "Stage: train, iter: 29860, lr: 5.110e-06, loss 0.055045\n",
      "Stage: train, iter: 29880, lr: 5.094e-06, loss 0.051327\n",
      "Stage: train, iter: 29900, lr: 5.078e-06, loss 0.081322\n",
      "Stage: train, iter: 29920, lr: 5.062e-06, loss 0.050838\n",
      "Stage: train, iter: 29940, lr: 5.047e-06, loss 0.083872\n",
      "Stage: train, iter: 29960, lr: 5.031e-06, loss 0.096259\n",
      "Stage: train, iter: 29980, lr: 5.015e-06, loss 0.084870\n",
      "Stage: train, iter: 30000, lr: 5.000e-06, loss 0.077935\n",
      "Stage: train, iter: 30020, lr: 4.984e-06, loss 0.084904\n",
      "Stage: train, iter: 30040, lr: 4.968e-06, loss 0.059827\n",
      "Stage: train, iter: 30060, lr: 4.952e-06, loss 0.075466\n",
      "Stage: train, iter: 30080, lr: 4.937e-06, loss 0.043927\n",
      "Stage: train, iter: 30100, lr: 4.921e-06, loss 0.066531\n",
      "Stage: train, iter: 30120, lr: 4.905e-06, loss 0.079969\n",
      "Stage: train, iter: 30140, lr: 4.890e-06, loss 0.107718\n",
      "Stage: train, iter: 30160, lr: 4.874e-06, loss 0.084389\n",
      "Stage: train, iter: 30180, lr: 4.858e-06, loss 0.066782\n",
      "Stage: train, iter: 30200, lr: 4.843e-06, loss 0.117371\n",
      "Stage: train, iter: 30220, lr: 4.827e-06, loss 0.089076\n",
      "Stage: train, iter: 30240, lr: 4.811e-06, loss 0.063649\n",
      "Stage: train, iter: 30260, lr: 4.795e-06, loss 0.082289\n",
      "Stage: train, iter: 30280, lr: 4.780e-06, loss 0.109030\n",
      "Stage: train, iter: 30300, lr: 4.764e-06, loss 0.094832\n",
      "Stage: train, iter: 30320, lr: 4.748e-06, loss 0.072072\n",
      "Stage: train, iter: 30340, lr: 4.733e-06, loss 0.079126\n",
      "Stage: train, iter: 30360, lr: 4.717e-06, loss 0.079098\n",
      "Stage: train, iter: 30380, lr: 4.701e-06, loss 0.112603\n",
      "Stage: train, iter: 30400, lr: 4.686e-06, loss 0.083877\n",
      "Stage: train, iter: 30420, lr: 4.670e-06, loss 0.060622\n",
      "Stage: train, iter: 30440, lr: 4.654e-06, loss 0.070290\n",
      "Stage: train, iter: 30460, lr: 4.639e-06, loss 0.134103\n",
      "Stage: train, iter: 30480, lr: 4.623e-06, loss 0.042440\n",
      "Stage: train, iter: 30500, lr: 4.607e-06, loss 0.109234\n",
      "Stage: train, iter: 30520, lr: 4.592e-06, loss 0.112163\n",
      "Stage: train, iter: 30540, lr: 4.576e-06, loss 0.096263\n",
      "Stage: train, iter: 30560, lr: 4.560e-06, loss 0.082694\n",
      "Stage: train, iter: 30580, lr: 4.545e-06, loss 0.093490\n",
      "Stage: train, iter: 30600, lr: 4.529e-06, loss 0.099696\n",
      "Stage: train, iter: 30620, lr: 4.513e-06, loss 0.068718\n",
      "Stage: train, iter: 30640, lr: 4.498e-06, loss 0.064094\n",
      "Stage: train, iter: 30660, lr: 4.482e-06, loss 0.080327\n",
      "Stage: train, iter: 30680, lr: 4.467e-06, loss 0.129303\n",
      "Stage: train, iter: 30700, lr: 4.451e-06, loss 0.067080\n",
      "Stage: train, iter: 30720, lr: 4.435e-06, loss 0.059179\n",
      "Stage: train, iter: 30740, lr: 4.420e-06, loss 0.059830\n",
      "Stage: train, iter: 30760, lr: 4.404e-06, loss 0.102717\n",
      "Stage: train, iter: 30780, lr: 4.389e-06, loss 0.053675\n",
      "Stage: train, iter: 30800, lr: 4.373e-06, loss 0.089704\n",
      "Stage: train, iter: 30820, lr: 4.357e-06, loss 0.079580\n",
      "Stage: train, iter: 30840, lr: 4.342e-06, loss 0.088226\n",
      "Stage: train, iter: 30860, lr: 4.326e-06, loss 0.117832\n",
      "Stage: train, iter: 30880, lr: 4.311e-06, loss 0.057458\n",
      "Stage: train, iter: 30900, lr: 4.295e-06, loss 0.108426\n",
      "Stage: train, iter: 30920, lr: 4.280e-06, loss 0.084332\n",
      "Stage: train, iter: 30940, lr: 4.264e-06, loss 0.071069\n",
      "Stage: train, iter: 30960, lr: 4.248e-06, loss 0.103423\n",
      "Stage: train, iter: 30980, lr: 4.233e-06, loss 0.106406\n",
      "Stage: train, iter: 31000, lr: 4.217e-06, loss 0.096761\n",
      "Stage: train, iter: 31020, lr: 4.202e-06, loss 0.103497\n",
      "Stage: train, iter: 31040, lr: 4.186e-06, loss 0.105190\n",
      "Stage: train, iter: 31060, lr: 4.171e-06, loss 0.104829\n",
      "Stage: train, iter: 31080, lr: 4.155e-06, loss 0.098236\n",
      "Stage: train, iter: 31100, lr: 4.140e-06, loss 0.090604\n",
      "Stage: train, iter: 31120, lr: 4.124e-06, loss 0.072004\n",
      "Stage: train, iter: 31140, lr: 4.109e-06, loss 0.085998\n",
      "Stage: train, iter: 31160, lr: 4.094e-06, loss 0.108172\n",
      "Stage: train, iter: 31180, lr: 4.078e-06, loss 0.088075\n",
      "Stage: train, iter: 31200, lr: 4.063e-06, loss 0.066325\n",
      "Stage: train, iter: 31220, lr: 4.047e-06, loss 0.071767\n",
      "Stage: train, iter: 31240, lr: 4.032e-06, loss 0.062525\n",
      "Stage: train, iter: 31260, lr: 4.016e-06, loss 0.074077\n",
      "Stage: train, iter: 31280, lr: 4.001e-06, loss 0.060746\n",
      "Stage: train, iter: 31300, lr: 3.986e-06, loss 0.094678\n",
      "Stage: train, iter: 31320, lr: 3.970e-06, loss 0.068621\n",
      "Stage: train, iter: 31340, lr: 3.955e-06, loss 0.084425\n",
      "Stage: train, iter: 31360, lr: 3.940e-06, loss 0.069850\n",
      "Stage: train, iter: 31380, lr: 3.924e-06, loss 0.078112\n",
      "Stage: train, iter: 31400, lr: 3.909e-06, loss 0.096407\n",
      "Stage: train, iter: 31420, lr: 3.894e-06, loss 0.096981\n",
      "Stage: train, iter: 31440, lr: 3.878e-06, loss 0.070327\n",
      "Stage: train, iter: 31460, lr: 3.863e-06, loss 0.125542\n",
      "Stage: train, iter: 31480, lr: 3.848e-06, loss 0.097455\n",
      "Stage: train, iter: 31500, lr: 3.832e-06, loss 0.084203\n",
      "Stage: train, iter: 31520, lr: 3.817e-06, loss 0.078752\n",
      "Stage: train, iter: 31540, lr: 3.802e-06, loss 0.061274\n",
      "Stage: train, iter: 31560, lr: 3.787e-06, loss 0.079023\n",
      "Stage: train, iter: 31580, lr: 3.771e-06, loss 0.093925\n",
      "Stage: train, iter: 31600, lr: 3.756e-06, loss 0.083140\n",
      "Stage: train, iter: 31620, lr: 3.741e-06, loss 0.071443\n",
      "Stage: train, iter: 31640, lr: 3.726e-06, loss 0.072015\n",
      "Stage: train, iter: 31660, lr: 3.711e-06, loss 0.087910\n",
      "Stage: train, iter: 31680, lr: 3.695e-06, loss 0.096882\n",
      "Stage: train, iter: 31700, lr: 3.680e-06, loss 0.119691\n",
      "Stage: train, iter: 31720, lr: 3.665e-06, loss 0.091082\n",
      "Stage: train, iter: 31740, lr: 3.650e-06, loss 0.051163\n",
      "Stage: train, iter: 31760, lr: 3.635e-06, loss 0.049457\n",
      "Stage: train, iter: 31780, lr: 3.620e-06, loss 0.077536\n",
      "Stage: train, iter: 31800, lr: 3.605e-06, loss 0.085434\n",
      "Stage: train, iter: 31820, lr: 3.590e-06, loss 0.123149\n",
      "Stage: train, iter: 31840, lr: 3.574e-06, loss 0.084737\n",
      "Stage: train, iter: 31860, lr: 3.559e-06, loss 0.085669\n",
      "Stage: train, iter: 31880, lr: 3.544e-06, loss 0.089295\n",
      "Stage: train, iter: 31900, lr: 3.529e-06, loss 0.109300\n",
      "Stage: train, iter: 31920, lr: 3.514e-06, loss 0.072145\n",
      "Stage: train, iter: 31940, lr: 3.499e-06, loss 0.105710\n",
      "Stage: train, iter: 31960, lr: 3.484e-06, loss 0.053130\n",
      "Stage: train, iter: 31980, lr: 3.469e-06, loss 0.077294\n",
      "Stage: train, iter: 32000, lr: 3.454e-06, loss 0.053869\n",
      "Stage: train, iter: 32020, lr: 3.440e-06, loss 0.097281\n",
      "Stage: train, iter: 32040, lr: 3.425e-06, loss 0.079083\n",
      "Stage: train, iter: 32060, lr: 3.410e-06, loss 0.049958\n",
      "Stage: train, iter: 32080, lr: 3.395e-06, loss 0.160221\n",
      "Stage: train, iter: 32100, lr: 3.380e-06, loss 0.100365\n",
      "Stage: train, iter: 32120, lr: 3.365e-06, loss 0.117539\n",
      "Stage: train, iter: 32140, lr: 3.350e-06, loss 0.059982\n",
      "Stage: train, iter: 32160, lr: 3.335e-06, loss 0.081117\n",
      "Stage: train, iter: 32180, lr: 3.321e-06, loss 0.057611\n",
      "Stage: train, iter: 32200, lr: 3.306e-06, loss 0.098995\n",
      "Stage: train, iter: 32220, lr: 3.291e-06, loss 0.092775\n",
      "Stage: train, iter: 32240, lr: 3.276e-06, loss 0.063902\n",
      "Stage: train, iter: 32260, lr: 3.262e-06, loss 0.093534\n",
      "Stage: train, iter: 32280, lr: 3.247e-06, loss 0.112867\n",
      "Stage: train, iter: 32300, lr: 3.232e-06, loss 0.069847\n",
      "Stage: train, iter: 32320, lr: 3.217e-06, loss 0.062617\n",
      "Stage: train, iter: 32340, lr: 3.203e-06, loss 0.067707\n",
      "Stage: train, iter: 32360, lr: 3.188e-06, loss 0.066058\n",
      "Stage: train, iter: 32380, lr: 3.174e-06, loss 0.102372\n",
      "Stage: train, iter: 32400, lr: 3.159e-06, loss 0.033121\n",
      "Stage: train, iter: 32420, lr: 3.144e-06, loss 0.061107\n",
      "Stage: train, iter: 32440, lr: 3.130e-06, loss 0.069287\n",
      "Stage: train, iter: 32460, lr: 3.115e-06, loss 0.085751\n",
      "Stage: train, iter: 32480, lr: 3.101e-06, loss 0.112657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 32500, lr: 3.086e-06, loss 0.099476\n",
      "Stage: train, iter: 32520, lr: 3.072e-06, loss 0.097280\n",
      "Stage: train, iter: 32540, lr: 3.057e-06, loss 0.060685\n",
      "Stage: train, iter: 32560, lr: 3.043e-06, loss 0.076163\n",
      "Stage: train, iter: 32580, lr: 3.028e-06, loss 0.105355\n",
      "Stage: train, iter: 32600, lr: 3.014e-06, loss 0.100916\n",
      "Stage: train, iter: 32620, lr: 2.999e-06, loss 0.067461\n",
      "Stage: train, iter: 32640, lr: 2.985e-06, loss 0.112676\n",
      "Stage: train, iter: 32660, lr: 2.971e-06, loss 0.084230\n",
      "Stage: train, iter: 32680, lr: 2.956e-06, loss 0.094824\n",
      "Stage: train, iter: 32700, lr: 2.942e-06, loss 0.108044\n",
      "Stage: train, iter: 32720, lr: 2.928e-06, loss 0.093733\n",
      "Stage: train, iter: 32740, lr: 2.913e-06, loss 0.090211\n",
      "Stage: train, iter: 32760, lr: 2.899e-06, loss 0.099688\n",
      "Stage: train, iter: 32780, lr: 2.885e-06, loss 0.125503\n",
      "Stage: train, iter: 32800, lr: 2.871e-06, loss 0.086356\n",
      "Stage: train, iter: 32820, lr: 2.856e-06, loss 0.132260\n",
      "Stage: train, iter: 32840, lr: 2.842e-06, loss 0.072145\n",
      "Stage: train, iter: 32860, lr: 2.828e-06, loss 0.072508\n",
      "Stage: train, iter: 32880, lr: 2.814e-06, loss 0.100941\n",
      "Stage: train, iter: 32900, lr: 2.800e-06, loss 0.068645\n",
      "Stage: train, iter: 32920, lr: 2.786e-06, loss 0.048265\n",
      "Stage: train, iter: 32940, lr: 2.772e-06, loss 0.060398\n",
      "Stage: train, iter: 32960, lr: 2.758e-06, loss 0.054864\n",
      "Stage: train, iter: 32980, lr: 2.744e-06, loss 0.078781\n",
      "Stage: train, iter: 33000, lr: 2.730e-06, loss 0.095594\n",
      "Stage: train, iter: 33020, lr: 2.716e-06, loss 0.099983\n",
      "Stage: train, iter: 33040, lr: 2.702e-06, loss 0.076821\n",
      "Stage: train, iter: 33060, lr: 2.688e-06, loss 0.104797\n",
      "Stage: train, iter: 33080, lr: 2.674e-06, loss 0.092548\n",
      "Stage: train, iter: 33100, lr: 2.660e-06, loss 0.098980\n",
      "Stage: train, iter: 33120, lr: 2.646e-06, loss 0.107275\n",
      "Stage: train, iter: 33140, lr: 2.632e-06, loss 0.080632\n",
      "Stage: train, iter: 33160, lr: 2.618e-06, loss 0.106582\n",
      "Stage: train, iter: 33180, lr: 2.605e-06, loss 0.055814\n",
      "Stage: train, iter: 33200, lr: 2.591e-06, loss 0.058644\n",
      "Stage: train, iter: 33220, lr: 2.577e-06, loss 0.098235\n",
      "Stage: train, iter: 33240, lr: 2.563e-06, loss 0.081999\n",
      "Stage: train, iter: 33260, lr: 2.550e-06, loss 0.088555\n",
      "Stage: train, iter: 33280, lr: 2.536e-06, loss 0.053734\n",
      "Stage: train, iter: 33300, lr: 2.522e-06, loss 0.056395\n",
      "Stage: train, iter: 33320, lr: 2.509e-06, loss 0.055603\n",
      "Stage: train, iter: 33340, lr: 2.495e-06, loss 0.109585\n",
      "Stage: train, iter: 33360, lr: 2.481e-06, loss 0.112375\n",
      "Stage: train, iter: 33380, lr: 2.468e-06, loss 0.082589\n",
      "Stage: train, iter: 33400, lr: 2.454e-06, loss 0.042160\n",
      "Stage: train, iter: 33420, lr: 2.441e-06, loss 0.043547\n",
      "Stage: train, iter: 33440, lr: 2.427e-06, loss 0.102241\n",
      "Stage: train, iter: 33460, lr: 2.414e-06, loss 0.081121\n",
      "Stage: train, iter: 33480, lr: 2.400e-06, loss 0.097495\n",
      "Stage: train, iter: 33500, lr: 2.387e-06, loss 0.067920\n",
      "Stage: train, iter: 33520, lr: 2.374e-06, loss 0.117130\n",
      "Stage: train, iter: 33540, lr: 2.360e-06, loss 0.062885\n",
      "Stage: train, iter: 33560, lr: 2.347e-06, loss 0.072374\n",
      "Stage: train, iter: 33580, lr: 2.334e-06, loss 0.089702\n",
      "Stage: train, iter: 33600, lr: 2.320e-06, loss 0.087924\n",
      "Stage: train, iter: 33620, lr: 2.307e-06, loss 0.079840\n",
      "Stage: train, iter: 33640, lr: 2.294e-06, loss 0.059043\n",
      "Stage: train, iter: 33660, lr: 2.281e-06, loss 0.085421\n",
      "Stage: train, iter: 33680, lr: 2.268e-06, loss 0.105381\n",
      "Stage: train, iter: 33700, lr: 2.254e-06, loss 0.093357\n",
      "Stage: train, iter: 33720, lr: 2.241e-06, loss 0.039335\n",
      "Stage: train, iter: 33740, lr: 2.228e-06, loss 0.086084\n",
      "Stage: train, iter: 33760, lr: 2.215e-06, loss 0.083370\n",
      "Stage: train, iter: 33780, lr: 2.202e-06, loss 0.076608\n",
      "Stage: train, iter: 33800, lr: 2.189e-06, loss 0.109393\n",
      "Stage: train, iter: 33820, lr: 2.176e-06, loss 0.097691\n",
      "Stage: train, iter: 33840, lr: 2.163e-06, loss 0.073783\n",
      "Stage: train, iter: 33860, lr: 2.150e-06, loss 0.091724\n",
      "Stage: train, iter: 33880, lr: 2.137e-06, loss 0.074798\n",
      "Stage: train, iter: 33900, lr: 2.125e-06, loss 0.074830\n",
      "Stage: train, iter: 33920, lr: 2.112e-06, loss 0.112078\n",
      "Stage: train, iter: 33940, lr: 2.099e-06, loss 0.100711\n",
      "Stage: train, iter: 33960, lr: 2.086e-06, loss 0.056060\n",
      "Stage: train, iter: 33980, lr: 2.073e-06, loss 0.105733\n",
      "Stage: train, iter: 34000, lr: 2.061e-06, loss 0.064670\n",
      "Stage: train, iter: 34020, lr: 2.048e-06, loss 0.083529\n",
      "Stage: train, iter: 34040, lr: 2.035e-06, loss 0.079546\n",
      "Stage: train, iter: 34060, lr: 2.023e-06, loss 0.054984\n",
      "Stage: train, iter: 34080, lr: 2.010e-06, loss 0.045875\n",
      "Stage: train, iter: 34100, lr: 1.997e-06, loss 0.078558\n",
      "Stage: train, iter: 34120, lr: 1.985e-06, loss 0.061044\n",
      "Stage: train, iter: 34140, lr: 1.972e-06, loss 0.086119\n",
      "Stage: train, iter: 34160, lr: 1.960e-06, loss 0.093446\n",
      "Stage: train, iter: 34180, lr: 1.947e-06, loss 0.099078\n",
      "Stage: train, iter: 34200, lr: 1.935e-06, loss 0.085030\n",
      "Stage: train, iter: 34220, lr: 1.923e-06, loss 0.106019\n",
      "Stage: train, iter: 34240, lr: 1.910e-06, loss 0.068019\n",
      "Stage: train, iter: 34260, lr: 1.898e-06, loss 0.076209\n",
      "Stage: train, iter: 34280, lr: 1.886e-06, loss 0.070697\n",
      "Stage: train, iter: 34300, lr: 1.873e-06, loss 0.072708\n",
      "Stage: train, iter: 34320, lr: 1.861e-06, loss 0.064834\n",
      "Stage: train, iter: 34340, lr: 1.849e-06, loss 0.101504\n",
      "Stage: train, iter: 34360, lr: 1.837e-06, loss 0.076846\n",
      "Stage: train, iter: 34380, lr: 1.825e-06, loss 0.092782\n",
      "Stage: train, iter: 34400, lr: 1.812e-06, loss 0.103265\n",
      "Stage: train, iter: 34420, lr: 1.800e-06, loss 0.098532\n",
      "Stage: train, iter: 34440, lr: 1.788e-06, loss 0.112254\n",
      "Stage: train, iter: 34460, lr: 1.776e-06, loss 0.111674\n",
      "Stage: train, iter: 34480, lr: 1.764e-06, loss 0.086035\n",
      "Stage: train, iter: 34500, lr: 1.752e-06, loss 0.094102\n",
      "Stage: train, iter: 34520, lr: 1.740e-06, loss 0.072475\n",
      "Stage: train, iter: 34540, lr: 1.729e-06, loss 0.082256\n",
      "Stage: train, iter: 34560, lr: 1.717e-06, loss 0.081891\n",
      "Stage: train, iter: 34580, lr: 1.705e-06, loss 0.077312\n",
      "Stage: train, iter: 34600, lr: 1.693e-06, loss 0.077163\n",
      "Stage: train, iter: 34620, lr: 1.681e-06, loss 0.067668\n",
      "Stage: train, iter: 34640, lr: 1.670e-06, loss 0.046571\n",
      "Stage: train, iter: 34660, lr: 1.658e-06, loss 0.052337\n",
      "Stage: train, iter: 34680, lr: 1.646e-06, loss 0.084587\n",
      "Stage: train, iter: 34700, lr: 1.635e-06, loss 0.084022\n",
      "Stage: train, iter: 34720, lr: 1.623e-06, loss 0.051282\n",
      "Stage: train, iter: 34740, lr: 1.611e-06, loss 0.086537\n",
      "Stage: train, iter: 34760, lr: 1.600e-06, loss 0.092801\n",
      "Stage: train, iter: 34780, lr: 1.588e-06, loss 0.054276\n",
      "Stage: train, iter: 34800, lr: 1.577e-06, loss 0.068118\n",
      "Stage: train, iter: 34820, lr: 1.565e-06, loss 0.056625\n",
      "Stage: train, iter: 34840, lr: 1.554e-06, loss 0.061437\n",
      "Stage: train, iter: 34860, lr: 1.543e-06, loss 0.097508\n",
      "Stage: train, iter: 34880, lr: 1.531e-06, loss 0.092834\n",
      "Stage: train, iter: 34900, lr: 1.520e-06, loss 0.079547\n",
      "Stage: train, iter: 34920, lr: 1.509e-06, loss 0.093477\n",
      "Stage: train, iter: 34940, lr: 1.498e-06, loss 0.080463\n",
      "Stage: train, iter: 34960, lr: 1.486e-06, loss 0.087973\n",
      "Stage: train, iter: 34980, lr: 1.475e-06, loss 0.072014\n",
      "Stage: train, iter: 35000, lr: 1.464e-06, loss 0.074123\n",
      "Stage: train, iter: 35020, lr: 1.453e-06, loss 0.090747\n",
      "Stage: train, iter: 35040, lr: 1.442e-06, loss 0.068217\n",
      "Stage: train, iter: 35060, lr: 1.431e-06, loss 0.065783\n",
      "Stage: train, iter: 35080, lr: 1.420e-06, loss 0.043035\n",
      "Stage: train, iter: 35100, lr: 1.409e-06, loss 0.088083\n",
      "Stage: train, iter: 35120, lr: 1.398e-06, loss 0.070401\n",
      "Stage: train, iter: 35140, lr: 1.387e-06, loss 0.132229\n",
      "Stage: train, iter: 35160, lr: 1.376e-06, loss 0.109117\n",
      "Stage: train, iter: 35180, lr: 1.366e-06, loss 0.117631\n",
      "Stage: train, iter: 35200, lr: 1.355e-06, loss 0.041865\n",
      "Stage: train, iter: 35220, lr: 1.344e-06, loss 0.085477\n",
      "Stage: train, iter: 35240, lr: 1.333e-06, loss 0.084094\n",
      "Stage: train, iter: 35260, lr: 1.323e-06, loss 0.100343\n",
      "Stage: train, iter: 35280, lr: 1.312e-06, loss 0.092903\n",
      "Stage: train, iter: 35300, lr: 1.301e-06, loss 0.063955\n",
      "Stage: train, iter: 35320, lr: 1.291e-06, loss 0.077772\n",
      "Stage: train, iter: 35340, lr: 1.280e-06, loss 0.069884\n",
      "Stage: train, iter: 35360, lr: 1.270e-06, loss 0.058632\n",
      "Stage: train, iter: 35380, lr: 1.259e-06, loss 0.100818\n",
      "Stage: train, iter: 35400, lr: 1.249e-06, loss 0.111249\n",
      "Stage: train, iter: 35420, lr: 1.239e-06, loss 0.072203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 35440, lr: 1.228e-06, loss 0.132337\n",
      "Stage: train, iter: 35460, lr: 1.218e-06, loss 0.095514\n",
      "Stage: train, iter: 35480, lr: 1.208e-06, loss 0.100500\n",
      "Stage: train, iter: 35500, lr: 1.198e-06, loss 0.044159\n",
      "Stage: train, iter: 35520, lr: 1.187e-06, loss 0.078521\n",
      "Stage: train, iter: 35540, lr: 1.177e-06, loss 0.081389\n",
      "Stage: train, iter: 35560, lr: 1.167e-06, loss 0.086981\n",
      "Stage: train, iter: 35580, lr: 1.157e-06, loss 0.076707\n",
      "Stage: train, iter: 35600, lr: 1.147e-06, loss 0.064975\n",
      "Stage: train, iter: 35620, lr: 1.137e-06, loss 0.089511\n",
      "Stage: train, iter: 35640, lr: 1.127e-06, loss 0.134328\n",
      "Stage: train, iter: 35660, lr: 1.117e-06, loss 0.083677\n",
      "Stage: train, iter: 35680, lr: 1.107e-06, loss 0.087442\n",
      "Stage: train, iter: 35700, lr: 1.097e-06, loss 0.066915\n",
      "Stage: train, iter: 35720, lr: 1.088e-06, loss 0.073322\n",
      "Stage: train, iter: 35740, lr: 1.078e-06, loss 0.088644\n",
      "Stage: train, iter: 35760, lr: 1.068e-06, loss 0.081197\n",
      "Stage: train, iter: 35780, lr: 1.058e-06, loss 0.080717\n",
      "Stage: train, iter: 35800, lr: 1.049e-06, loss 0.061932\n",
      "Stage: train, iter: 35820, lr: 1.039e-06, loss 0.084456\n",
      "Stage: train, iter: 35840, lr: 1.030e-06, loss 0.102643\n",
      "Stage: train, iter: 35860, lr: 1.020e-06, loss 0.064148\n",
      "Stage: train, iter: 35880, lr: 1.011e-06, loss 0.099404\n",
      "Stage: train, iter: 35900, lr: 1.001e-06, loss 0.061548\n",
      "Stage: train, iter: 35920, lr: 9.918e-07, loss 0.098158\n",
      "Stage: train, iter: 35940, lr: 9.824e-07, loss 0.086467\n",
      "Stage: train, iter: 35960, lr: 9.731e-07, loss 0.097786\n",
      "Stage: train, iter: 35980, lr: 9.638e-07, loss 0.072621\n",
      "Stage: train, iter: 36000, lr: 9.545e-07, loss 0.079491\n",
      "Stage: train, iter: 36020, lr: 9.453e-07, loss 0.096373\n",
      "Stage: train, iter: 36040, lr: 9.362e-07, loss 0.084478\n",
      "Stage: train, iter: 36060, lr: 9.270e-07, loss 0.096827\n",
      "Stage: train, iter: 36080, lr: 9.179e-07, loss 0.037390\n",
      "Stage: train, iter: 36100, lr: 9.089e-07, loss 0.023319\n",
      "Stage: train, iter: 36120, lr: 8.999e-07, loss 0.092295\n",
      "Stage: train, iter: 36140, lr: 8.909e-07, loss 0.124810\n",
      "Stage: train, iter: 36160, lr: 8.820e-07, loss 0.112211\n",
      "Stage: train, iter: 36180, lr: 8.731e-07, loss 0.089957\n",
      "Stage: train, iter: 36200, lr: 8.642e-07, loss 0.078368\n",
      "Stage: train, iter: 36220, lr: 8.554e-07, loss 0.120614\n",
      "Stage: train, iter: 36240, lr: 8.467e-07, loss 0.063941\n",
      "Stage: train, iter: 36260, lr: 8.379e-07, loss 0.071858\n",
      "Stage: train, iter: 36280, lr: 8.293e-07, loss 0.093139\n",
      "Stage: train, iter: 36300, lr: 8.206e-07, loss 0.144577\n",
      "Stage: train, iter: 36320, lr: 8.120e-07, loss 0.065142\n",
      "Stage: train, iter: 36340, lr: 8.034e-07, loss 0.089780\n",
      "Stage: train, iter: 36360, lr: 7.949e-07, loss 0.090895\n",
      "Stage: train, iter: 36380, lr: 7.865e-07, loss 0.055298\n",
      "Stage: train, iter: 36400, lr: 7.780e-07, loss 0.090158\n",
      "Stage: train, iter: 36420, lr: 7.696e-07, loss 0.077856\n",
      "Stage: train, iter: 36440, lr: 7.613e-07, loss 0.068604\n",
      "Stage: train, iter: 36460, lr: 7.530e-07, loss 0.067153\n",
      "Stage: train, iter: 36480, lr: 7.447e-07, loss 0.083389\n",
      "Stage: train, iter: 36500, lr: 7.365e-07, loss 0.066083\n",
      "Stage: train, iter: 36520, lr: 7.283e-07, loss 0.076579\n",
      "Stage: train, iter: 36540, lr: 7.201e-07, loss 0.059856\n",
      "Stage: train, iter: 36560, lr: 7.120e-07, loss 0.104389\n",
      "Stage: train, iter: 36580, lr: 7.040e-07, loss 0.077960\n",
      "Stage: train, iter: 36600, lr: 6.960e-07, loss 0.124460\n",
      "Stage: train, iter: 36620, lr: 6.880e-07, loss 0.061667\n",
      "Stage: train, iter: 36640, lr: 6.801e-07, loss 0.064857\n",
      "Stage: train, iter: 36660, lr: 6.722e-07, loss 0.117021\n",
      "Stage: train, iter: 36680, lr: 6.643e-07, loss 0.099682\n",
      "Stage: train, iter: 36700, lr: 6.565e-07, loss 0.122859\n",
      "Stage: train, iter: 36720, lr: 6.488e-07, loss 0.072802\n",
      "Stage: train, iter: 36740, lr: 6.410e-07, loss 0.101396\n",
      "Stage: train, iter: 36760, lr: 6.334e-07, loss 0.082242\n",
      "Stage: train, iter: 36780, lr: 6.257e-07, loss 0.087799\n",
      "Stage: train, iter: 36800, lr: 6.181e-07, loss 0.076230\n",
      "Stage: train, iter: 36820, lr: 6.106e-07, loss 0.073124\n",
      "Stage: train, iter: 36840, lr: 6.031e-07, loss 0.058249\n",
      "Stage: train, iter: 36860, lr: 5.956e-07, loss 0.101639\n",
      "Stage: train, iter: 36880, lr: 5.882e-07, loss 0.094375\n",
      "Stage: train, iter: 36900, lr: 5.809e-07, loss 0.042725\n",
      "Stage: train, iter: 36920, lr: 5.735e-07, loss 0.109187\n",
      "Stage: train, iter: 36940, lr: 5.663e-07, loss 0.139283\n",
      "Stage: train, iter: 36960, lr: 5.590e-07, loss 0.097649\n",
      "Stage: train, iter: 36980, lr: 5.518e-07, loss 0.085893\n",
      "Stage: train, iter: 37000, lr: 5.447e-07, loss 0.094190\n",
      "Stage: train, iter: 37020, lr: 5.376e-07, loss 0.106546\n",
      "Stage: train, iter: 37040, lr: 5.305e-07, loss 0.067251\n",
      "Stage: train, iter: 37060, lr: 5.235e-07, loss 0.101568\n",
      "Stage: train, iter: 37080, lr: 5.165e-07, loss 0.060143\n",
      "Stage: train, iter: 37100, lr: 5.096e-07, loss 0.062925\n",
      "Stage: train, iter: 37120, lr: 5.027e-07, loss 0.102610\n",
      "Stage: train, iter: 37140, lr: 4.958e-07, loss 0.066062\n",
      "Stage: train, iter: 37160, lr: 4.890e-07, loss 0.047203\n",
      "Stage: train, iter: 37180, lr: 4.823e-07, loss 0.095857\n",
      "Stage: train, iter: 37200, lr: 4.756e-07, loss 0.079114\n",
      "Stage: train, iter: 37220, lr: 4.689e-07, loss 0.052448\n",
      "Stage: train, iter: 37240, lr: 4.623e-07, loss 0.088789\n",
      "Stage: train, iter: 37260, lr: 4.557e-07, loss 0.079485\n",
      "Stage: train, iter: 37280, lr: 4.492e-07, loss 0.099253\n",
      "Stage: train, iter: 37300, lr: 4.427e-07, loss 0.063916\n",
      "Stage: train, iter: 37320, lr: 4.363e-07, loss 0.085032\n",
      "Stage: train, iter: 37340, lr: 4.299e-07, loss 0.098874\n",
      "Stage: train, iter: 37360, lr: 4.235e-07, loss 0.070019\n",
      "Stage: train, iter: 37380, lr: 4.172e-07, loss 0.042975\n",
      "Stage: train, iter: 37400, lr: 4.110e-07, loss 0.070458\n",
      "Stage: train, iter: 37420, lr: 4.047e-07, loss 0.069462\n",
      "Stage: train, iter: 37440, lr: 3.986e-07, loss 0.111935\n",
      "Stage: train, iter: 37460, lr: 3.924e-07, loss 0.072669\n",
      "Stage: train, iter: 37480, lr: 3.864e-07, loss 0.126309\n",
      "Stage: train, iter: 37500, lr: 3.803e-07, loss 0.062867\n",
      "Stage: train, iter: 37520, lr: 3.744e-07, loss 0.078317\n",
      "Stage: train, iter: 37540, lr: 3.684e-07, loss 0.071217\n",
      "Stage: train, iter: 37560, lr: 3.625e-07, loss 0.062021\n",
      "Stage: train, iter: 37580, lr: 3.567e-07, loss 0.073343\n",
      "Stage: train, iter: 37600, lr: 3.509e-07, loss 0.092742\n",
      "Stage: train, iter: 37620, lr: 3.451e-07, loss 0.086717\n",
      "Stage: train, iter: 37640, lr: 3.394e-07, loss 0.099726\n",
      "Stage: train, iter: 37660, lr: 3.337e-07, loss 0.087135\n",
      "Stage: train, iter: 37680, lr: 3.281e-07, loss 0.087995\n",
      "Stage: train, iter: 37700, lr: 3.225e-07, loss 0.085382\n",
      "Stage: train, iter: 37720, lr: 3.170e-07, loss 0.102244\n",
      "Stage: train, iter: 37740, lr: 3.115e-07, loss 0.076612\n",
      "Stage: train, iter: 37760, lr: 3.061e-07, loss 0.110518\n",
      "Stage: train, iter: 37780, lr: 3.007e-07, loss 0.078919\n",
      "Stage: train, iter: 37800, lr: 2.954e-07, loss 0.085647\n",
      "Stage: train, iter: 37820, lr: 2.901e-07, loss 0.055819\n",
      "Stage: train, iter: 37840, lr: 2.848e-07, loss 0.063800\n",
      "Stage: train, iter: 37860, lr: 2.796e-07, loss 0.052495\n",
      "Stage: train, iter: 37880, lr: 2.745e-07, loss 0.097123\n",
      "Stage: train, iter: 37900, lr: 2.693e-07, loss 0.150349\n",
      "Stage: train, iter: 37920, lr: 2.643e-07, loss 0.092699\n",
      "Stage: train, iter: 37940, lr: 2.593e-07, loss 0.078819\n",
      "Stage: train, iter: 37960, lr: 2.543e-07, loss 0.044816\n",
      "Stage: train, iter: 37980, lr: 2.494e-07, loss 0.088489\n",
      "Stage: train, iter: 38000, lr: 2.445e-07, loss 0.084883\n",
      "Stage: train, iter: 38020, lr: 2.397e-07, loss 0.070669\n",
      "Stage: train, iter: 38040, lr: 2.349e-07, loss 0.172430\n",
      "Stage: train, iter: 38060, lr: 2.302e-07, loss 0.116417\n",
      "Stage: train, iter: 38080, lr: 2.255e-07, loss 0.059759\n",
      "Stage: train, iter: 38100, lr: 2.208e-07, loss 0.056540\n",
      "Stage: train, iter: 38120, lr: 2.162e-07, loss 0.100586\n",
      "Stage: train, iter: 38140, lr: 2.117e-07, loss 0.070746\n",
      "Stage: train, iter: 38160, lr: 2.072e-07, loss 0.081816\n",
      "Stage: train, iter: 38180, lr: 2.027e-07, loss 0.111930\n",
      "Stage: train, iter: 38200, lr: 1.983e-07, loss 0.067409\n",
      "Stage: train, iter: 38220, lr: 1.940e-07, loss 0.082662\n",
      "Stage: train, iter: 38240, lr: 1.897e-07, loss 0.090913\n",
      "Stage: train, iter: 38260, lr: 1.854e-07, loss 0.063968\n",
      "Stage: train, iter: 38280, lr: 1.812e-07, loss 0.064911\n",
      "Stage: train, iter: 38300, lr: 1.770e-07, loss 0.113965\n",
      "Stage: train, iter: 38320, lr: 1.729e-07, loss 0.091306\n",
      "Stage: train, iter: 38340, lr: 1.688e-07, loss 0.087064\n",
      "Stage: train, iter: 38360, lr: 1.648e-07, loss 0.102632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 38380, lr: 1.608e-07, loss 0.066558\n",
      "Stage: train, iter: 38400, lr: 1.569e-07, loss 0.088997\n",
      "Stage: train, iter: 38420, lr: 1.530e-07, loss 0.057643\n",
      "Stage: train, iter: 38440, lr: 1.492e-07, loss 0.103245\n",
      "Stage: train, iter: 38460, lr: 1.454e-07, loss 0.108171\n",
      "Stage: train, iter: 38480, lr: 1.417e-07, loss 0.088711\n",
      "Stage: train, iter: 38500, lr: 1.380e-07, loss 0.100423\n",
      "Stage: train, iter: 38520, lr: 1.343e-07, loss 0.086419\n",
      "Stage: train, iter: 38540, lr: 1.307e-07, loss 0.083584\n",
      "Stage: train, iter: 38560, lr: 1.272e-07, loss 0.095719\n",
      "Stage: train, iter: 38580, lr: 1.237e-07, loss 0.085513\n",
      "Stage: train, iter: 38600, lr: 1.203e-07, loss 0.074357\n",
      "Stage: train, iter: 38620, lr: 1.169e-07, loss 0.062617\n",
      "Stage: train, iter: 38640, lr: 1.135e-07, loss 0.048975\n",
      "Stage: train, iter: 38660, lr: 1.102e-07, loss 0.063540\n",
      "Stage: train, iter: 38680, lr: 1.069e-07, loss 0.053266\n",
      "Stage: train, iter: 38700, lr: 1.037e-07, loss 0.071798\n",
      "Stage: train, iter: 38720, lr: 1.006e-07, loss 0.112227\n",
      "Stage: train, iter: 38740, lr: 9.747e-08, loss 0.058010\n",
      "Stage: train, iter: 38760, lr: 9.440e-08, loss 0.049545\n",
      "Stage: train, iter: 38780, lr: 9.139e-08, loss 0.049798\n",
      "Stage: train, iter: 38800, lr: 8.843e-08, loss 0.063666\n",
      "Stage: train, iter: 38820, lr: 8.551e-08, loss 0.095348\n",
      "Stage: train, iter: 38840, lr: 8.264e-08, loss 0.096615\n",
      "Stage: train, iter: 38860, lr: 7.982e-08, loss 0.083635\n",
      "Stage: train, iter: 38880, lr: 7.705e-08, loss 0.073056\n",
      "Stage: train, iter: 38900, lr: 7.433e-08, loss 0.080515\n",
      "Stage: train, iter: 38920, lr: 7.165e-08, loss 0.061583\n",
      "Stage: train, iter: 38940, lr: 6.903e-08, loss 0.100083\n",
      "Stage: train, iter: 38960, lr: 6.645e-08, loss 0.071687\n",
      "Stage: train, iter: 38980, lr: 6.392e-08, loss 0.067690\n",
      "Stage: train, iter: 39000, lr: 6.144e-08, loss 0.089892\n",
      "Stage: train, iter: 39020, lr: 5.901e-08, loss 0.104725\n",
      "Stage: train, iter: 39040, lr: 5.663e-08, loss 0.078010\n",
      "Stage: train, iter: 39060, lr: 5.430e-08, loss 0.074841\n",
      "Stage: train, iter: 39080, lr: 5.201e-08, loss 0.102212\n",
      "Stage: train, iter: 39100, lr: 4.978e-08, loss 0.071249\n",
      "Stage: train, iter: 39120, lr: 4.759e-08, loss 0.077564\n",
      "Stage: train, iter: 39140, lr: 4.545e-08, loss 0.071900\n",
      "Stage: train, iter: 39160, lr: 4.336e-08, loss 0.062416\n",
      "Stage: train, iter: 39180, lr: 4.132e-08, loss 0.070170\n",
      "Stage: train, iter: 39200, lr: 3.933e-08, loss 0.067210\n",
      "Stage: train, iter: 39220, lr: 3.739e-08, loss 0.071190\n",
      "Stage: train, iter: 39240, lr: 3.550e-08, loss 0.070225\n",
      "Stage: train, iter: 39260, lr: 3.365e-08, loss 0.043863\n",
      "Stage: train, iter: 39280, lr: 3.186e-08, loss 0.113241\n",
      "Stage: train, iter: 39300, lr: 3.011e-08, loss 0.066158\n",
      "Stage: train, iter: 39320, lr: 2.842e-08, loss 0.094816\n",
      "Stage: train, iter: 39340, lr: 2.677e-08, loss 0.100452\n",
      "Stage: train, iter: 39360, lr: 2.517e-08, loss 0.091069\n",
      "Stage: train, iter: 39380, lr: 2.362e-08, loss 0.039810\n",
      "Stage: train, iter: 39400, lr: 2.212e-08, loss 0.094473\n",
      "Stage: train, iter: 39420, lr: 2.067e-08, loss 0.064570\n",
      "Stage: train, iter: 39440, lr: 1.926e-08, loss 0.080009\n",
      "Stage: train, iter: 39460, lr: 1.791e-08, loss 0.096733\n",
      "Stage: train, iter: 39480, lr: 1.661e-08, loss 0.091839\n",
      "Stage: train, iter: 39500, lr: 1.535e-08, loss 0.086073\n",
      "Stage: train, iter: 39520, lr: 1.415e-08, loss 0.101581\n",
      "Stage: train, iter: 39540, lr: 1.299e-08, loss 0.080391\n",
      "Stage: train, iter: 39560, lr: 1.188e-08, loss 0.079942\n",
      "Stage: train, iter: 39580, lr: 1.083e-08, loss 0.107252\n",
      "Stage: train, iter: 39600, lr: 9.818e-09, loss 0.087084\n",
      "Stage: train, iter: 39620, lr: 8.859e-09, loss 0.087946\n",
      "Stage: train, iter: 39640, lr: 7.949e-09, loss 0.061037\n",
      "Stage: train, iter: 39660, lr: 7.088e-09, loss 0.068468\n",
      "Stage: train, iter: 39680, lr: 6.276e-09, loss 0.060406\n",
      "Stage: train, iter: 39700, lr: 5.514e-09, loss 0.070602\n",
      "Stage: train, iter: 39720, lr: 4.801e-09, loss 0.098953\n",
      "Stage: train, iter: 39740, lr: 4.138e-09, loss 0.071934\n",
      "Stage: train, iter: 39760, lr: 3.523e-09, loss 0.091269\n",
      "Stage: train, iter: 39780, lr: 2.958e-09, loss 0.063713\n",
      "Stage: train, iter: 39800, lr: 2.443e-09, loss 0.139963\n",
      "Stage: train, iter: 39820, lr: 1.977e-09, loss 0.102200\n",
      "Stage: train, iter: 39840, lr: 1.560e-09, loss 0.070879\n",
      "Stage: train, iter: 39860, lr: 1.192e-09, loss 0.090873\n",
      "Stage: train, iter: 39880, lr: 8.736e-10, loss 0.102721\n",
      "Stage: train, iter: 39900, lr: 6.046e-10, loss 0.103500\n",
      "Stage: train, iter: 39920, lr: 3.850e-10, loss 0.065353\n",
      "Stage: train, iter: 39940, lr: 2.147e-10, loss 0.038638\n",
      "Stage: train, iter: 39960, lr: 9.383e-11, loss 0.084602\n",
      "Stage: train, iter: 39980, lr: 2.227e-11, loss 0.061555\n",
      "Stage: train, iter: 40000, lr: 1.000e-05, loss 0.034223\n",
      "Stage: train, iter: 40020, lr: 1.000e-05, loss 0.121332\n",
      "Stage: train, iter: 40040, lr: 1.000e-05, loss 0.054139\n",
      "Stage: train, iter: 40060, lr: 1.000e-05, loss 0.072546\n",
      "Stage: train, iter: 40080, lr: 1.000e-05, loss 0.072644\n",
      "Stage: train, iter: 40100, lr: 9.999e-06, loss 0.099908\n",
      "Stage: train, iter: 40120, lr: 9.999e-06, loss 0.106749\n",
      "Stage: train, iter: 40140, lr: 9.999e-06, loss 0.068741\n",
      "Stage: train, iter: 40160, lr: 9.998e-06, loss 0.083230\n",
      "Stage: train, iter: 40180, lr: 9.998e-06, loss 0.100237\n",
      "Stage: train, iter: 40200, lr: 9.998e-06, loss 0.081430\n",
      "Stage: train, iter: 40220, lr: 9.997e-06, loss 0.088624\n",
      "Stage: train, iter: 40240, lr: 9.996e-06, loss 0.082504\n",
      "Stage: train, iter: 40260, lr: 9.996e-06, loss 0.156255\n",
      "Stage: train, iter: 40280, lr: 9.995e-06, loss 0.080299\n",
      "Stage: train, iter: 40300, lr: 9.994e-06, loss 0.072944\n",
      "Stage: train, iter: 40320, lr: 9.994e-06, loss 0.076758\n",
      "Stage: train, iter: 40340, lr: 9.993e-06, loss 0.082047\n",
      "Stage: train, iter: 40360, lr: 9.992e-06, loss 0.092682\n",
      "Stage: train, iter: 40380, lr: 9.991e-06, loss 0.071215\n",
      "Stage: train, iter: 40400, lr: 9.990e-06, loss 0.063489\n",
      "Stage: train, iter: 40420, lr: 9.989e-06, loss 0.094801\n",
      "Stage: train, iter: 40440, lr: 9.988e-06, loss 0.092846\n",
      "Stage: train, iter: 40460, lr: 9.987e-06, loss 0.094409\n",
      "Stage: train, iter: 40480, lr: 9.986e-06, loss 0.080019\n",
      "Stage: train, iter: 40500, lr: 9.985e-06, loss 0.098372\n",
      "Stage: train, iter: 40520, lr: 9.983e-06, loss 0.057829\n",
      "Stage: train, iter: 40540, lr: 9.982e-06, loss 0.087932\n",
      "Stage: train, iter: 40560, lr: 9.981e-06, loss 0.046366\n",
      "Stage: train, iter: 40580, lr: 9.979e-06, loss 0.041257\n",
      "Stage: train, iter: 40600, lr: 9.978e-06, loss 0.144629\n",
      "Stage: train, iter: 40620, lr: 9.976e-06, loss 0.096203\n",
      "Stage: train, iter: 40640, lr: 9.975e-06, loss 0.108696\n",
      "Stage: train, iter: 40660, lr: 9.973e-06, loss 0.074665\n",
      "Stage: train, iter: 40680, lr: 9.972e-06, loss 0.088480\n",
      "Stage: train, iter: 40700, lr: 9.970e-06, loss 0.057961\n",
      "Stage: train, iter: 40720, lr: 9.968e-06, loss 0.091087\n",
      "Stage: train, iter: 40740, lr: 9.966e-06, loss 0.104793\n",
      "Stage: train, iter: 40760, lr: 9.964e-06, loss 0.070722\n",
      "Stage: train, iter: 40780, lr: 9.963e-06, loss 0.057375\n",
      "Stage: train, iter: 40800, lr: 9.961e-06, loss 0.086442\n",
      "Stage: train, iter: 40820, lr: 9.959e-06, loss 0.078371\n",
      "Stage: train, iter: 40840, lr: 9.957e-06, loss 0.073779\n",
      "Stage: train, iter: 40860, lr: 9.954e-06, loss 0.109710\n",
      "Stage: train, iter: 40880, lr: 9.952e-06, loss 0.089045\n",
      "Stage: train, iter: 40900, lr: 9.950e-06, loss 0.067401\n",
      "Stage: train, iter: 40920, lr: 9.948e-06, loss 0.181190\n",
      "Stage: train, iter: 40940, lr: 9.946e-06, loss 0.046102\n",
      "Stage: train, iter: 40960, lr: 9.943e-06, loss 0.073608\n",
      "Stage: train, iter: 40980, lr: 9.941e-06, loss 0.110815\n",
      "Stage: train, iter: 41000, lr: 9.938e-06, loss 0.076206\n",
      "Stage: train, iter: 41020, lr: 9.936e-06, loss 0.089086\n",
      "Stage: train, iter: 41040, lr: 9.933e-06, loss 0.099969\n",
      "Stage: train, iter: 41060, lr: 9.931e-06, loss 0.098690\n",
      "Stage: train, iter: 41080, lr: 9.928e-06, loss 0.066382\n",
      "Stage: train, iter: 41100, lr: 9.926e-06, loss 0.075788\n",
      "Stage: train, iter: 41120, lr: 9.923e-06, loss 0.056505\n",
      "Stage: train, iter: 41140, lr: 9.920e-06, loss 0.076199\n",
      "Stage: train, iter: 41160, lr: 9.917e-06, loss 0.068403\n",
      "Stage: train, iter: 41180, lr: 9.914e-06, loss 0.066896\n",
      "Stage: train, iter: 41200, lr: 9.911e-06, loss 0.118958\n",
      "Stage: train, iter: 41220, lr: 9.908e-06, loss 0.072669\n",
      "Stage: train, iter: 41240, lr: 9.905e-06, loss 0.057198\n",
      "Stage: train, iter: 41260, lr: 9.902e-06, loss 0.091419\n",
      "Stage: train, iter: 41280, lr: 9.899e-06, loss 0.092585\n",
      "Stage: train, iter: 41300, lr: 9.896e-06, loss 0.069222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 41320, lr: 9.893e-06, loss 0.096281\n",
      "Stage: train, iter: 41340, lr: 9.890e-06, loss 0.080049\n",
      "Stage: train, iter: 41360, lr: 9.886e-06, loss 0.087843\n",
      "Stage: train, iter: 41380, lr: 9.883e-06, loss 0.066098\n",
      "Stage: train, iter: 41400, lr: 9.880e-06, loss 0.070604\n",
      "Stage: train, iter: 41420, lr: 9.876e-06, loss 0.089234\n",
      "Stage: train, iter: 41440, lr: 9.873e-06, loss 0.116478\n",
      "Stage: train, iter: 41460, lr: 9.869e-06, loss 0.067477\n",
      "Stage: train, iter: 41480, lr: 9.865e-06, loss 0.081785\n",
      "Stage: train, iter: 41500, lr: 9.862e-06, loss 0.062500\n",
      "Stage: train, iter: 41520, lr: 9.858e-06, loss 0.057075\n",
      "Stage: train, iter: 41540, lr: 9.854e-06, loss 0.116463\n",
      "Stage: train, iter: 41560, lr: 9.851e-06, loss 0.081795\n",
      "Stage: train, iter: 41580, lr: 9.847e-06, loss 0.063664\n",
      "Stage: train, iter: 41600, lr: 9.843e-06, loss 0.070483\n",
      "Stage: train, iter: 41620, lr: 9.839e-06, loss 0.061697\n",
      "Stage: train, iter: 41640, lr: 9.835e-06, loss 0.052399\n",
      "Stage: train, iter: 41660, lr: 9.831e-06, loss 0.074430\n",
      "Stage: train, iter: 41680, lr: 9.827e-06, loss 0.055482\n",
      "Stage: train, iter: 41700, lr: 9.823e-06, loss 0.055010\n",
      "Stage: train, iter: 41720, lr: 9.819e-06, loss 0.064940\n",
      "Stage: train, iter: 41740, lr: 9.814e-06, loss 0.095176\n",
      "Stage: train, iter: 41760, lr: 9.810e-06, loss 0.109888\n",
      "Stage: train, iter: 41780, lr: 9.806e-06, loss 0.097775\n",
      "Stage: train, iter: 41800, lr: 9.801e-06, loss 0.086732\n",
      "Stage: train, iter: 41820, lr: 9.797e-06, loss 0.089746\n",
      "Stage: train, iter: 41840, lr: 9.793e-06, loss 0.067913\n",
      "Stage: train, iter: 41860, lr: 9.788e-06, loss 0.090716\n",
      "Stage: train, iter: 41880, lr: 9.784e-06, loss 0.079040\n",
      "Stage: train, iter: 41900, lr: 9.779e-06, loss 0.109953\n",
      "Stage: train, iter: 41920, lr: 9.774e-06, loss 0.064178\n",
      "Stage: train, iter: 41940, lr: 9.770e-06, loss 0.107678\n",
      "Stage: train, iter: 41960, lr: 9.765e-06, loss 0.064531\n",
      "Stage: train, iter: 41980, lr: 9.760e-06, loss 0.090813\n",
      "Stage: train, iter: 42000, lr: 9.755e-06, loss 0.071109\n",
      "Stage: train, iter: 42020, lr: 9.750e-06, loss 0.097708\n",
      "Stage: train, iter: 42040, lr: 9.745e-06, loss 0.077137\n",
      "Stage: train, iter: 42060, lr: 9.740e-06, loss 0.084035\n",
      "Stage: train, iter: 42080, lr: 9.735e-06, loss 0.093669\n",
      "Stage: train, iter: 42100, lr: 9.730e-06, loss 0.055992\n",
      "Stage: train, iter: 42120, lr: 9.725e-06, loss 0.112864\n",
      "Stage: train, iter: 42140, lr: 9.720e-06, loss 0.069092\n",
      "Stage: train, iter: 42160, lr: 9.715e-06, loss 0.081242\n",
      "Stage: train, iter: 42180, lr: 9.710e-06, loss 0.059846\n",
      "Stage: train, iter: 42200, lr: 9.704e-06, loss 0.072434\n",
      "Stage: train, iter: 42220, lr: 9.699e-06, loss 0.073024\n",
      "Stage: train, iter: 42240, lr: 9.694e-06, loss 0.065983\n",
      "Stage: train, iter: 42260, lr: 9.688e-06, loss 0.063151\n",
      "Stage: train, iter: 42280, lr: 9.683e-06, loss 0.099360\n",
      "Stage: train, iter: 42300, lr: 9.677e-06, loss 0.052300\n",
      "Stage: train, iter: 42320, lr: 9.672e-06, loss 0.081581\n",
      "Stage: train, iter: 42340, lr: 9.666e-06, loss 0.062474\n",
      "Stage: train, iter: 42360, lr: 9.660e-06, loss 0.073898\n",
      "Stage: train, iter: 42380, lr: 9.655e-06, loss 0.077136\n",
      "Stage: train, iter: 42400, lr: 9.649e-06, loss 0.123331\n",
      "Stage: train, iter: 42420, lr: 9.643e-06, loss 0.087391\n",
      "Stage: train, iter: 42440, lr: 9.637e-06, loss 0.062127\n",
      "Stage: train, iter: 42460, lr: 9.631e-06, loss 0.083468\n",
      "Stage: train, iter: 42480, lr: 9.625e-06, loss 0.075130\n",
      "Stage: train, iter: 42500, lr: 9.619e-06, loss 0.073334\n",
      "Stage: train, iter: 42520, lr: 9.613e-06, loss 0.117623\n",
      "Stage: train, iter: 42540, lr: 9.607e-06, loss 0.072165\n",
      "Stage: train, iter: 42560, lr: 9.601e-06, loss 0.076344\n",
      "Stage: train, iter: 42580, lr: 9.595e-06, loss 0.091620\n",
      "Stage: train, iter: 42600, lr: 9.589e-06, loss 0.060905\n",
      "Stage: train, iter: 42620, lr: 9.582e-06, loss 0.074394\n",
      "Stage: train, iter: 42640, lr: 9.576e-06, loss 0.108221\n",
      "Stage: train, iter: 42660, lr: 9.570e-06, loss 0.109222\n",
      "Stage: train, iter: 42680, lr: 9.563e-06, loss 0.087827\n",
      "Stage: train, iter: 42700, lr: 9.557e-06, loss 0.120908\n",
      "Stage: train, iter: 42720, lr: 9.550e-06, loss 0.062986\n",
      "Stage: train, iter: 42740, lr: 9.544e-06, loss 0.102051\n",
      "Stage: train, iter: 42760, lr: 9.537e-06, loss 0.073577\n",
      "Stage: train, iter: 42780, lr: 9.531e-06, loss 0.063491\n",
      "Stage: train, iter: 42800, lr: 9.524e-06, loss 0.053113\n",
      "Stage: train, iter: 42820, lr: 9.517e-06, loss 0.099352\n",
      "Stage: train, iter: 42840, lr: 9.511e-06, loss 0.054273\n",
      "Stage: train, iter: 42860, lr: 9.504e-06, loss 0.102541\n",
      "Stage: train, iter: 42880, lr: 9.497e-06, loss 0.072956\n",
      "Stage: train, iter: 42900, lr: 9.490e-06, loss 0.065473\n",
      "Stage: train, iter: 42920, lr: 9.483e-06, loss 0.039564\n",
      "Stage: train, iter: 42940, lr: 9.476e-06, loss 0.079391\n",
      "Stage: train, iter: 42960, lr: 9.469e-06, loss 0.077405\n",
      "Stage: train, iter: 42980, lr: 9.462e-06, loss 0.084249\n",
      "Stage: train, iter: 43000, lr: 9.455e-06, loss 0.083822\n",
      "Stage: train, iter: 43020, lr: 9.448e-06, loss 0.101742\n",
      "Stage: train, iter: 43040, lr: 9.441e-06, loss 0.065761\n",
      "Stage: train, iter: 43060, lr: 9.433e-06, loss 0.065813\n",
      "Stage: train, iter: 43080, lr: 9.426e-06, loss 0.088152\n",
      "Stage: train, iter: 43100, lr: 9.419e-06, loss 0.062012\n",
      "Stage: train, iter: 43120, lr: 9.411e-06, loss 0.082528\n",
      "Stage: train, iter: 43140, lr: 9.404e-06, loss 0.085345\n",
      "Stage: train, iter: 43160, lr: 9.397e-06, loss 0.109327\n",
      "Stage: train, iter: 43180, lr: 9.389e-06, loss 0.076693\n",
      "Stage: train, iter: 43200, lr: 9.381e-06, loss 0.107081\n",
      "Stage: train, iter: 43220, lr: 9.374e-06, loss 0.102395\n",
      "Stage: train, iter: 43240, lr: 9.366e-06, loss 0.050854\n",
      "Stage: train, iter: 43260, lr: 9.359e-06, loss 0.054745\n",
      "Stage: train, iter: 43280, lr: 9.351e-06, loss 0.109474\n",
      "Stage: train, iter: 43300, lr: 9.343e-06, loss 0.059214\n",
      "Stage: train, iter: 43320, lr: 9.335e-06, loss 0.108769\n",
      "Stage: train, iter: 43340, lr: 9.327e-06, loss 0.038735\n",
      "Stage: train, iter: 43360, lr: 9.320e-06, loss 0.095473\n",
      "Stage: train, iter: 43380, lr: 9.312e-06, loss 0.064460\n",
      "Stage: train, iter: 43400, lr: 9.304e-06, loss 0.082351\n",
      "Stage: train, iter: 43420, lr: 9.296e-06, loss 0.097373\n",
      "Stage: train, iter: 43440, lr: 9.288e-06, loss 0.062225\n",
      "Stage: train, iter: 43460, lr: 9.279e-06, loss 0.087694\n",
      "Stage: train, iter: 43480, lr: 9.271e-06, loss 0.070029\n",
      "Stage: train, iter: 43500, lr: 9.263e-06, loss 0.111994\n",
      "Stage: train, iter: 43520, lr: 9.255e-06, loss 0.088277\n",
      "Stage: train, iter: 43540, lr: 9.247e-06, loss 0.080834\n",
      "Stage: train, iter: 43560, lr: 9.238e-06, loss 0.066684\n",
      "Stage: train, iter: 43580, lr: 9.230e-06, loss 0.091916\n",
      "Stage: train, iter: 43600, lr: 9.222e-06, loss 0.095622\n",
      "Stage: train, iter: 43620, lr: 9.213e-06, loss 0.041105\n",
      "Stage: train, iter: 43640, lr: 9.205e-06, loss 0.082551\n",
      "Stage: train, iter: 43660, lr: 9.196e-06, loss 0.088869\n",
      "Stage: train, iter: 43680, lr: 9.188e-06, loss 0.076883\n",
      "Stage: train, iter: 43700, lr: 9.179e-06, loss 0.065451\n",
      "Stage: train, iter: 43720, lr: 9.170e-06, loss 0.089044\n",
      "Stage: train, iter: 43740, lr: 9.162e-06, loss 0.059670\n",
      "Stage: train, iter: 43760, lr: 9.153e-06, loss 0.090911\n",
      "Stage: train, iter: 43780, lr: 9.144e-06, loss 0.064637\n",
      "Stage: train, iter: 43800, lr: 9.135e-06, loss 0.103305\n",
      "Stage: train, iter: 43820, lr: 9.126e-06, loss 0.093027\n",
      "Stage: train, iter: 43840, lr: 9.118e-06, loss 0.107812\n",
      "Stage: train, iter: 43860, lr: 9.109e-06, loss 0.116356\n",
      "Stage: train, iter: 43880, lr: 9.100e-06, loss 0.092728\n",
      "Stage: train, iter: 43900, lr: 9.091e-06, loss 0.074107\n",
      "Stage: train, iter: 43920, lr: 9.082e-06, loss 0.100690\n",
      "Stage: train, iter: 43940, lr: 9.073e-06, loss 0.116734\n",
      "Stage: train, iter: 43960, lr: 9.063e-06, loss 0.097927\n",
      "Stage: train, iter: 43980, lr: 9.054e-06, loss 0.033901\n",
      "Stage: train, iter: 44000, lr: 9.045e-06, loss 0.083963\n",
      "Stage: train, iter: 44020, lr: 9.036e-06, loss 0.028127\n",
      "Stage: train, iter: 44040, lr: 9.026e-06, loss 0.059979\n",
      "Stage: train, iter: 44060, lr: 9.017e-06, loss 0.081776\n",
      "Stage: train, iter: 44080, lr: 9.008e-06, loss 0.058835\n",
      "Stage: train, iter: 44100, lr: 8.998e-06, loss 0.081862\n",
      "Stage: train, iter: 44120, lr: 8.989e-06, loss 0.063156\n",
      "Stage: train, iter: 44140, lr: 8.979e-06, loss 0.062149\n",
      "Stage: train, iter: 44160, lr: 8.970e-06, loss 0.097275\n",
      "Stage: train, iter: 44180, lr: 8.960e-06, loss 0.086946\n",
      "Stage: train, iter: 44200, lr: 8.951e-06, loss 0.116192\n",
      "Stage: train, iter: 44220, lr: 8.941e-06, loss 0.089364\n",
      "Stage: train, iter: 44240, lr: 8.931e-06, loss 0.108850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 44260, lr: 8.922e-06, loss 0.092934\n",
      "Stage: train, iter: 44280, lr: 8.912e-06, loss 0.084873\n",
      "Stage: train, iter: 44300, lr: 8.902e-06, loss 0.088477\n",
      "Stage: train, iter: 44320, lr: 8.892e-06, loss 0.086171\n",
      "Stage: train, iter: 44340, lr: 8.882e-06, loss 0.116340\n",
      "Stage: train, iter: 44360, lr: 8.872e-06, loss 0.072691\n",
      "Stage: train, iter: 44380, lr: 8.862e-06, loss 0.088272\n",
      "Stage: train, iter: 44400, lr: 8.852e-06, loss 0.089024\n",
      "Stage: train, iter: 44420, lr: 8.842e-06, loss 0.094937\n",
      "Stage: train, iter: 44440, lr: 8.832e-06, loss 0.115114\n",
      "Stage: train, iter: 44460, lr: 8.822e-06, loss 0.137583\n",
      "Stage: train, iter: 44480, lr: 8.812e-06, loss 0.073535\n",
      "Stage: train, iter: 44500, lr: 8.802e-06, loss 0.070904\n",
      "Stage: train, iter: 44520, lr: 8.792e-06, loss 0.089174\n",
      "Stage: train, iter: 44540, lr: 8.781e-06, loss 0.076213\n",
      "Stage: train, iter: 44560, lr: 8.771e-06, loss 0.076885\n",
      "Stage: train, iter: 44580, lr: 8.761e-06, loss 0.099872\n",
      "Stage: train, iter: 44600, lr: 8.750e-06, loss 0.088424\n",
      "Stage: train, iter: 44620, lr: 8.740e-06, loss 0.058067\n",
      "Stage: train, iter: 44640, lr: 8.730e-06, loss 0.076832\n",
      "Stage: train, iter: 44660, lr: 8.719e-06, loss 0.086837\n",
      "Stage: train, iter: 44680, lr: 8.709e-06, loss 0.094889\n",
      "Stage: train, iter: 44700, lr: 8.698e-06, loss 0.069308\n",
      "Stage: train, iter: 44720, lr: 8.687e-06, loss 0.088993\n",
      "Stage: train, iter: 44740, lr: 8.677e-06, loss 0.084417\n",
      "Stage: train, iter: 44760, lr: 8.666e-06, loss 0.078733\n",
      "Stage: train, iter: 44780, lr: 8.655e-06, loss 0.077130\n",
      "Stage: train, iter: 44800, lr: 8.645e-06, loss 0.081168\n",
      "Stage: train, iter: 44820, lr: 8.634e-06, loss 0.070882\n",
      "Stage: train, iter: 44840, lr: 8.623e-06, loss 0.082957\n",
      "Stage: train, iter: 44860, lr: 8.612e-06, loss 0.077283\n",
      "Stage: train, iter: 44880, lr: 8.601e-06, loss 0.081471\n",
      "Stage: train, iter: 44900, lr: 8.590e-06, loss 0.076142\n",
      "Stage: train, iter: 44920, lr: 8.580e-06, loss 0.056209\n",
      "Stage: train, iter: 44940, lr: 8.569e-06, loss 0.087550\n",
      "Stage: train, iter: 44960, lr: 8.558e-06, loss 0.052378\n",
      "Stage: train, iter: 44980, lr: 8.546e-06, loss 0.097022\n",
      "Stage: train, iter: 45000, lr: 8.535e-06, loss 0.067367\n",
      "Stage: train, iter: 45020, lr: 8.524e-06, loss 0.086364\n",
      "Stage: train, iter: 45040, lr: 8.513e-06, loss 0.079367\n",
      "Stage: train, iter: 45060, lr: 8.502e-06, loss 0.070597\n",
      "Stage: train, iter: 45080, lr: 8.491e-06, loss 0.096683\n",
      "Stage: train, iter: 45100, lr: 8.479e-06, loss 0.079804\n",
      "Stage: train, iter: 45120, lr: 8.468e-06, loss 0.086075\n",
      "Stage: train, iter: 45140, lr: 8.457e-06, loss 0.100889\n",
      "Stage: train, iter: 45160, lr: 8.445e-06, loss 0.078731\n",
      "Stage: train, iter: 45180, lr: 8.434e-06, loss 0.103784\n",
      "Stage: train, iter: 45200, lr: 8.423e-06, loss 0.053653\n",
      "Stage: train, iter: 45220, lr: 8.411e-06, loss 0.071810\n",
      "Stage: train, iter: 45240, lr: 8.400e-06, loss 0.089614\n",
      "Stage: train, iter: 45260, lr: 8.388e-06, loss 0.069690\n",
      "Stage: train, iter: 45280, lr: 8.377e-06, loss 0.087254\n",
      "Stage: train, iter: 45300, lr: 8.365e-06, loss 0.069403\n",
      "Stage: train, iter: 45320, lr: 8.353e-06, loss 0.072531\n",
      "Stage: train, iter: 45340, lr: 8.342e-06, loss 0.099512\n",
      "Stage: train, iter: 45360, lr: 8.330e-06, loss 0.060527\n",
      "Stage: train, iter: 45380, lr: 8.318e-06, loss 0.095731\n",
      "Stage: train, iter: 45400, lr: 8.306e-06, loss 0.051533\n",
      "Stage: train, iter: 45420, lr: 8.295e-06, loss 0.099707\n",
      "Stage: train, iter: 45440, lr: 8.283e-06, loss 0.079257\n",
      "Stage: train, iter: 45460, lr: 8.271e-06, loss 0.089855\n",
      "Stage: train, iter: 45480, lr: 8.259e-06, loss 0.067447\n",
      "Stage: train, iter: 45500, lr: 8.247e-06, loss 0.074471\n",
      "Stage: train, iter: 45520, lr: 8.235e-06, loss 0.055994\n",
      "Stage: train, iter: 45540, lr: 8.223e-06, loss 0.081203\n",
      "Stage: train, iter: 45560, lr: 8.211e-06, loss 0.091691\n",
      "Stage: train, iter: 45580, lr: 8.199e-06, loss 0.079773\n",
      "Stage: train, iter: 45600, lr: 8.187e-06, loss 0.065668\n",
      "Stage: train, iter: 45620, lr: 8.175e-06, loss 0.067249\n",
      "Stage: train, iter: 45640, lr: 8.163e-06, loss 0.088643\n",
      "Stage: train, iter: 45660, lr: 8.150e-06, loss 0.112952\n",
      "Stage: train, iter: 45680, lr: 8.138e-06, loss 0.090992\n",
      "Stage: train, iter: 45700, lr: 8.126e-06, loss 0.089970\n",
      "Stage: train, iter: 45720, lr: 8.114e-06, loss 0.094188\n",
      "Stage: train, iter: 45740, lr: 8.101e-06, loss 0.075494\n",
      "Stage: train, iter: 45760, lr: 8.089e-06, loss 0.079456\n",
      "Stage: train, iter: 45780, lr: 8.077e-06, loss 0.066840\n",
      "Stage: train, iter: 45800, lr: 8.064e-06, loss 0.085588\n",
      "Stage: train, iter: 45820, lr: 8.052e-06, loss 0.056842\n",
      "Stage: train, iter: 45840, lr: 8.039e-06, loss 0.070995\n",
      "Stage: train, iter: 45860, lr: 8.027e-06, loss 0.094824\n",
      "Stage: train, iter: 45880, lr: 8.014e-06, loss 0.100780\n",
      "Stage: train, iter: 45900, lr: 8.002e-06, loss 0.054638\n",
      "Stage: train, iter: 45920, lr: 7.989e-06, loss 0.088592\n",
      "Stage: train, iter: 45940, lr: 7.977e-06, loss 0.096024\n",
      "Stage: train, iter: 45960, lr: 7.964e-06, loss 0.072705\n",
      "Stage: train, iter: 45980, lr: 7.951e-06, loss 0.063250\n",
      "Stage: train, iter: 46000, lr: 7.939e-06, loss 0.058944\n",
      "Stage: train, iter: 46020, lr: 7.926e-06, loss 0.060465\n",
      "Stage: train, iter: 46040, lr: 7.913e-06, loss 0.066508\n",
      "Stage: train, iter: 46060, lr: 7.900e-06, loss 0.102369\n",
      "Stage: train, iter: 46080, lr: 7.888e-06, loss 0.081644\n",
      "Stage: train, iter: 46100, lr: 7.875e-06, loss 0.111963\n",
      "Stage: train, iter: 46120, lr: 7.862e-06, loss 0.046511\n",
      "Stage: train, iter: 46140, lr: 7.849e-06, loss 0.064173\n",
      "Stage: train, iter: 46160, lr: 7.836e-06, loss 0.079701\n",
      "Stage: train, iter: 46180, lr: 7.823e-06, loss 0.106112\n",
      "Stage: train, iter: 46200, lr: 7.810e-06, loss 0.075393\n",
      "Stage: train, iter: 46220, lr: 7.797e-06, loss 0.078072\n",
      "Stage: train, iter: 46240, lr: 7.784e-06, loss 0.065693\n",
      "Stage: train, iter: 46260, lr: 7.771e-06, loss 0.065521\n",
      "Stage: train, iter: 46280, lr: 7.758e-06, loss 0.108068\n",
      "Stage: train, iter: 46300, lr: 7.745e-06, loss 0.076404\n",
      "Stage: train, iter: 46320, lr: 7.732e-06, loss 0.062153\n",
      "Stage: train, iter: 46340, lr: 7.719e-06, loss 0.100032\n",
      "Stage: train, iter: 46360, lr: 7.705e-06, loss 0.078558\n",
      "Stage: train, iter: 46380, lr: 7.692e-06, loss 0.075258\n",
      "Stage: train, iter: 46400, lr: 7.679e-06, loss 0.108536\n",
      "Stage: train, iter: 46420, lr: 7.666e-06, loss 0.082844\n",
      "Stage: train, iter: 46440, lr: 7.652e-06, loss 0.068801\n",
      "Stage: train, iter: 46460, lr: 7.639e-06, loss 0.098525\n",
      "Stage: train, iter: 46480, lr: 7.626e-06, loss 0.095969\n",
      "Stage: train, iter: 46500, lr: 7.612e-06, loss 0.094771\n",
      "Stage: train, iter: 46520, lr: 7.599e-06, loss 0.080707\n",
      "Stage: train, iter: 46540, lr: 7.585e-06, loss 0.075034\n",
      "Stage: train, iter: 46560, lr: 7.572e-06, loss 0.058441\n",
      "Stage: train, iter: 46580, lr: 7.558e-06, loss 0.078118\n",
      "Stage: train, iter: 46600, lr: 7.545e-06, loss 0.060832\n",
      "Stage: train, iter: 46620, lr: 7.531e-06, loss 0.078843\n",
      "Stage: train, iter: 46640, lr: 7.518e-06, loss 0.085891\n",
      "Stage: train, iter: 46660, lr: 7.504e-06, loss 0.139053\n",
      "Stage: train, iter: 46680, lr: 7.491e-06, loss 0.040641\n",
      "Stage: train, iter: 46700, lr: 7.477e-06, loss 0.130040\n",
      "Stage: train, iter: 46720, lr: 7.463e-06, loss 0.089982\n",
      "Stage: train, iter: 46740, lr: 7.450e-06, loss 0.102178\n",
      "Stage: train, iter: 46760, lr: 7.436e-06, loss 0.053261\n",
      "Stage: train, iter: 46780, lr: 7.422e-06, loss 0.071491\n",
      "Stage: train, iter: 46800, lr: 7.409e-06, loss 0.066798\n",
      "Stage: train, iter: 46820, lr: 7.395e-06, loss 0.068906\n",
      "Stage: train, iter: 46840, lr: 7.381e-06, loss 0.065136\n",
      "Stage: train, iter: 46860, lr: 7.367e-06, loss 0.064962\n",
      "Stage: train, iter: 46880, lr: 7.353e-06, loss 0.083740\n",
      "Stage: train, iter: 46900, lr: 7.339e-06, loss 0.060380\n",
      "Stage: train, iter: 46920, lr: 7.326e-06, loss 0.108606\n",
      "Stage: train, iter: 46940, lr: 7.312e-06, loss 0.119209\n",
      "Stage: train, iter: 46960, lr: 7.298e-06, loss 0.074470\n",
      "Stage: train, iter: 46980, lr: 7.284e-06, loss 0.090521\n",
      "Stage: train, iter: 47000, lr: 7.270e-06, loss 0.062726\n",
      "Stage: train, iter: 47020, lr: 7.256e-06, loss 0.080972\n",
      "Stage: train, iter: 47040, lr: 7.242e-06, loss 0.109950\n",
      "Stage: train, iter: 47060, lr: 7.228e-06, loss 0.104566\n",
      "Stage: train, iter: 47080, lr: 7.214e-06, loss 0.051431\n",
      "Stage: train, iter: 47100, lr: 7.199e-06, loss 0.107743\n",
      "Stage: train, iter: 47120, lr: 7.185e-06, loss 0.126184\n",
      "Stage: train, iter: 47140, lr: 7.171e-06, loss 0.045909\n",
      "Stage: train, iter: 47160, lr: 7.157e-06, loss 0.088479\n",
      "Stage: train, iter: 47180, lr: 7.143e-06, loss 0.121865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 47200, lr: 7.129e-06, loss 0.077370\n",
      "Stage: train, iter: 47220, lr: 7.114e-06, loss 0.057413\n",
      "Stage: train, iter: 47240, lr: 7.100e-06, loss 0.066232\n",
      "Stage: train, iter: 47260, lr: 7.086e-06, loss 0.060371\n",
      "Stage: train, iter: 47280, lr: 7.072e-06, loss 0.024611\n",
      "Stage: train, iter: 47300, lr: 7.057e-06, loss 0.056347\n",
      "Stage: train, iter: 47320, lr: 7.043e-06, loss 0.068898\n",
      "Stage: train, iter: 47340, lr: 7.029e-06, loss 0.071884\n",
      "Stage: train, iter: 47360, lr: 7.014e-06, loss 0.063999\n",
      "Stage: train, iter: 47380, lr: 7.000e-06, loss 0.078558\n",
      "Stage: train, iter: 47400, lr: 6.985e-06, loss 0.071884\n",
      "Stage: train, iter: 47420, lr: 6.971e-06, loss 0.085310\n",
      "Stage: train, iter: 47440, lr: 6.957e-06, loss 0.123534\n",
      "Stage: train, iter: 47460, lr: 6.942e-06, loss 0.046830\n",
      "Stage: train, iter: 47480, lr: 6.928e-06, loss 0.094018\n",
      "Stage: train, iter: 47500, lr: 6.913e-06, loss 0.102429\n",
      "Stage: train, iter: 47520, lr: 6.899e-06, loss 0.098802\n",
      "Stage: train, iter: 47540, lr: 6.884e-06, loss 0.068549\n",
      "Stage: train, iter: 47560, lr: 6.870e-06, loss 0.065071\n",
      "Stage: train, iter: 47580, lr: 6.855e-06, loss 0.041844\n",
      "Stage: train, iter: 47600, lr: 6.840e-06, loss 0.126836\n",
      "Stage: train, iter: 47620, lr: 6.826e-06, loss 0.055597\n",
      "Stage: train, iter: 47640, lr: 6.811e-06, loss 0.099129\n",
      "Stage: train, iter: 47660, lr: 6.796e-06, loss 0.057017\n",
      "Stage: train, iter: 47680, lr: 6.782e-06, loss 0.077041\n",
      "Stage: train, iter: 47700, lr: 6.767e-06, loss 0.092587\n",
      "Stage: train, iter: 47720, lr: 6.752e-06, loss 0.083115\n",
      "Stage: train, iter: 47740, lr: 6.738e-06, loss 0.132094\n",
      "Stage: train, iter: 47760, lr: 6.723e-06, loss 0.063913\n",
      "Stage: train, iter: 47780, lr: 6.708e-06, loss 0.061897\n",
      "Stage: train, iter: 47800, lr: 6.693e-06, loss 0.059806\n",
      "Stage: train, iter: 47820, lr: 6.679e-06, loss 0.072306\n",
      "Stage: train, iter: 47840, lr: 6.664e-06, loss 0.090855\n",
      "Stage: train, iter: 47860, lr: 6.649e-06, loss 0.075832\n",
      "Stage: train, iter: 47880, lr: 6.634e-06, loss 0.084641\n",
      "Stage: train, iter: 47900, lr: 6.619e-06, loss 0.113022\n",
      "Stage: train, iter: 47920, lr: 6.604e-06, loss 0.064319\n",
      "Stage: train, iter: 47940, lr: 6.590e-06, loss 0.079785\n",
      "Stage: train, iter: 47960, lr: 6.575e-06, loss 0.102656\n",
      "Stage: train, iter: 47980, lr: 6.560e-06, loss 0.070057\n",
      "Stage: train, iter: 48000, lr: 6.545e-06, loss 0.058664\n",
      "Stage: train, iter: 48020, lr: 6.530e-06, loss 0.103183\n",
      "Stage: train, iter: 48040, lr: 6.515e-06, loss 0.108946\n",
      "Stage: train, iter: 48060, lr: 6.500e-06, loss 0.059799\n",
      "Stage: train, iter: 48080, lr: 6.485e-06, loss 0.060904\n",
      "Stage: train, iter: 48100, lr: 6.470e-06, loss 0.088253\n",
      "Stage: train, iter: 48120, lr: 6.455e-06, loss 0.058275\n",
      "Stage: train, iter: 48140, lr: 6.440e-06, loss 0.075319\n",
      "Stage: train, iter: 48160, lr: 6.425e-06, loss 0.059487\n",
      "Stage: train, iter: 48180, lr: 6.410e-06, loss 0.098103\n",
      "Stage: train, iter: 48200, lr: 6.395e-06, loss 0.067753\n",
      "Stage: train, iter: 48220, lr: 6.380e-06, loss 0.053979\n",
      "Stage: train, iter: 48240, lr: 6.364e-06, loss 0.101798\n",
      "Stage: train, iter: 48260, lr: 6.349e-06, loss 0.167715\n",
      "Stage: train, iter: 48280, lr: 6.334e-06, loss 0.078241\n",
      "Stage: train, iter: 48300, lr: 6.319e-06, loss 0.085372\n",
      "Stage: train, iter: 48320, lr: 6.304e-06, loss 0.093823\n",
      "Stage: train, iter: 48340, lr: 6.289e-06, loss 0.104478\n",
      "Stage: train, iter: 48360, lr: 6.274e-06, loss 0.070000\n",
      "Stage: train, iter: 48380, lr: 6.258e-06, loss 0.055400\n",
      "Stage: train, iter: 48400, lr: 6.243e-06, loss 0.090113\n",
      "Stage: train, iter: 48420, lr: 6.228e-06, loss 0.065538\n",
      "Stage: train, iter: 48440, lr: 6.213e-06, loss 0.073243\n",
      "Stage: train, iter: 48460, lr: 6.197e-06, loss 0.061001\n",
      "Stage: train, iter: 48480, lr: 6.182e-06, loss 0.067358\n",
      "Stage: train, iter: 48500, lr: 6.167e-06, loss 0.041207\n",
      "Stage: train, iter: 48520, lr: 6.152e-06, loss 0.074114\n",
      "Stage: train, iter: 48540, lr: 6.136e-06, loss 0.061017\n",
      "Stage: train, iter: 48560, lr: 6.121e-06, loss 0.082769\n",
      "Stage: train, iter: 48580, lr: 6.106e-06, loss 0.092832\n",
      "Stage: train, iter: 48600, lr: 6.090e-06, loss 0.064402\n",
      "Stage: train, iter: 48620, lr: 6.075e-06, loss 0.106386\n",
      "Stage: train, iter: 48640, lr: 6.060e-06, loss 0.067481\n",
      "Stage: train, iter: 48660, lr: 6.044e-06, loss 0.069851\n",
      "Stage: train, iter: 48680, lr: 6.029e-06, loss 0.060529\n",
      "Stage: train, iter: 48700, lr: 6.014e-06, loss 0.108817\n",
      "Stage: train, iter: 48720, lr: 5.998e-06, loss 0.098313\n",
      "Stage: train, iter: 48740, lr: 5.983e-06, loss 0.115471\n",
      "Stage: train, iter: 48760, lr: 5.967e-06, loss 0.097808\n",
      "Stage: train, iter: 48780, lr: 5.952e-06, loss 0.054146\n",
      "Stage: train, iter: 48800, lr: 5.937e-06, loss 0.071533\n",
      "Stage: train, iter: 48820, lr: 5.921e-06, loss 0.060468\n",
      "Stage: train, iter: 48840, lr: 5.906e-06, loss 0.119790\n",
      "Stage: train, iter: 48860, lr: 5.890e-06, loss 0.095373\n",
      "Stage: train, iter: 48880, lr: 5.875e-06, loss 0.051941\n",
      "Stage: train, iter: 48900, lr: 5.859e-06, loss 0.087052\n",
      "Stage: train, iter: 48920, lr: 5.844e-06, loss 0.094102\n",
      "Stage: train, iter: 48940, lr: 5.828e-06, loss 0.084646\n",
      "Stage: train, iter: 48960, lr: 5.813e-06, loss 0.063319\n",
      "Stage: train, iter: 48980, lr: 5.797e-06, loss 0.077905\n",
      "Stage: train, iter: 49000, lr: 5.782e-06, loss 0.057007\n",
      "Stage: train, iter: 49020, lr: 5.766e-06, loss 0.107253\n",
      "Stage: train, iter: 49040, lr: 5.751e-06, loss 0.046872\n",
      "Stage: train, iter: 49060, lr: 5.735e-06, loss 0.087205\n",
      "Stage: train, iter: 49080, lr: 5.720e-06, loss 0.102677\n",
      "Stage: train, iter: 49100, lr: 5.704e-06, loss 0.077255\n",
      "Stage: train, iter: 49120, lr: 5.689e-06, loss 0.070227\n",
      "Stage: train, iter: 49140, lr: 5.673e-06, loss 0.061267\n",
      "Stage: train, iter: 49160, lr: 5.657e-06, loss 0.060883\n",
      "Stage: train, iter: 49180, lr: 5.642e-06, loss 0.054843\n",
      "Stage: train, iter: 49200, lr: 5.626e-06, loss 0.059202\n",
      "Stage: train, iter: 49220, lr: 5.611e-06, loss 0.041295\n",
      "Stage: train, iter: 49240, lr: 5.595e-06, loss 0.117044\n",
      "Stage: train, iter: 49260, lr: 5.580e-06, loss 0.090635\n",
      "Stage: train, iter: 49280, lr: 5.564e-06, loss 0.102389\n",
      "Stage: train, iter: 49300, lr: 5.548e-06, loss 0.024005\n",
      "Stage: train, iter: 49320, lr: 5.533e-06, loss 0.126779\n",
      "Stage: train, iter: 49340, lr: 5.517e-06, loss 0.072599\n",
      "Stage: train, iter: 49360, lr: 5.501e-06, loss 0.085692\n",
      "Stage: train, iter: 49380, lr: 5.486e-06, loss 0.087174\n",
      "Stage: train, iter: 49400, lr: 5.470e-06, loss 0.078861\n",
      "Stage: train, iter: 49420, lr: 5.455e-06, loss 0.072593\n",
      "Stage: train, iter: 49440, lr: 5.439e-06, loss 0.092883\n",
      "Stage: train, iter: 49460, lr: 5.423e-06, loss 0.055352\n",
      "Stage: train, iter: 49480, lr: 5.408e-06, loss 0.098134\n",
      "Stage: train, iter: 49500, lr: 5.392e-06, loss 0.073612\n",
      "Stage: train, iter: 49520, lr: 5.376e-06, loss 0.100976\n",
      "Stage: train, iter: 49540, lr: 5.361e-06, loss 0.096571\n",
      "Stage: train, iter: 49560, lr: 5.345e-06, loss 0.086658\n",
      "Stage: train, iter: 49580, lr: 5.329e-06, loss 0.103626\n",
      "Stage: train, iter: 49600, lr: 5.314e-06, loss 0.081240\n",
      "Stage: train, iter: 49620, lr: 5.298e-06, loss 0.070195\n",
      "Stage: train, iter: 49640, lr: 5.282e-06, loss 0.073316\n",
      "Stage: train, iter: 49660, lr: 5.267e-06, loss 0.080617\n",
      "Stage: train, iter: 49680, lr: 5.251e-06, loss 0.084101\n",
      "Stage: train, iter: 49700, lr: 5.235e-06, loss 0.093623\n",
      "Stage: train, iter: 49720, lr: 5.219e-06, loss 0.061377\n",
      "Stage: train, iter: 49740, lr: 5.204e-06, loss 0.085388\n",
      "Stage: train, iter: 49760, lr: 5.188e-06, loss 0.112379\n",
      "Stage: train, iter: 49780, lr: 5.172e-06, loss 0.106746\n",
      "Stage: train, iter: 49800, lr: 5.157e-06, loss 0.055591\n",
      "Stage: train, iter: 49820, lr: 5.141e-06, loss 0.076083\n",
      "Stage: train, iter: 49840, lr: 5.125e-06, loss 0.097484\n",
      "Stage: train, iter: 49860, lr: 5.110e-06, loss 0.107196\n",
      "Stage: train, iter: 49880, lr: 5.094e-06, loss 0.065005\n",
      "Stage: train, iter: 49900, lr: 5.078e-06, loss 0.077687\n",
      "Stage: train, iter: 49920, lr: 5.062e-06, loss 0.057653\n",
      "Stage: train, iter: 49940, lr: 5.047e-06, loss 0.065526\n",
      "Stage: train, iter: 49960, lr: 5.031e-06, loss 0.080134\n",
      "Stage: train, iter: 49980, lr: 5.015e-06, loss 0.093192\n",
      "Stage: train, iter: 50000, lr: 5.000e-06, loss 0.075144\n",
      "Stage: train, iter: 50020, lr: 4.984e-06, loss 0.048385\n",
      "Stage: train, iter: 50040, lr: 4.968e-06, loss 0.073333\n",
      "Stage: train, iter: 50060, lr: 4.952e-06, loss 0.074330\n",
      "Stage: train, iter: 50080, lr: 4.937e-06, loss 0.128181\n",
      "Stage: train, iter: 50100, lr: 4.921e-06, loss 0.150795\n",
      "Stage: train, iter: 50120, lr: 4.905e-06, loss 0.108418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 50140, lr: 4.890e-06, loss 0.091579\n",
      "Stage: train, iter: 50160, lr: 4.874e-06, loss 0.070369\n",
      "Stage: train, iter: 50180, lr: 4.858e-06, loss 0.061537\n",
      "Stage: train, iter: 50200, lr: 4.843e-06, loss 0.081559\n",
      "Stage: train, iter: 50220, lr: 4.827e-06, loss 0.076340\n",
      "Stage: train, iter: 50240, lr: 4.811e-06, loss 0.078138\n",
      "Stage: train, iter: 50260, lr: 4.795e-06, loss 0.096660\n",
      "Stage: train, iter: 50280, lr: 4.780e-06, loss 0.072315\n",
      "Stage: train, iter: 50300, lr: 4.764e-06, loss 0.077976\n",
      "Stage: train, iter: 50320, lr: 4.748e-06, loss 0.055112\n",
      "Stage: train, iter: 50340, lr: 4.733e-06, loss 0.095233\n",
      "Stage: train, iter: 50360, lr: 4.717e-06, loss 0.084264\n",
      "Stage: train, iter: 50380, lr: 4.701e-06, loss 0.070222\n",
      "Stage: train, iter: 50400, lr: 4.686e-06, loss 0.064683\n",
      "Stage: train, iter: 50420, lr: 4.670e-06, loss 0.091993\n",
      "Stage: train, iter: 50440, lr: 4.654e-06, loss 0.079700\n",
      "Stage: train, iter: 50460, lr: 4.639e-06, loss 0.067255\n",
      "Stage: train, iter: 50480, lr: 4.623e-06, loss 0.067286\n",
      "Stage: train, iter: 50500, lr: 4.607e-06, loss 0.070962\n",
      "Stage: train, iter: 50520, lr: 4.592e-06, loss 0.070137\n",
      "Stage: train, iter: 50540, lr: 4.576e-06, loss 0.075417\n",
      "Stage: train, iter: 50560, lr: 4.560e-06, loss 0.043987\n",
      "Stage: train, iter: 50580, lr: 4.545e-06, loss 0.133892\n",
      "Stage: train, iter: 50600, lr: 4.529e-06, loss 0.066479\n",
      "Stage: train, iter: 50620, lr: 4.513e-06, loss 0.115490\n",
      "Stage: train, iter: 50640, lr: 4.498e-06, loss 0.056444\n",
      "Stage: train, iter: 50660, lr: 4.482e-06, loss 0.079988\n",
      "Stage: train, iter: 50680, lr: 4.467e-06, loss 0.076706\n",
      "Stage: train, iter: 50700, lr: 4.451e-06, loss 0.072817\n",
      "Stage: train, iter: 50720, lr: 4.435e-06, loss 0.069083\n",
      "Stage: train, iter: 50740, lr: 4.420e-06, loss 0.055908\n",
      "Stage: train, iter: 50760, lr: 4.404e-06, loss 0.068566\n",
      "Stage: train, iter: 50780, lr: 4.389e-06, loss 0.025833\n",
      "Stage: train, iter: 50800, lr: 4.373e-06, loss 0.070196\n",
      "Stage: train, iter: 50820, lr: 4.357e-06, loss 0.117065\n",
      "Stage: train, iter: 50840, lr: 4.342e-06, loss 0.053341\n",
      "Stage: train, iter: 50860, lr: 4.326e-06, loss 0.055437\n",
      "Stage: train, iter: 50880, lr: 4.311e-06, loss 0.098483\n",
      "Stage: train, iter: 50900, lr: 4.295e-06, loss 0.056651\n",
      "Stage: train, iter: 50920, lr: 4.280e-06, loss 0.072249\n",
      "Stage: train, iter: 50940, lr: 4.264e-06, loss 0.076402\n",
      "Stage: train, iter: 50960, lr: 4.248e-06, loss 0.095418\n",
      "Stage: train, iter: 50980, lr: 4.233e-06, loss 0.077584\n",
      "Stage: train, iter: 51000, lr: 4.217e-06, loss 0.082567\n",
      "Stage: train, iter: 51020, lr: 4.202e-06, loss 0.047636\n",
      "Stage: train, iter: 51040, lr: 4.186e-06, loss 0.097871\n",
      "Stage: train, iter: 51060, lr: 4.171e-06, loss 0.050115\n",
      "Stage: train, iter: 51080, lr: 4.155e-06, loss 0.099377\n",
      "Stage: train, iter: 51100, lr: 4.140e-06, loss 0.074147\n",
      "Stage: train, iter: 51120, lr: 4.124e-06, loss 0.090666\n",
      "Stage: train, iter: 51140, lr: 4.109e-06, loss 0.074544\n",
      "Stage: train, iter: 51160, lr: 4.094e-06, loss 0.092413\n",
      "Stage: train, iter: 51180, lr: 4.078e-06, loss 0.116425\n",
      "Stage: train, iter: 51200, lr: 4.063e-06, loss 0.100136\n",
      "Stage: train, iter: 51220, lr: 4.047e-06, loss 0.055452\n",
      "Stage: train, iter: 51240, lr: 4.032e-06, loss 0.074381\n",
      "Stage: train, iter: 51260, lr: 4.016e-06, loss 0.073870\n",
      "Stage: train, iter: 51280, lr: 4.001e-06, loss 0.036383\n",
      "Stage: train, iter: 51300, lr: 3.986e-06, loss 0.051243\n",
      "Stage: train, iter: 51320, lr: 3.970e-06, loss 0.084612\n",
      "Stage: train, iter: 51340, lr: 3.955e-06, loss 0.076100\n",
      "Stage: train, iter: 51360, lr: 3.940e-06, loss 0.132745\n",
      "Stage: train, iter: 51380, lr: 3.924e-06, loss 0.076397\n",
      "Stage: train, iter: 51400, lr: 3.909e-06, loss 0.064105\n",
      "Stage: train, iter: 51420, lr: 3.894e-06, loss 0.071516\n",
      "Stage: train, iter: 51440, lr: 3.878e-06, loss 0.122076\n",
      "Stage: train, iter: 51460, lr: 3.863e-06, loss 0.073280\n",
      "Stage: train, iter: 51480, lr: 3.848e-06, loss 0.043325\n",
      "Stage: train, iter: 51500, lr: 3.832e-06, loss 0.091788\n",
      "Stage: train, iter: 51520, lr: 3.817e-06, loss 0.089428\n",
      "Stage: train, iter: 51540, lr: 3.802e-06, loss 0.076428\n",
      "Stage: train, iter: 51560, lr: 3.787e-06, loss 0.069055\n",
      "Stage: train, iter: 51580, lr: 3.771e-06, loss 0.064702\n",
      "Stage: train, iter: 51600, lr: 3.756e-06, loss 0.052543\n",
      "Stage: train, iter: 51620, lr: 3.741e-06, loss 0.074525\n",
      "Stage: train, iter: 51640, lr: 3.726e-06, loss 0.072113\n",
      "Stage: train, iter: 51660, lr: 3.711e-06, loss 0.064369\n",
      "Stage: train, iter: 51680, lr: 3.695e-06, loss 0.058925\n",
      "Stage: train, iter: 51700, lr: 3.680e-06, loss 0.078188\n",
      "Stage: train, iter: 51720, lr: 3.665e-06, loss 0.058294\n",
      "Stage: train, iter: 51740, lr: 3.650e-06, loss 0.094387\n",
      "Stage: train, iter: 51760, lr: 3.635e-06, loss 0.066040\n",
      "Stage: train, iter: 51780, lr: 3.620e-06, loss 0.076601\n",
      "Stage: train, iter: 51800, lr: 3.605e-06, loss 0.071253\n",
      "Stage: train, iter: 51820, lr: 3.590e-06, loss 0.070106\n",
      "Stage: train, iter: 51840, lr: 3.574e-06, loss 0.072391\n",
      "Stage: train, iter: 51860, lr: 3.559e-06, loss 0.094830\n",
      "Stage: train, iter: 51880, lr: 3.544e-06, loss 0.073659\n",
      "Stage: train, iter: 51900, lr: 3.529e-06, loss 0.081677\n",
      "Stage: train, iter: 51920, lr: 3.514e-06, loss 0.066224\n",
      "Stage: train, iter: 51940, lr: 3.499e-06, loss 0.073884\n",
      "Stage: train, iter: 51960, lr: 3.484e-06, loss 0.105278\n",
      "Stage: train, iter: 51980, lr: 3.469e-06, loss 0.111566\n",
      "Stage: train, iter: 52000, lr: 3.454e-06, loss 0.096703\n",
      "Stage: train, iter: 52020, lr: 3.440e-06, loss 0.055019\n",
      "Stage: train, iter: 52040, lr: 3.425e-06, loss 0.059725\n",
      "Stage: train, iter: 52060, lr: 3.410e-06, loss 0.099433\n",
      "Stage: train, iter: 52080, lr: 3.395e-06, loss 0.078304\n",
      "Stage: train, iter: 52100, lr: 3.380e-06, loss 0.110789\n",
      "Stage: train, iter: 52120, lr: 3.365e-06, loss 0.081912\n",
      "Stage: train, iter: 52140, lr: 3.350e-06, loss 0.118391\n",
      "Stage: train, iter: 52160, lr: 3.335e-06, loss 0.086121\n",
      "Stage: train, iter: 52180, lr: 3.321e-06, loss 0.086526\n",
      "Stage: train, iter: 52200, lr: 3.306e-06, loss 0.072454\n",
      "Stage: train, iter: 52220, lr: 3.291e-06, loss 0.115985\n",
      "Stage: train, iter: 52240, lr: 3.276e-06, loss 0.090043\n",
      "Stage: train, iter: 52260, lr: 3.262e-06, loss 0.058564\n",
      "Stage: train, iter: 52280, lr: 3.247e-06, loss 0.101419\n",
      "Stage: train, iter: 52300, lr: 3.232e-06, loss 0.127080\n",
      "Stage: train, iter: 52320, lr: 3.217e-06, loss 0.067575\n",
      "Stage: train, iter: 52340, lr: 3.203e-06, loss 0.077586\n",
      "Stage: train, iter: 52360, lr: 3.188e-06, loss 0.065298\n",
      "Stage: train, iter: 52380, lr: 3.174e-06, loss 0.076586\n",
      "Stage: train, iter: 52400, lr: 3.159e-06, loss 0.073889\n",
      "Stage: train, iter: 52420, lr: 3.144e-06, loss 0.106289\n",
      "Stage: train, iter: 52440, lr: 3.130e-06, loss 0.114798\n",
      "Stage: train, iter: 52460, lr: 3.115e-06, loss 0.110964\n",
      "Stage: train, iter: 52480, lr: 3.101e-06, loss 0.061356\n",
      "Stage: train, iter: 52500, lr: 3.086e-06, loss 0.101199\n",
      "Stage: train, iter: 52520, lr: 3.072e-06, loss 0.104476\n",
      "Stage: train, iter: 52540, lr: 3.057e-06, loss 0.106612\n",
      "Stage: train, iter: 52560, lr: 3.043e-06, loss 0.068991\n",
      "Stage: train, iter: 52580, lr: 3.028e-06, loss 0.058536\n",
      "Stage: train, iter: 52600, lr: 3.014e-06, loss 0.053415\n",
      "Stage: train, iter: 52620, lr: 2.999e-06, loss 0.079016\n",
      "Stage: train, iter: 52640, lr: 2.985e-06, loss 0.106188\n",
      "Stage: train, iter: 52660, lr: 2.971e-06, loss 0.078813\n",
      "Stage: train, iter: 52680, lr: 2.956e-06, loss 0.075345\n",
      "Stage: train, iter: 52700, lr: 2.942e-06, loss 0.094125\n",
      "Stage: train, iter: 52720, lr: 2.928e-06, loss 0.108448\n",
      "Stage: train, iter: 52740, lr: 2.913e-06, loss 0.087001\n",
      "Stage: train, iter: 52760, lr: 2.899e-06, loss 0.067366\n",
      "Stage: train, iter: 52780, lr: 2.885e-06, loss 0.082029\n",
      "Stage: train, iter: 52800, lr: 2.871e-06, loss 0.134302\n",
      "Stage: train, iter: 52820, lr: 2.856e-06, loss 0.061976\n",
      "Stage: train, iter: 52840, lr: 2.842e-06, loss 0.052337\n",
      "Stage: train, iter: 52860, lr: 2.828e-06, loss 0.032044\n",
      "Stage: train, iter: 52880, lr: 2.814e-06, loss 0.073466\n",
      "Stage: train, iter: 52900, lr: 2.800e-06, loss 0.060476\n",
      "Stage: train, iter: 52920, lr: 2.786e-06, loss 0.056589\n",
      "Stage: train, iter: 52940, lr: 2.772e-06, loss 0.080063\n",
      "Stage: train, iter: 52960, lr: 2.758e-06, loss 0.090380\n",
      "Stage: train, iter: 52980, lr: 2.744e-06, loss 0.083313\n",
      "Stage: train, iter: 53000, lr: 2.730e-06, loss 0.079005\n",
      "Stage: train, iter: 53020, lr: 2.716e-06, loss 0.067742\n",
      "Stage: train, iter: 53040, lr: 2.702e-06, loss 0.103169\n",
      "Stage: train, iter: 53060, lr: 2.688e-06, loss 0.077440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 53080, lr: 2.674e-06, loss 0.093483\n",
      "Stage: train, iter: 53100, lr: 2.660e-06, loss 0.062688\n",
      "Stage: train, iter: 53120, lr: 2.646e-06, loss 0.104165\n",
      "Stage: train, iter: 53140, lr: 2.632e-06, loss 0.093298\n",
      "Stage: train, iter: 53160, lr: 2.618e-06, loss 0.098458\n",
      "Stage: train, iter: 53180, lr: 2.605e-06, loss 0.056547\n",
      "Stage: train, iter: 53200, lr: 2.591e-06, loss 0.070906\n",
      "Stage: train, iter: 53220, lr: 2.577e-06, loss 0.050430\n",
      "Stage: train, iter: 53240, lr: 2.563e-06, loss 0.087760\n",
      "Stage: train, iter: 53260, lr: 2.550e-06, loss 0.087235\n",
      "Stage: train, iter: 53280, lr: 2.536e-06, loss 0.065433\n",
      "Stage: train, iter: 53300, lr: 2.522e-06, loss 0.100367\n",
      "Stage: train, iter: 53320, lr: 2.509e-06, loss 0.086758\n",
      "Stage: train, iter: 53340, lr: 2.495e-06, loss 0.061662\n",
      "Stage: train, iter: 53360, lr: 2.481e-06, loss 0.047210\n",
      "Stage: train, iter: 53380, lr: 2.468e-06, loss 0.095966\n",
      "Stage: train, iter: 53400, lr: 2.454e-06, loss 0.087672\n",
      "Stage: train, iter: 53420, lr: 2.441e-06, loss 0.079879\n",
      "Stage: train, iter: 53440, lr: 2.427e-06, loss 0.059990\n",
      "Stage: train, iter: 53460, lr: 2.414e-06, loss 0.040041\n",
      "Stage: train, iter: 53480, lr: 2.400e-06, loss 0.109472\n",
      "Stage: train, iter: 53500, lr: 2.387e-06, loss 0.052037\n",
      "Stage: train, iter: 53520, lr: 2.374e-06, loss 0.111747\n",
      "Stage: train, iter: 53540, lr: 2.360e-06, loss 0.061489\n",
      "Stage: train, iter: 53560, lr: 2.347e-06, loss 0.091371\n",
      "Stage: train, iter: 53580, lr: 2.334e-06, loss 0.048687\n",
      "Stage: train, iter: 53600, lr: 2.320e-06, loss 0.083035\n",
      "Stage: train, iter: 53620, lr: 2.307e-06, loss 0.074919\n",
      "Stage: train, iter: 53640, lr: 2.294e-06, loss 0.070357\n",
      "Stage: train, iter: 53660, lr: 2.281e-06, loss 0.086574\n",
      "Stage: train, iter: 53680, lr: 2.268e-06, loss 0.075871\n",
      "Stage: train, iter: 53700, lr: 2.254e-06, loss 0.066985\n",
      "Stage: train, iter: 53720, lr: 2.241e-06, loss 0.066283\n",
      "Stage: train, iter: 53740, lr: 2.228e-06, loss 0.072769\n",
      "Stage: train, iter: 53760, lr: 2.215e-06, loss 0.060482\n",
      "Stage: train, iter: 53780, lr: 2.202e-06, loss 0.064531\n",
      "Stage: train, iter: 53800, lr: 2.189e-06, loss 0.101100\n",
      "Stage: train, iter: 53820, lr: 2.176e-06, loss 0.073390\n",
      "Stage: train, iter: 53840, lr: 2.163e-06, loss 0.055426\n",
      "Stage: train, iter: 53860, lr: 2.150e-06, loss 0.059348\n",
      "Stage: train, iter: 53880, lr: 2.137e-06, loss 0.053413\n",
      "Stage: train, iter: 53900, lr: 2.125e-06, loss 0.057153\n",
      "Stage: train, iter: 53920, lr: 2.112e-06, loss 0.052370\n",
      "Stage: train, iter: 53940, lr: 2.099e-06, loss 0.077989\n",
      "Stage: train, iter: 53960, lr: 2.086e-06, loss 0.085681\n",
      "Stage: train, iter: 53980, lr: 2.073e-06, loss 0.093807\n",
      "Stage: train, iter: 54000, lr: 2.061e-06, loss 0.080020\n",
      "Stage: train, iter: 54020, lr: 2.048e-06, loss 0.078198\n",
      "Stage: train, iter: 54040, lr: 2.035e-06, loss 0.064906\n",
      "Stage: train, iter: 54060, lr: 2.023e-06, loss 0.080886\n",
      "Stage: train, iter: 54080, lr: 2.010e-06, loss 0.116877\n",
      "Stage: train, iter: 54100, lr: 1.997e-06, loss 0.074767\n",
      "Stage: train, iter: 54120, lr: 1.985e-06, loss 0.083691\n",
      "Stage: train, iter: 54140, lr: 1.972e-06, loss 0.113121\n",
      "Stage: train, iter: 54160, lr: 1.960e-06, loss 0.082790\n",
      "Stage: train, iter: 54180, lr: 1.947e-06, loss 0.064193\n",
      "Stage: train, iter: 54200, lr: 1.935e-06, loss 0.079611\n",
      "Stage: train, iter: 54220, lr: 1.923e-06, loss 0.085030\n",
      "Stage: train, iter: 54240, lr: 1.910e-06, loss 0.072946\n",
      "Stage: train, iter: 54260, lr: 1.898e-06, loss 0.049234\n",
      "Stage: train, iter: 54280, lr: 1.886e-06, loss 0.084164\n",
      "Stage: train, iter: 54300, lr: 1.873e-06, loss 0.075992\n",
      "Stage: train, iter: 54320, lr: 1.861e-06, loss 0.085497\n",
      "Stage: train, iter: 54340, lr: 1.849e-06, loss 0.061079\n",
      "Stage: train, iter: 54360, lr: 1.837e-06, loss 0.081563\n",
      "Stage: train, iter: 54380, lr: 1.825e-06, loss 0.077556\n",
      "Stage: train, iter: 54400, lr: 1.812e-06, loss 0.036831\n",
      "Stage: train, iter: 54420, lr: 1.800e-06, loss 0.085338\n",
      "Stage: train, iter: 54440, lr: 1.788e-06, loss 0.061829\n",
      "Stage: train, iter: 54460, lr: 1.776e-06, loss 0.079120\n",
      "Stage: train, iter: 54480, lr: 1.764e-06, loss 0.080856\n",
      "Stage: train, iter: 54500, lr: 1.752e-06, loss 0.088995\n",
      "Stage: train, iter: 54520, lr: 1.740e-06, loss 0.043312\n",
      "Stage: train, iter: 54540, lr: 1.729e-06, loss 0.092651\n",
      "Stage: train, iter: 54560, lr: 1.717e-06, loss 0.124699\n",
      "Stage: train, iter: 54580, lr: 1.705e-06, loss 0.068003\n",
      "Stage: train, iter: 54600, lr: 1.693e-06, loss 0.085684\n",
      "Stage: train, iter: 54620, lr: 1.681e-06, loss 0.101862\n",
      "Stage: train, iter: 54640, lr: 1.670e-06, loss 0.084939\n",
      "Stage: train, iter: 54660, lr: 1.658e-06, loss 0.079350\n",
      "Stage: train, iter: 54680, lr: 1.646e-06, loss 0.076698\n",
      "Stage: train, iter: 54700, lr: 1.635e-06, loss 0.088629\n",
      "Stage: train, iter: 54720, lr: 1.623e-06, loss 0.056678\n",
      "Stage: train, iter: 54740, lr: 1.611e-06, loss 0.092822\n",
      "Stage: train, iter: 54760, lr: 1.600e-06, loss 0.064314\n",
      "Stage: train, iter: 54780, lr: 1.588e-06, loss 0.078700\n",
      "Stage: train, iter: 54800, lr: 1.577e-06, loss 0.081232\n",
      "Stage: train, iter: 54820, lr: 1.565e-06, loss 0.071353\n",
      "Stage: train, iter: 54840, lr: 1.554e-06, loss 0.073770\n",
      "Stage: train, iter: 54860, lr: 1.543e-06, loss 0.062046\n",
      "Stage: train, iter: 54880, lr: 1.531e-06, loss 0.049789\n",
      "Stage: train, iter: 54900, lr: 1.520e-06, loss 0.056535\n",
      "Stage: train, iter: 54920, lr: 1.509e-06, loss 0.049302\n",
      "Stage: train, iter: 54940, lr: 1.498e-06, loss 0.110785\n",
      "Stage: train, iter: 54960, lr: 1.486e-06, loss 0.064609\n",
      "Stage: train, iter: 54980, lr: 1.475e-06, loss 0.096161\n",
      "Stage: train, iter: 55000, lr: 1.464e-06, loss 0.063539\n",
      "Stage: train, iter: 55020, lr: 1.453e-06, loss 0.080756\n",
      "Stage: train, iter: 55040, lr: 1.442e-06, loss 0.082487\n",
      "Stage: train, iter: 55060, lr: 1.431e-06, loss 0.093233\n",
      "Stage: train, iter: 55080, lr: 1.420e-06, loss 0.062241\n",
      "Stage: train, iter: 55100, lr: 1.409e-06, loss 0.105480\n",
      "Stage: train, iter: 55120, lr: 1.398e-06, loss 0.125672\n",
      "Stage: train, iter: 55140, lr: 1.387e-06, loss 0.071129\n",
      "Stage: train, iter: 55160, lr: 1.376e-06, loss 0.068590\n",
      "Stage: train, iter: 55180, lr: 1.366e-06, loss 0.065422\n",
      "Stage: train, iter: 55200, lr: 1.355e-06, loss 0.064263\n",
      "Stage: train, iter: 55220, lr: 1.344e-06, loss 0.086527\n",
      "Stage: train, iter: 55240, lr: 1.333e-06, loss 0.079037\n",
      "Stage: train, iter: 55260, lr: 1.323e-06, loss 0.066319\n",
      "Stage: train, iter: 55280, lr: 1.312e-06, loss 0.065609\n",
      "Stage: train, iter: 55300, lr: 1.301e-06, loss 0.060649\n",
      "Stage: train, iter: 55320, lr: 1.291e-06, loss 0.078074\n",
      "Stage: train, iter: 55340, lr: 1.280e-06, loss 0.081231\n",
      "Stage: train, iter: 55360, lr: 1.270e-06, loss 0.072997\n",
      "Stage: train, iter: 55380, lr: 1.259e-06, loss 0.102285\n",
      "Stage: train, iter: 55400, lr: 1.249e-06, loss 0.129423\n",
      "Stage: train, iter: 55420, lr: 1.239e-06, loss 0.052258\n",
      "Stage: train, iter: 55440, lr: 1.228e-06, loss 0.079975\n",
      "Stage: train, iter: 55460, lr: 1.218e-06, loss 0.071648\n",
      "Stage: train, iter: 55480, lr: 1.208e-06, loss 0.082044\n",
      "Stage: train, iter: 55500, lr: 1.198e-06, loss 0.062338\n",
      "Stage: train, iter: 55520, lr: 1.187e-06, loss 0.065912\n",
      "Stage: train, iter: 55540, lr: 1.177e-06, loss 0.070119\n",
      "Stage: train, iter: 55560, lr: 1.167e-06, loss 0.087435\n",
      "Stage: train, iter: 55580, lr: 1.157e-06, loss 0.079112\n",
      "Stage: train, iter: 55600, lr: 1.147e-06, loss 0.052420\n",
      "Stage: train, iter: 55620, lr: 1.137e-06, loss 0.095016\n",
      "Stage: train, iter: 55640, lr: 1.127e-06, loss 0.064782\n",
      "Stage: train, iter: 55660, lr: 1.117e-06, loss 0.092949\n",
      "Stage: train, iter: 55680, lr: 1.107e-06, loss 0.072836\n",
      "Stage: train, iter: 55700, lr: 1.097e-06, loss 0.063745\n",
      "Stage: train, iter: 55720, lr: 1.088e-06, loss 0.088623\n",
      "Stage: train, iter: 55740, lr: 1.078e-06, loss 0.097988\n",
      "Stage: train, iter: 55760, lr: 1.068e-06, loss 0.080658\n",
      "Stage: train, iter: 55780, lr: 1.058e-06, loss 0.077969\n",
      "Stage: train, iter: 55800, lr: 1.049e-06, loss 0.083232\n",
      "Stage: train, iter: 55820, lr: 1.039e-06, loss 0.074427\n",
      "Stage: train, iter: 55840, lr: 1.030e-06, loss 0.085149\n",
      "Stage: train, iter: 55860, lr: 1.020e-06, loss 0.061224\n",
      "Stage: train, iter: 55880, lr: 1.011e-06, loss 0.069802\n",
      "Stage: train, iter: 55900, lr: 1.001e-06, loss 0.076827\n",
      "Stage: train, iter: 55920, lr: 9.918e-07, loss 0.061309\n",
      "Stage: train, iter: 55940, lr: 9.824e-07, loss 0.090837\n",
      "Stage: train, iter: 55960, lr: 9.731e-07, loss 0.055550\n",
      "Stage: train, iter: 55980, lr: 9.638e-07, loss 0.028222\n",
      "Stage: train, iter: 56000, lr: 9.545e-07, loss 0.099743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 56020, lr: 9.453e-07, loss 0.078387\n",
      "Stage: train, iter: 56040, lr: 9.362e-07, loss 0.118725\n",
      "Stage: train, iter: 56060, lr: 9.270e-07, loss 0.083216\n",
      "Stage: train, iter: 56080, lr: 9.179e-07, loss 0.080509\n",
      "Stage: train, iter: 56100, lr: 9.089e-07, loss 0.075106\n",
      "Stage: train, iter: 56120, lr: 8.999e-07, loss 0.086598\n",
      "Stage: train, iter: 56140, lr: 8.909e-07, loss 0.092820\n",
      "Stage: train, iter: 56160, lr: 8.820e-07, loss 0.074026\n",
      "Stage: train, iter: 56180, lr: 8.731e-07, loss 0.081283\n",
      "Stage: train, iter: 56200, lr: 8.642e-07, loss 0.065454\n",
      "Stage: train, iter: 56220, lr: 8.554e-07, loss 0.107913\n",
      "Stage: train, iter: 56240, lr: 8.467e-07, loss 0.095013\n",
      "Stage: train, iter: 56260, lr: 8.379e-07, loss 0.074757\n",
      "Stage: train, iter: 56280, lr: 8.293e-07, loss 0.083218\n",
      "Stage: train, iter: 56300, lr: 8.206e-07, loss 0.066662\n",
      "Stage: train, iter: 56320, lr: 8.120e-07, loss 0.074153\n",
      "Stage: train, iter: 56340, lr: 8.034e-07, loss 0.053412\n",
      "Stage: train, iter: 56360, lr: 7.949e-07, loss 0.078878\n",
      "Stage: train, iter: 56380, lr: 7.865e-07, loss 0.072083\n",
      "Stage: train, iter: 56400, lr: 7.780e-07, loss 0.067219\n",
      "Stage: train, iter: 56420, lr: 7.696e-07, loss 0.050589\n",
      "Stage: train, iter: 56440, lr: 7.613e-07, loss 0.073622\n",
      "Stage: train, iter: 56460, lr: 7.530e-07, loss 0.075466\n",
      "Stage: train, iter: 56480, lr: 7.447e-07, loss 0.075064\n",
      "Stage: train, iter: 56500, lr: 7.365e-07, loss 0.080033\n",
      "Stage: train, iter: 56520, lr: 7.283e-07, loss 0.034461\n",
      "Stage: train, iter: 56540, lr: 7.201e-07, loss 0.055004\n",
      "Stage: train, iter: 56560, lr: 7.120e-07, loss 0.056992\n",
      "Stage: train, iter: 56580, lr: 7.040e-07, loss 0.101480\n",
      "Stage: train, iter: 56600, lr: 6.960e-07, loss 0.112349\n",
      "Stage: train, iter: 56620, lr: 6.880e-07, loss 0.115718\n",
      "Stage: train, iter: 56640, lr: 6.801e-07, loss 0.096560\n",
      "Stage: train, iter: 56660, lr: 6.722e-07, loss 0.067011\n",
      "Stage: train, iter: 56680, lr: 6.643e-07, loss 0.094168\n",
      "Stage: train, iter: 56700, lr: 6.565e-07, loss 0.114148\n",
      "Stage: train, iter: 56720, lr: 6.488e-07, loss 0.091356\n",
      "Stage: train, iter: 56740, lr: 6.410e-07, loss 0.093889\n",
      "Stage: train, iter: 56760, lr: 6.334e-07, loss 0.075608\n",
      "Stage: train, iter: 56780, lr: 6.257e-07, loss 0.058783\n",
      "Stage: train, iter: 56800, lr: 6.181e-07, loss 0.098967\n",
      "Stage: train, iter: 56820, lr: 6.106e-07, loss 0.099799\n",
      "Stage: train, iter: 56840, lr: 6.031e-07, loss 0.073148\n",
      "Stage: train, iter: 56860, lr: 5.956e-07, loss 0.082774\n",
      "Stage: train, iter: 56880, lr: 5.882e-07, loss 0.106945\n",
      "Stage: train, iter: 56900, lr: 5.809e-07, loss 0.093181\n",
      "Stage: train, iter: 56920, lr: 5.735e-07, loss 0.072575\n",
      "Stage: train, iter: 56940, lr: 5.663e-07, loss 0.032005\n",
      "Stage: train, iter: 56960, lr: 5.590e-07, loss 0.067824\n",
      "Stage: train, iter: 56980, lr: 5.518e-07, loss 0.047577\n",
      "Stage: train, iter: 57000, lr: 5.447e-07, loss 0.079106\n",
      "Stage: train, iter: 57020, lr: 5.376e-07, loss 0.062036\n",
      "Stage: train, iter: 57040, lr: 5.305e-07, loss 0.090448\n",
      "Stage: train, iter: 57060, lr: 5.235e-07, loss 0.066539\n",
      "Stage: train, iter: 57080, lr: 5.165e-07, loss 0.079838\n",
      "Stage: train, iter: 57100, lr: 5.096e-07, loss 0.063728\n",
      "Stage: train, iter: 57120, lr: 5.027e-07, loss 0.082905\n",
      "Stage: train, iter: 57140, lr: 4.958e-07, loss 0.098477\n",
      "Stage: train, iter: 57160, lr: 4.890e-07, loss 0.086364\n",
      "Stage: train, iter: 57180, lr: 4.823e-07, loss 0.092236\n",
      "Stage: train, iter: 57200, lr: 4.756e-07, loss 0.112483\n",
      "Stage: train, iter: 57220, lr: 4.689e-07, loss 0.102310\n",
      "Stage: train, iter: 57240, lr: 4.623e-07, loss 0.080150\n",
      "Stage: train, iter: 57260, lr: 4.557e-07, loss 0.081514\n",
      "Stage: train, iter: 57280, lr: 4.492e-07, loss 0.070597\n",
      "Stage: train, iter: 57300, lr: 4.427e-07, loss 0.083567\n",
      "Stage: train, iter: 57320, lr: 4.363e-07, loss 0.067176\n",
      "Stage: train, iter: 57340, lr: 4.299e-07, loss 0.085228\n",
      "Stage: train, iter: 57360, lr: 4.235e-07, loss 0.050744\n",
      "Stage: train, iter: 57380, lr: 4.172e-07, loss 0.084483\n",
      "Stage: train, iter: 57400, lr: 4.110e-07, loss 0.107933\n",
      "Stage: train, iter: 57420, lr: 4.047e-07, loss 0.061108\n",
      "Stage: train, iter: 57440, lr: 3.986e-07, loss 0.084237\n",
      "Stage: train, iter: 57460, lr: 3.924e-07, loss 0.061321\n",
      "Stage: train, iter: 57480, lr: 3.864e-07, loss 0.069516\n",
      "Stage: train, iter: 57500, lr: 3.803e-07, loss 0.087134\n",
      "Stage: train, iter: 57520, lr: 3.744e-07, loss 0.075838\n",
      "Stage: train, iter: 57540, lr: 3.684e-07, loss 0.088373\n",
      "Stage: train, iter: 57560, lr: 3.625e-07, loss 0.081362\n",
      "Stage: train, iter: 57580, lr: 3.567e-07, loss 0.078145\n",
      "Stage: train, iter: 57600, lr: 3.509e-07, loss 0.051108\n",
      "Stage: train, iter: 57620, lr: 3.451e-07, loss 0.101344\n",
      "Stage: train, iter: 57640, lr: 3.394e-07, loss 0.059176\n",
      "Stage: train, iter: 57660, lr: 3.337e-07, loss 0.074695\n",
      "Stage: train, iter: 57680, lr: 3.281e-07, loss 0.064560\n",
      "Stage: train, iter: 57700, lr: 3.225e-07, loss 0.054133\n",
      "Stage: train, iter: 57720, lr: 3.170e-07, loss 0.089868\n",
      "Stage: train, iter: 57740, lr: 3.115e-07, loss 0.083553\n",
      "Stage: train, iter: 57760, lr: 3.061e-07, loss 0.066237\n",
      "Stage: train, iter: 57780, lr: 3.007e-07, loss 0.063065\n",
      "Stage: train, iter: 57800, lr: 2.954e-07, loss 0.080956\n",
      "Stage: train, iter: 57820, lr: 2.901e-07, loss 0.064175\n",
      "Stage: train, iter: 57840, lr: 2.848e-07, loss 0.078209\n",
      "Stage: train, iter: 57860, lr: 2.796e-07, loss 0.056756\n",
      "Stage: train, iter: 57880, lr: 2.745e-07, loss 0.097512\n",
      "Stage: train, iter: 57900, lr: 2.693e-07, loss 0.062040\n",
      "Stage: train, iter: 57920, lr: 2.643e-07, loss 0.089141\n",
      "Stage: train, iter: 57940, lr: 2.593e-07, loss 0.088303\n",
      "Stage: train, iter: 57960, lr: 2.543e-07, loss 0.085221\n",
      "Stage: train, iter: 57980, lr: 2.494e-07, loss 0.083442\n",
      "Stage: train, iter: 58000, lr: 2.445e-07, loss 0.082553\n",
      "Stage: train, iter: 58020, lr: 2.397e-07, loss 0.076549\n",
      "Stage: train, iter: 58040, lr: 2.349e-07, loss 0.056505\n",
      "Stage: train, iter: 58060, lr: 2.302e-07, loss 0.118018\n",
      "Stage: train, iter: 58080, lr: 2.255e-07, loss 0.075214\n",
      "Stage: train, iter: 58100, lr: 2.208e-07, loss 0.071198\n",
      "Stage: train, iter: 58120, lr: 2.162e-07, loss 0.085778\n",
      "Stage: train, iter: 58140, lr: 2.117e-07, loss 0.084540\n",
      "Stage: train, iter: 58160, lr: 2.072e-07, loss 0.079174\n",
      "Stage: train, iter: 58180, lr: 2.027e-07, loss 0.036696\n",
      "Stage: train, iter: 58200, lr: 1.983e-07, loss 0.093457\n",
      "Stage: train, iter: 58220, lr: 1.940e-07, loss 0.087965\n",
      "Stage: train, iter: 58240, lr: 1.897e-07, loss 0.055840\n",
      "Stage: train, iter: 58260, lr: 1.854e-07, loss 0.101162\n",
      "Stage: train, iter: 58280, lr: 1.812e-07, loss 0.081067\n",
      "Stage: train, iter: 58300, lr: 1.770e-07, loss 0.073219\n",
      "Stage: train, iter: 58320, lr: 1.729e-07, loss 0.101745\n",
      "Stage: train, iter: 58340, lr: 1.688e-07, loss 0.124761\n",
      "Stage: train, iter: 58360, lr: 1.648e-07, loss 0.076107\n",
      "Stage: train, iter: 58380, lr: 1.608e-07, loss 0.076863\n",
      "Stage: train, iter: 58400, lr: 1.569e-07, loss 0.045681\n",
      "Stage: train, iter: 58420, lr: 1.530e-07, loss 0.054579\n",
      "Stage: train, iter: 58440, lr: 1.492e-07, loss 0.077365\n",
      "Stage: train, iter: 58460, lr: 1.454e-07, loss 0.079684\n",
      "Stage: train, iter: 58480, lr: 1.417e-07, loss 0.069634\n",
      "Stage: train, iter: 58500, lr: 1.380e-07, loss 0.075440\n",
      "Stage: train, iter: 58520, lr: 1.343e-07, loss 0.100124\n",
      "Stage: train, iter: 58540, lr: 1.307e-07, loss 0.081102\n",
      "Stage: train, iter: 58560, lr: 1.272e-07, loss 0.102050\n",
      "Stage: train, iter: 58580, lr: 1.237e-07, loss 0.088861\n",
      "Stage: train, iter: 58600, lr: 1.203e-07, loss 0.063725\n",
      "Stage: train, iter: 58620, lr: 1.169e-07, loss 0.062281\n",
      "Stage: train, iter: 58640, lr: 1.135e-07, loss 0.079081\n",
      "Stage: train, iter: 58660, lr: 1.102e-07, loss 0.062597\n",
      "Stage: train, iter: 58680, lr: 1.069e-07, loss 0.054949\n",
      "Stage: train, iter: 58700, lr: 1.037e-07, loss 0.052822\n",
      "Stage: train, iter: 58720, lr: 1.006e-07, loss 0.077367\n",
      "Stage: train, iter: 58740, lr: 9.747e-08, loss 0.065025\n",
      "Stage: train, iter: 58760, lr: 9.440e-08, loss 0.094924\n",
      "Stage: train, iter: 58780, lr: 9.139e-08, loss 0.068830\n",
      "Stage: train, iter: 58800, lr: 8.843e-08, loss 0.138983\n",
      "Stage: train, iter: 58820, lr: 8.551e-08, loss 0.092022\n",
      "Stage: train, iter: 58840, lr: 8.264e-08, loss 0.066161\n",
      "Stage: train, iter: 58860, lr: 7.982e-08, loss 0.061117\n",
      "Stage: train, iter: 58880, lr: 7.705e-08, loss 0.041358\n",
      "Stage: train, iter: 58900, lr: 7.433e-08, loss 0.063917\n",
      "Stage: train, iter: 58920, lr: 7.165e-08, loss 0.079341\n",
      "Stage: train, iter: 58940, lr: 6.903e-08, loss 0.038905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: train, iter: 58960, lr: 6.645e-08, loss 0.051945\n",
      "Stage: train, iter: 58980, lr: 6.392e-08, loss 0.066936\n",
      "Stage: train, iter: 59000, lr: 6.144e-08, loss 0.056959\n",
      "Stage: train, iter: 59020, lr: 5.901e-08, loss 0.082397\n",
      "Stage: train, iter: 59040, lr: 5.663e-08, loss 0.105391\n",
      "Stage: train, iter: 59060, lr: 5.430e-08, loss 0.083896\n",
      "Stage: train, iter: 59080, lr: 5.201e-08, loss 0.057992\n",
      "Stage: train, iter: 59100, lr: 4.978e-08, loss 0.083953\n",
      "Stage: train, iter: 59120, lr: 4.759e-08, loss 0.085364\n",
      "Stage: train, iter: 59140, lr: 4.545e-08, loss 0.058849\n",
      "Stage: train, iter: 59160, lr: 4.336e-08, loss 0.064490\n",
      "Stage: train, iter: 59180, lr: 4.132e-08, loss 0.093415\n",
      "Stage: train, iter: 59200, lr: 3.933e-08, loss 0.053591\n",
      "Stage: train, iter: 59220, lr: 3.739e-08, loss 0.064750\n",
      "Stage: train, iter: 59240, lr: 3.550e-08, loss 0.096881\n",
      "Stage: train, iter: 59260, lr: 3.365e-08, loss 0.086174\n",
      "Stage: train, iter: 59280, lr: 3.186e-08, loss 0.069991\n",
      "Stage: train, iter: 59300, lr: 3.011e-08, loss 0.051304\n",
      "Stage: train, iter: 59320, lr: 2.842e-08, loss 0.043440\n",
      "Stage: train, iter: 59340, lr: 2.677e-08, loss 0.085491\n",
      "Stage: train, iter: 59360, lr: 2.517e-08, loss 0.056949\n",
      "Stage: train, iter: 59380, lr: 2.362e-08, loss 0.060707\n",
      "Stage: train, iter: 59400, lr: 2.212e-08, loss 0.087585\n",
      "Stage: train, iter: 59420, lr: 2.067e-08, loss 0.078463\n",
      "Stage: train, iter: 59440, lr: 1.926e-08, loss 0.083535\n",
      "Stage: train, iter: 59460, lr: 1.791e-08, loss 0.094510\n",
      "Stage: train, iter: 59480, lr: 1.661e-08, loss 0.077729\n",
      "Stage: train, iter: 59500, lr: 1.535e-08, loss 0.078236\n",
      "Stage: train, iter: 59520, lr: 1.415e-08, loss 0.110992\n",
      "Stage: train, iter: 59540, lr: 1.299e-08, loss 0.063558\n",
      "Stage: train, iter: 59560, lr: 1.188e-08, loss 0.069659\n",
      "Stage: train, iter: 59580, lr: 1.083e-08, loss 0.073883\n",
      "Stage: train, iter: 59600, lr: 9.818e-09, loss 0.068748\n",
      "Stage: train, iter: 59620, lr: 8.859e-09, loss 0.081835\n",
      "Stage: train, iter: 59640, lr: 7.949e-09, loss 0.067963\n",
      "Stage: train, iter: 59660, lr: 7.088e-09, loss 0.049093\n",
      "Stage: train, iter: 59680, lr: 6.276e-09, loss 0.068320\n",
      "Stage: train, iter: 59700, lr: 5.514e-09, loss 0.072011\n",
      "Stage: train, iter: 59720, lr: 4.801e-09, loss 0.054663\n",
      "Stage: train, iter: 59740, lr: 4.138e-09, loss 0.071888\n",
      "Stage: train, iter: 59760, lr: 3.523e-09, loss 0.072486\n",
      "Stage: train, iter: 59780, lr: 2.958e-09, loss 0.093546\n",
      "Stage: train, iter: 59800, lr: 2.443e-09, loss 0.060505\n",
      "Stage: train, iter: 59820, lr: 1.977e-09, loss 0.058842\n",
      "Stage: train, iter: 59840, lr: 1.560e-09, loss 0.081432\n",
      "Stage: train, iter: 59860, lr: 1.192e-09, loss 0.081379\n",
      "Stage: train, iter: 59880, lr: 8.736e-10, loss 0.079687\n",
      "Stage: train, iter: 59900, lr: 6.046e-10, loss 0.075126\n",
      "Stage: train, iter: 59920, lr: 3.850e-10, loss 0.079738\n",
      "Stage: train, iter: 59940, lr: 2.147e-10, loss 0.087652\n",
      "Stage: train, iter: 59960, lr: 9.383e-11, loss 0.072830\n",
      "Stage: train, iter: 59980, lr: 2.227e-11, loss 0.134502\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(pjoin(experiment_dir, 'train_log.txt'))\n",
    "\n",
    "model = get_model()\n",
    "model.load_state_dict(torch.load('./output/res50_i512_ch128_dice0.5_400k/model_180000.pt'))\n",
    "\n",
    "start_lr = 1e-5\n",
    "optimizer = Adam(model.parameters(), lr=start_lr)\n",
    "# lr_policy = StepLR(1e-5, 20000, lr_decay=0.5)\n",
    "lr_policy = CyclicLR(start_lr, 20000)\n",
    "criterion = BCEDiceLoss(w_bce=1, w_dice=0.5)\n",
    "\n",
    "train_dict = {\n",
    "    'model': model,\n",
    "    'output_dirpath': experiment_dir,\n",
    "    'optimizer': optimizer,\n",
    "    'lr_policy': lr_policy,\n",
    "#     'start_iter': 200000,\n",
    "    'num_iters': 60000,\n",
    "    'criterion': criterion,\n",
    "    'train_dataloader': dl_train,\n",
    "    'val_set': val_set,\n",
    "    'logger': logger,\n",
    "}\n",
    "train_hist = train(**train_dict)\n",
    "\n",
    "model_dirpath = join(experiment_dir, f'model_last.pt')\n",
    "torch.save(model.state_dict(), model_dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.log.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inria",
   "language": "python",
   "name": "inria-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
